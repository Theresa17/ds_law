{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f87c4b39",
   "metadata": {},
   "source": [
    "## 1. Aufbereitung der Urteilstexte und Vorbereitung des Analyse-Datensatzes\n",
    "\n",
    "In diesem Abschnitt werden die eingelesenen OpenJur-Urteilstexte weiterverarbeitet und strukturiert. Ziel ist es, relevante Textbestandteile wie den Kopfbereich und den Tenor zu extrahieren, Landgerichtsurteile zu identifizieren und die Daten schlie√ülich in ein geeignetes JSONL-Format f√ºr die nachgelagerte automatische Analyse zu √ºberf√ºhren.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972de4e7",
   "metadata": {},
   "source": [
    "### 1.1 Import der ben√∂tigten Bibliotheken\n",
    "\n",
    "Zu Beginn werden die f√ºr die weitere Verarbeitung erforderlichen Python-Bibliotheken importiert. Diese umfassen Funktionen f√ºr Dateizugriffe, regul√§re Ausdr√ºcke, Datenverarbeitung mit Pandas sowie den Export der Ergebnisse im JSON-Format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "58f86b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61a736b",
   "metadata": {},
   "source": [
    "### 1.2 Einlesen der Urteilstexte und Aufbau des DataFrames\n",
    "\n",
    "In diesem Schritt werden alle zuvor identifizierten Textdateien zeilenweise eingelesen. F√ºr jede Datei wird eine eindeutige Fall-ID aus dem Dateinamen erzeugt und gemeinsam mit dem vollst√§ndigen Text in einem Pandas-DataFrame gespeichert. Der DataFrame bildet die zentrale Datenstruktur f√ºr die weitere Analyse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1bef8dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pfad: c:\\Users\\there\\ds_law\\backend\\data\\Gerichtsurteile_Openjur\n",
      "Anzahl .txt: 2375\n",
      "Erste 10 Dateien: ['2090187.txt', '2112111.txt', '2112115.txt', '2112117.txt', '2112118.txt', '2112119.txt', '2112121.txt', '2112123.txt', '2124977.txt', '2126821.txt']\n"
     ]
    }
   ],
   "source": [
    "# (.txt) Dateien einlesen\n",
    "DATA_DIR = \"../data/Gerichtsurteile_Openjur\" \n",
    "files = [f for f in os.listdir(DATA_DIR) if f.lower().endswith(\".txt\")]\n",
    "\n",
    "print(\"Pfad:\", os.path.abspath(DATA_DIR))\n",
    "print(\"Anzahl .txt:\", len(files))\n",
    "print(\"Erste 10 Dateien:\", files[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d494b356",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed94d8a",
   "metadata": {},
   "source": [
    "## 2. Textvorverarbeitung und Extraktion zentraler Urteilsbestandteile\n",
    "\n",
    "In diesem Abschnitt werden die eingelesenen Urteilstexte weiterverarbeitet, um f√ºr die nachfolgende Analyse relevante Textbestandteile gezielt zu extrahieren. Hierzu z√§hlen insbesondere ein begrenzter Kopfbereich zur Voranalyse sowie der Tenor als Kern der gerichtlichen Entscheidung. Die strukturierte Aufbereitung dieser Textsegmente bildet die Grundlage f√ºr Filter-, Klassifikations- und Extraktionsschritte in den folgenden Abschnitten."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c915ba",
   "metadata": {},
   "source": [
    "### 2.1 Erzeugung eines Kopfbereichs zur Voranalyse\n",
    "\n",
    "Da relevante Metadaten wie Gericht, Entscheidungsart und Datum typischerweise am Anfang eines Urteilstextes stehen, wird ein begrenzter Kopfbereich (`head`) aus den ersten Zeichen des Dokuments extrahiert. Dieser verk√ºrzte Textausschnitt dient als effizienter Suchraum f√ºr Filter- und Klassifikationsschritte.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "28198986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gesamt eingelesen: 2375\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "for fn in files:\n",
    "    case_id = fn.replace(\".txt\", \"\")\n",
    "    path = os.path.join(DATA_DIR, fn)\n",
    "    with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        text = f.read()\n",
    "    rows.append({\"case_id\": case_id, \"text\": text})\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(\"Gesamt eingelesen:\", len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "99a88600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head-L√§nge (Beispiel): 8000\n"
     ]
    }
   ],
   "source": [
    "HEAD_CHARS = 8000\n",
    "df[\"head\"] = df[\"text\"].astype(str).str.slice(0, HEAD_CHARS)\n",
    "\n",
    "print(\"Head-L√§nge (Beispiel):\", len(df.loc[0, \"head\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b62f66",
   "metadata": {},
   "source": [
    "### 2.2 Extraktion des Tenors\n",
    "\n",
    "Der Tenor enth√§lt die eigentliche gerichtliche Entscheidung und ist daher f√ºr die inhaltliche Bewertung besonders relevant. Mithilfe regul√§rer Ausdr√ºcke wird der Textabschnitt zwischen der √úberschrift ‚ÄûTenor‚Äú und den nachfolgenden Abschnitten (z. B. ‚ÄûTatbestand‚Äú oder ‚ÄûGr√ºnde‚Äú) extrahiert und in einer separaten Spalte gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c8326393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tenor vorhanden: 2362 von 2375\n"
     ]
    }
   ],
   "source": [
    "def extract_tenor(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    m_start = re.search(r\"\\bTenor\\b\", text, flags=re.IGNORECASE)\n",
    "    if not m_start:\n",
    "        return \"\"\n",
    "    start = m_start.end()\n",
    "    m_end = re.search(\n",
    "        r\"\\b(Tatbestand|Gr√ºnde|Gruende|Entscheidungsgr√ºnde|Entscheidungsgruende)\\b\",\n",
    "        text[start:],\n",
    "        flags=re.IGNORECASE\n",
    "    )\n",
    "    end = start + m_end.start() if m_end else min(len(text), start + 8000)\n",
    "    return text[start:end].strip()\n",
    "\n",
    "df[\"tenor\"] = df[\"text\"].apply(extract_tenor)\n",
    "\n",
    "print(\"Tenor vorhanden:\", (df[\"tenor\"].str.len() > 0).sum(), \"von\", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2481ec6a",
   "metadata": {},
   "source": [
    "### 2.3 Identifikation von Landgerichtsurteilen (LG)\n",
    "\n",
    "Im n√§chsten Schritt werden die Urteile anhand des Kopfbereichs danach gefiltert, ob es sich um Entscheidungen eines Landgerichts handelt. Dazu wird gepr√ºft, ob charakteristische Begriffe wie ‚ÄûLandgericht‚Äú oder die Abk√ºrzung ‚ÄûLG‚Äú im Kopfbereich vorkommen. Auf dieser Grundlage wird eine boolesche Variable erzeugt, die zur Selektion der relevanten F√§lle dient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6577492d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "STATISTIK (LG-Filter)\n",
      "is_landgericht\n",
      "True     2088\n",
      "False     287\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "‚úÖ LG-Dokumente: 2088\n"
     ]
    }
   ],
   "source": [
    "lg_pattern = r\"\\bLandgericht\\b|\\bLG\\s+[A-Z√Ñ√ñ√úa-z√§√∂√º√ü\\-]+\"\n",
    "df[\"is_landgericht\"] = df[\"head\"].str.contains(lg_pattern, case=False, regex=True, na=False)\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(\"STATISTIK (LG-Filter)\")\n",
    "print(df[\"is_landgericht\"].value_counts(dropna=False))\n",
    "print(\"-\" * 40)\n",
    "\n",
    "df_lg = df[df[\"is_landgericht\"] == True].copy()\n",
    "print(\"‚úÖ LG-Dokumente:\", len(df_lg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf90b3f4",
   "metadata": {},
   "source": [
    "### 2.4 Bereinigung des Kopfbereichs von OLG-Verweisen\n",
    "\n",
    "Da in vielen Urteilen Verweise auf Oberlandesgerichte (z. B. im Rahmen von Berufungsverfahren) enthalten sind, werden entsprechende Zeilen aus dem Kopfbereich entfernt. Ziel ist es, den Text f√ºr die sp√§tere automatische Analyse auf die tats√§chlich entscheidungsrelevanten Informationen zu reduzieren und potenzielle Fehlinterpretationen zu vermeiden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "248b321c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé OLG-ZEILEN in head_clean (soll 0 sein): 0\n"
     ]
    }
   ],
   "source": [
    "re_olg_line = re.compile(\n",
    "    r\"(?i)^\\s*(?:Einfach\\s*)?O\\s*L\\s*G\\b|^\\s*(?:Einfach\\s*)?Oberlandesgericht\\b\"\n",
    ")\n",
    "\n",
    "def remove_olg_lines(block: str) -> str:\n",
    "    if not isinstance(block, str) or not block:\n",
    "        return \"\"\n",
    "    kept = []\n",
    "    for line in block.splitlines():\n",
    "        if re_olg_line.search(line):\n",
    "            continue\n",
    "        kept.append(line)\n",
    "    return \"\\n\".join(kept).strip()\n",
    "\n",
    "df_lg[\"head_clean\"] = df_lg[\"head\"].apply(remove_olg_lines)\n",
    "\n",
    "still_olg = df_lg[\"head_clean\"].str.contains(\n",
    "    r\"(?i)^\\s*(?:Einfach\\s*)?O\\s*L\\s*G\\b|^\\s*(?:Einfach\\s*)?Oberlandesgericht\\b\",\n",
    "    regex=True, na=False\n",
    ").sum()\n",
    "\n",
    "print(\"üîé OLG-ZEILEN in head_clean (soll 0 sein):\", still_olg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d302013a",
   "metadata": {},
   "source": [
    "### 2.5 Definition des Extraktions- und Analyse-Prompts\n",
    "\n",
    "F√ºr die sp√§tere automatisierte Auswertung der Urteile wird ein strukturierter Prompt definiert. Dieser enth√§lt detaillierte Anweisungen zur Extraktion von Sachverhaltsmerkmalen, Entscheidungsparametern und Zielvariablen. Der Prompt stellt sicher, dass alle Urteile nach einem einheitlichen Schema analysiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "48c3b4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPREHENSIVE_PROMPT = \"\"\"\n",
    "Lies den Text genau und analysiere das vorliegende Gerichtsurteil. Extrahiere die folgenden Informationen pr√§zise. Falls eine Information im Text nicht auffindbar ist, gib \"null\" an.\n",
    "\n",
    "### Extraktions-Anweisungen:\n",
    "1. **Input-Variablen (Features):**\n",
    "    * **Dieselmotor_Typ (String):** Welcher Motortyp (z. B. EA 189, EA 288)?\n",
    "    * **Art_Abschalteinrichtung (String):** Beschreibung der genannten Abschalteinrichtung.\n",
    "    * **KBA_Rueckruf (Boolean):** Verpflichtender R√ºckruf des Kraftfahrt-Bundesamtes? (true/false)\n",
    "    * **Fahrzeugstatus (String):** \"Neuwagen\" oder \"Gebrauchtwagen\"?\n",
    "    * **Fahrzeugmodell_Baureihe (String):** Bezeichnung des Modells.\n",
    "    * **Update_Status (Boolean/null):** Software-Update aufgespielt? (true/false/null)\n",
    "    * **Kilometerstand_Kauf (Integer):** Stand bei Erwerb.\n",
    "    * **Kilometerstand_Klageerhebung (Integer):** Stand bei Klageeinreichung.\n",
    "    * **Erwartete_Gesamtlaufleistung (Integer):** Vom Gericht angenommene Gesamtlaufleistung.\n",
    "    * **Kaufdatum (Date):** Format: YYYY-MM-DD.\n",
    "    * **Uebergabedatum (Date):** Format: YYYY-MM-DD.\n",
    "    * **Datum_Klageerhebung (Date):** Format: YYYY-MM-DD.\n",
    "    * **Nachweis_Aufklaerung (Boolean):** Gab es eine Anlage zum Kaufvertrag √ºber die Software? (true/false)\n",
    "    * **Beklagten_Typ (String):** \"H√§ndler\" oder \"Hersteller\".\n",
    "    * **Datum_Urteil (Date):** Format: YYYY-MM-DD.\n",
    "    * **Kaufpreis (Float):** Betrag in Euro (ohne Zinsen).\n",
    "    * **Nacherfuellungsverlangen_Fristsetzung (String):** \"Ja\", \"Nein\", \"Entbehrlich\".\n",
    "    * **Klageziel (String):** z. B. \"R√ºckabwicklung\", \"Minderung\", \"Schadensersatz\".\n",
    "    * **Rechtsgrundlage (String):** z. B. ¬ß 437 BGB oder ¬ß 826 BGB.\n",
    "\n",
    "2. **Zielvariablen (Labeling):**\n",
    "    * **LABEL_Anspruch_Schadensersatz (Boolean):** Kl√§ger erh√§lt Schadensersatz? (true/false)\n",
    "    * **LABEL_Schadensersatzhoehe_Betrag (Float):** Zugesprochener Betrag in Euro (ohne Zinsen).\n",
    "    * **LABEL_Schadensersatzhoehe_Range (String):** \"< 5000\", \"5000-10000\", \"10001-15000\", \"> 15000\", \"Klage abgewiesen\".\n",
    "\n",
    "3. **Kategorisierung \"Sonstige\":**\n",
    "    Sollte im Tenor nichts √ºber Abweisung oder Schadensersatz stehen (sondern Streitwertfestsetzung, Ablehnungsgesuche etc.), kategorisiere als \"Sonstige\". Gib im Feld \"Urteil_Anmerkung\" die Begr√ºndung an.\n",
    "\n",
    "### Ausgabeformat:\n",
    "Antworte AUSSCHLIESSLICH als JSON-Liste mit einem Eintrag. Ignoriere Streitwerte und Zinsen.\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bcdc03",
   "metadata": {},
   "source": [
    "### 2.6 Export der gefilterten LG-Urteile im JSONL-Format\n",
    "\n",
    "Abschlie√üend werden ausschlie√ülich die gefilterten Landgerichtsurteile in eine JSONL-Datei exportiert. Jedes Urteil wird dabei als einzelner Eintrag mit Fall-ID, bereinigtem Kopfbereich, Tenor und Analyse-Prompt gespeichert. Dieses Format eignet sich insbesondere f√ºr die Batch-Verarbeitung mit gro√üen Sprachmodellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "704fac23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ JSONL geschrieben: gemini_batch_input_NUR_LG.jsonl\n"
     ]
    }
   ],
   "source": [
    "output_path = \"gemini_batch_input_NUR_LG.jsonl\"\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for _, row in df_lg.iterrows():\n",
    "        payload = {\n",
    "            \"custom_id\": f\"case_{row['case_id']}\",\n",
    "            \"contents\": [{\n",
    "                \"role\": \"user\",\n",
    "                \"parts\": [{\n",
    "                    \"text\": f\"Kopf: {row['head_clean']}\\nTenor: {row['tenor']}\\n\\n{COMPREHENSIVE_PROMPT}\"\n",
    "                }]\n",
    "            }]\n",
    "        }\n",
    "        f.write(json.dumps(payload, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(\"‚úÖ JSONL geschrieben:\", output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350ef924",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b34d41b",
   "metadata": {},
   "source": [
    "## 3. Validierung der Batch-Verarbeitung anhand eines Einzelfalls\n",
    "\n",
    "Bevor die vollst√§ndige Batch-Verarbeitung aller Landgerichtsurteile durchgef√ºhrt wird, erfolgt ein Probelauf anhand eines einzelnen Dokuments. Dazu wird aus der zuvor erzeugten JSONL-Datei eine reduzierte Testdatei erstellt, die ausschlie√ülich den ersten Eintrag enth√§lt.\n",
    "\n",
    "Dieser Einzelfall wird √ºber die Batch-API verarbeitet, um die Funktionsf√§higkeit des Prompts, die Struktur der Modellantwort sowie die inhaltliche Plausibilit√§t der extrahierten Informationen zu √ºberpr√ºfen. Auf diese Weise k√∂nnen potenzielle Fehler fr√ºhzeitig identifiziert werden, bevor die Analyse auf den gesamten Datensatz ausgeweitet wird.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb07224c",
   "metadata": {},
   "source": [
    "### 3.1 Erstellung einer Test-JSONL-Datei f√ºr den Probelauf\n",
    "\n",
    "Zur technischen und inhaltlichen Validierung der Batch-Verarbeitung wird zun√§chst eine reduzierte JSONL-Datei erstellt, die ausschlie√ülich einen einzelnen Fall enth√§lt. Dieser Probelauf erm√∂glicht eine gezielte √úberpr√ºfung des Prompts und der Modellantwort, bevor die Analyse auf den vollst√§ndigen Datensatz ausgeweitet wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d72202f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Test-JSONL mit einem Dokument erstellt: gemini_batch_input_TEST_1.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Pfade\n",
    "input_jsonl = \"gemini_batch_input_NUR_LG.jsonl\"\n",
    "test_jsonl  = \"gemini_batch_input_TEST_1.jsonl\"\n",
    "\n",
    "# Erste Zeile aus der gro√üen JSONL kopieren\n",
    "with open(input_jsonl, \"r\", encoding=\"utf-8\") as fin:\n",
    "    first_line = fin.readline()\n",
    "\n",
    "with open(test_jsonl, \"w\", encoding=\"utf-8\") as fout:\n",
    "    fout.write(first_line)\n",
    "\n",
    "print(\"‚úÖ Test-JSONL mit einem Dokument erstellt:\", test_jsonl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710eb470",
   "metadata": {},
   "source": [
    "### 3.2 Durchf√ºhrung eines Batch-Probelaufs mit der Gemini-API\n",
    "\n",
    "Im Anschluss wird die erzeugte Test-JSONL-Datei √ºber die Batch-API des Gemini-Modells verarbeitet. Dabei wird die Datei zun√§chst hochgeladen und anschlie√üend ein Batch-Job gestartet. Um tempor√§re API-Limitierungen abzufangen, wird ein Exponential-Backoff-Mechanismus implementiert. Der Probelauf dient der √úberpr√ºfung, ob das Modell die Eingabestruktur korrekt verarbeitet und eine valide, strukturierte Ausgabe erzeugt.\n",
    "\n",
    "&\n",
    "\n",
    "### 3.3 Sichtpr√ºfung der Modellantwort\n",
    "\n",
    "Die vom Modell erzeugte Ausgabe des Einzelfalls wird anschlie√üend manuell √ºberpr√ºft. Dabei wird kontrolliert, ob die extrahierten Merkmale vollst√§ndig, konsistent und in dem erwarteten JSON-Format vorliegen. Auf Grundlage dieser Sichtpr√ºfung wird entschieden, ob der Prompt oder die Vorverarbeitung angepasst werden m√ºssen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef2fbf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload: files/7samsw8f9ztq\n",
      "[1/8] 429 -> sleep 2.7s\n",
      "[2/8] 429 -> sleep 4.9s\n",
      "[3/8] 429 -> sleep 11.9s\n",
      "[4/8] 429 -> sleep 20.1s\n",
      "[5/8] 429 -> sleep 38.2s\n",
      "[6/8] 429 -> sleep 68.8s\n"
     ]
    }
   ],
   "source": [
    "import time, random\n",
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=\"AIzaSyA_5C2o01dKnD6uOtEmJoCfTQKWkKB9QHE\")\n",
    "\n",
    "def create_batch_with_backoff(*, model, src, display_name, retries=8):\n",
    "    delay = 2.0\n",
    "    for attempt in range(1, retries + 1):\n",
    "        try:\n",
    "            return client.batches.create(\n",
    "                model=model,\n",
    "                src=src,\n",
    "                config={\"display_name\": display_name},\n",
    "            )\n",
    "        except Exception as e:\n",
    "            msg = str(e)\n",
    "            if \"429\" in msg or \"RESOURCE_EXHAUSTED\" in msg:\n",
    "                sleep_s = delay + random.uniform(0, 0.5 * delay)\n",
    "                print(f\"[{attempt}/{retries}] 429 -> sleep {sleep_s:.1f}s\")\n",
    "                time.sleep(sleep_s)\n",
    "                delay = min(delay * 2, 60)\n",
    "                continue\n",
    "            raise\n",
    "\n",
    "# Upload der Test-JSONL-Datei\n",
    "uploaded = client.files.upload(\n",
    "    file=\"gemini_batch_input_TEST_1.jsonl\",\n",
    "    config={\"display_name\": \"diesel-lg-test-1\", \"mime_type\": \"jsonl\"},\n",
    ")\n",
    "print(\"Upload:\", uploaded.name)\n",
    "\n",
    "# Start des Batch-Jobs\n",
    "job = create_batch_with_backoff(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    src=uploaded.name,\n",
    "    display_name=\"diesel-lg-test-1\",\n",
    ")\n",
    "print(\"Batch:\", job.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d86e870",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29e2cf5",
   "metadata": {},
   "source": [
    "## 4. Durchf√ºhrung der automatisierten Urteilsanalyse\n",
    "\n",
    "Ziel des Abschnitts:\n",
    "Durchf√ºhrung der finalen automatisierten Analyse des bereits aufbereiteten Analyse-Datensatzes mithilfe der Gemini Batch-API sowie Erzeugung eines strukturierten Ergebnisdatensatzes f√ºr die weitere Auswertung.\n",
    "\n",
    "Wichtig:\n",
    "Keine erneute Datenaufbereitung, sondern Nutzung der in Abschnitt 2 erzeugten JSONL-Datei."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f99f72e",
   "metadata": {},
   "source": [
    "### 4.1 Bereitstellung der Analyse-Eingabedaten\n",
    "\n",
    "Die in Abschnitt 2 aufbereiteten und gefilterten Urteilstexte liegen bereits in Form einer strukturierten JSONL-Datei vor.\n",
    "Diese Datei dient als direkter Input f√ºr die nachgelagerte automatisierte Analyse und wird im Folgenden in das Batch-Verarbeitungssystem eingelesen.\n",
    "\n",
    "(gemini_batch_input_NUR_LG.jsonl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaca577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier Code einf√ºgen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8b810e",
   "metadata": {},
   "source": [
    "### 4.2 √úbergabe des Analyse-Datensatzes an die Batch-API\n",
    "\n",
    "Nach der in Abschnitt 2 beschriebenen Aufbereitung der Urteilstexte liegt der vollst√§ndige Analyse-Datensatz in Form einer strukturierten JSONL-Datei vor. Diese Datei dient in diesem Schritt als Eingabe f√ºr die automatisierte Verarbeitung durch ein gro√ües Sprachmodell.\n",
    "\n",
    "Die JSONL-Datei wird zun√§chst in das Batch-System hochgeladen. Anschlie√üend wird ein Batch-Verarbeitungsjob gestartet, der die hochgeladene Datei als Eingabequelle verwendet. F√ºr jedes enthaltene Dokument erzeugt das Modell eine strukturierte Antwort gem√§√ü den im Prompt definierten Extraktionsvorgaben.\n",
    "\n",
    "Als Ergebnis des Batch-Jobs stellt die API eine Ausgabedatei bereit, die die Modellantworten zu allen verarbeiteten Urteilen enth√§lt. Diese Ausgabedatei liegt ebenfalls im JSONL-Format vor und bildet die Grundlage f√ºr die weitere Aufbereitung und Auswertung der Ergebnisse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f543fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier Code einf√ºgen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a7cbd2",
   "metadata": {},
   "source": [
    "### 4.3 Aufbereitung der Batch-Ergebnisse und Erstellung des Analyse-Datensatzes\n",
    "\n",
    "Die im vorherigen Schritt erzeugte Ausgabedatei des Batch-Jobs liegt zun√§chst als Rohdaten im JSONL-Format vor. Jede Zeile dieser Datei enth√§lt die strukturierte Modellantwort zu einem einzelnen Landgerichtsurteil.\n",
    "\n",
    "Diese Rohdaten werden lokal gespeichert und anschlie√üend in ein tabellarisches Format √ºberf√ºhrt. Hierzu werden die relevanten Felder aus den JSON-Strukturen extrahiert und in einer einheitlichen Datenstruktur zusammengef√ºhrt, beispielsweise in Form einer CSV-Datei. \n",
    "Der so erzeugte Datensatz bildet die Grundlage f√ºr die weitere statistische Auswertung und Analyse in den folgenden Abschnitten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e032793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier Code einf√ºgen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500c339b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f899d3",
   "metadata": {},
   "source": [
    "## 5. Datenaufbereitung\n",
    "\n",
    "In diesem Abschnitt werden die im vorherigen Schritt erzeugten Analyseergebnisse weiterverarbeitet und f√ºr die nachgelagerte statistische Auswertung vorbereitet. Grundlage hierf√ºr ist der aus den Batch-Ergebnissen abgeleitete strukturierte Datensatz, der die vom Sprachmodell extrahierten Informationen zu den einzelnen Urteilen enth√§lt.\n",
    "\n",
    "Ziel der Datenaufbereitung ist es, die extrahierten Merkmale in eine konsistente, auswertbare Form zu √ºberf√ºhren, fehlende oder uneinheitliche Angaben zu behandeln und die Zielvariablen f√ºr die sp√§tere Analyse eindeutig zu definieren."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a973d920",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05160c8f",
   "metadata": {},
   "source": [
    "## 6. Analyse und Auswertung"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

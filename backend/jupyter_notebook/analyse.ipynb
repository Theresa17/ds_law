{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b670ffb",
   "metadata": {},
   "source": [
    "- Daten einlesen\n",
    "- Texte bereinigen\n",
    "- Modell(e) trainieren\n",
    "- Accuracy, Precision & Recall berechnen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40ffd15",
   "metadata": {},
   "source": [
    "### Schritt 1A: Einlesen der Rohdaten\n",
    "In diesem Schritt wird geprüft, ob alle Urteilstexte aus dem bereitgestellten OpenJur-Datensatz korrekt geladen werden können. Ziel ist es, die Datengrundlage zu verifizieren, bevor weitere Verarbeitungsschritte erfolgen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f00128fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pfad: c:\\Users\\Lena\\Documents\\GitHub\\ds_law\\backend\\data\\Gerichtsurteile_Openjur\n",
      "Anzahl .txt: 2375\n",
      "Erste 10 Dateien: ['2090187.txt', '2112111.txt', '2112115.txt', '2112117.txt', '2112118.txt', '2112119.txt', '2112121.txt', '2112123.txt', '2124977.txt', '2126821.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "DATA_DIR = \"../data/Gerichtsurteile_Openjur\" \n",
    "files = [f for f in os.listdir(DATA_DIR) if f.lower().endswith(\".txt\")]\n",
    "\n",
    "print(\"Pfad:\", os.path.abspath(DATA_DIR))\n",
    "print(\"Anzahl .txt:\", len(files))\n",
    "print(\"Erste 10 Dateien:\", files[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fb7856",
   "metadata": {},
   "source": [
    "Die Ausgabe bestätigt, dass insgesamt 2375 Urteilstexte erfolgreich eingelesen wurden. Die Dateinamen entsprechen den von OpenJur vergebenen Fall-IDs, wodurch die Konsistenz und Vollständigkeit der Datengrundlage sichergestellt ist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d4f953",
   "metadata": {},
   "source": [
    "### Schritt 1B: Filterung nach LG + Extraktion der Variablen\n",
    "Aufgabe: Filterung nach LG muss noch in den Prompt integriert werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3c0cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "STATISTIK\n",
      "Gesamt eingelesen: 2375\n",
      "Gefilterte LGs:    2088\n",
      "----------------------------------------\n",
      "Teste Extraktion für Case: 2112111...\n",
      "\n",
      "Ergebnis des Einzeltests:\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"Dieselmotor_Typ\": \"EA 189\",\n",
      "    \"Art_Abschalteinrichtung\": \"Motorensteuerungsgerätesoftware (sog. Umschaltlogik), die erkennt, wenn das Fahrzeug auf dem Prüfstand den Neuen Europäischen Fahrzyklus (NEFZ) durchfährt, und dann einen besonderen Modus aktiviert, in dem die Rückführung von Abgasen im Vergleich zum normalen Betriebsmodus verändert wird, um den NOx-Grenzwert einzuhalten. Im normalen Fahrbetrieb ist dieser Modus deaktiviert, was zu höherem Schadstoffausstoß führt. Eine weitere Abschalteinrichtung in Form eines Thermofensters verbleibt auch nach einem Update.\",\n",
      "    \"KBA_Rueckruf\": true,\n",
      "    \"Fahrzeugstatus\": \"Neuwagen\",\n",
      "    \"Fahrzeugmodell_Baureihe\": \"1,6l TDI\",\n",
      "    \"Update_Status\": null,\n",
      "    \"Kilometerstand_Kauf\": null,\n",
      "    \"Kilometerstand_Klageerhebung\": null,\n",
      "    \"Erwartete_Gesamtlaufleistung\": null,\n",
      "    \"Kaufdatum\": null,\n",
      "    \"Uebergabedatum\": \"2010-12-20\",\n",
      "    \"Datum_Klageerhebung\": null,\n",
      "    \"Nachweis_Aufklaerung\": null,\n",
      "    \"Beklagten_Typ\": \"Hersteller\",\n",
      "    \"Datum_Urteil\": \"2018-05-18\",\n",
      "    \"Kaufpreis\": 28486.76,\n",
      "    \"Nacherfuellungsverlangen_Fristsetzung\": \"Entbehrlich\",\n",
      "    \"Klageziel\": \"Rückabwicklung\",\n",
      "    \"Rechtsgrundlage\": \"§ 826 BGB\",\n",
      "    \"LABEL_Anspruch_Schadensersatz\": true,\n",
      "    \"LABEL_Schadensersatzhoehe_Betrag\": 18412.37,\n",
      "    \"LABEL_Schadensersatzhoehe_Range\": \"> 15000\"\n",
      "  }\n",
      "]\n",
      "```\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nbatch_file_path = \"gemini_batch_input_lg_comprehensive.jsonl\"\\nwith open(batch_file_path, \"w\", encoding=\"utf-8\") as f:\\n    for _, row in df_lg.iterrows():\\n        payload = {\\n            \"custom_id\": f\"case_{row[\\'case_id\\']}\",\\n            \"contents\": [{\\n                \"role\": \"user\",\\n                \"parts\": [{\"text\": f\"Kopf: {row[\\'head\\']}\\nTenor: {row[\\'tenor\\']}\\n\\n{COMPRE_PROMPT}\"}]\\n            }]\\n        }\\n        f.write(json.dumps(payload) + \"\\n\")\\n\\n# BATCH-JOB STARTEN\\nprint(\"Lade Batch-Datei hoch...\")\\ninput_file = genai.upload_file(path=batch_file_path, mime_type=\"application/jsonl\")\\nbatch_job = genai.create_batch_job(\\n    model=\"models/gemini-1.5-pro\",\\n    input_file=input_file.name,\\n    output_file_name=\"ergebnisse_diesel_detailed\"\\n)\\nprint(f\"Batch-Job gestartet: {batch_job.name}\")\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "\n",
    "# --- 1. SETUP & EINLESEN ---\n",
    "# Hinweis: DATA_DIR und files müssen in deiner Umgebung definiert sein\n",
    "rows = []\n",
    "for fn in files:\n",
    "    case_id = fn.replace(\".txt\", \"\")\n",
    "    with open(os.path.join(DATA_DIR, fn), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        text = f.read()\n",
    "    rows.append({\"case_id\": case_id, \"text\": text})\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# --- 2. TEXT-EXTRAKTION ---\n",
    "df[\"head\"] = df[\"text\"].str.slice(0, 8000)\n",
    "\n",
    "def extract_tenor(text: str) -> str:\n",
    "    if not isinstance(text, str): return \"\"\n",
    "    m_start = re.search(r\"\\bTenor\\b\", text, flags=re.IGNORECASE)\n",
    "    if not m_start: return \"\"\n",
    "    start = m_start.end()\n",
    "    m_end = re.search(r\"\\b(Tatbestand|Gründe|Gruende|Entscheidungsgründe|Entscheidungsgruende)\\b\", \n",
    "                      text[start:], flags=re.IGNORECASE)\n",
    "    end = start + m_end.start() if m_end else min(len(text), start + 8000)\n",
    "    return text[start:end].strip()\n",
    "\n",
    "df[\"tenor\"] = df[\"text\"].apply(extract_tenor)\n",
    "\n",
    "# --- 3. LG-FILTER (REGEX) ---\n",
    "# Fokus auf Landesgerichtsurteile gemäß Aufgabenstellung [cite: 21]\n",
    "lg_pattern = r\"\\bLandgericht\\b|\\bLG\\s+[A-ZÄÖÜa-zäöü]+\"\n",
    "df[\"is_landgericht\"] = df[\"head\"].str.contains(lg_pattern, case=False, regex=True, na=False)\n",
    "df_lg = df[df[\"is_landgericht\"] == True].copy()\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(f\"STATISTIK\")\n",
    "print(f\"Gesamt eingelesen: {len(df)}\")\n",
    "print(f\"Gefilterte LGs:    {len(df_lg)}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# --- 4. DEFINITION DES UMFASSENDEN PROMPTS ---\n",
    "COMPREHENSIVE_PROMPT = \"\"\"\n",
    "Lies den Text genau und analysiere das vorliegende Gerichtsurteil. Extrahiere die folgenden Informationen präzise. Falls eine Information im Text nicht auffindbar ist, gib \"null\" an.\n",
    "\n",
    "### Extraktions-Anweisungen:\n",
    "\n",
    "1. **Input-Variablen (Features):**\n",
    "    * **Dieselmotor_Typ (String):** Welcher Motortyp (z. B. EA 189, EA 288)?\n",
    "    * **Art_Abschalteinrichtung (String):** Beschreibung der genannten Abschalteinrichtung.\n",
    "    * **KBA_Rueckruf (Boolean):** Verpflichtender Rückruf des Kraftfahrt-Bundesamtes? (true/false)\n",
    "    * **Fahrzeugstatus (String):** \"Neuwagen\" oder \"Gebrauchtwagen\"?\n",
    "    * **Fahrzeugmodell_Baureihe (String):** Bezeichnung des Modells.\n",
    "    * **Update_Status (Boolean/null):** Software-Update aufgespielt? (true/false/null)\n",
    "    * **Kilometerstand_Kauf (Integer):** Stand bei Erwerb.\n",
    "    * **Kilometerstand_Klageerhebung (Integer):** Stand bei Klageeinreichung.\n",
    "    * **Erwartete_Gesamtlaufleistung (Integer):** Vom Gericht angenommene Gesamtlaufleistung.\n",
    "    * **Kaufdatum (Date):** Format: YYYY-MM-DD.\n",
    "    * **Uebergabedatum (Date):** Format: YYYY-MM-DD.\n",
    "    * **Datum_Klageerhebung (Date):** Format: YYYY-MM-DD.\n",
    "    * **Nachweis_Aufklaerung (Boolean):** Gab es eine Anlage zum Kaufvertrag über die Software? (true/false)\n",
    "    * **Beklagten_Typ (String):** \"Händler\" oder \"Hersteller\".\n",
    "    * **Datum_Urteil (Date):** Format: YYYY-MM-DD.\n",
    "    * **Kaufpreis (Float):** Betrag in Euro (ohne Zinsen). (z.B. 23542,23 EUR)\n",
    "    * **Nacherfuellungsverlangen_Fristsetzung (String):** \"Ja\", \"Nein\", \"Entbehrlich\".\n",
    "    * **Klageziel (String):** z. B. \"Rückabwicklung\", \"Minderung\", \"Schadensersatz\".\n",
    "    * **Rechtsgrundlage (String):** z. B. § 437 BGB oder § 826 BGB.\n",
    "\n",
    "2. **Zielvariablen (Labeling):** Klassifiziere das Ergebnis im Tenor für die Zielvariablen absolut eindeutig. \n",
    "    * **LABEL_Anspruch_Schadensersatz (Boolean):** Kläger erhält Schadensersatz? (true/false) [cite: 27, 28]\n",
    "    * **LABEL_Schadensersatzhoehe_Betrag (Float):** Zugesprochener Betrag in Euro (ohne Zinsen). [cite: 30]\n",
    "    * **LABEL_Schadensersatzhoehe_Range (String):** Einordnung: \"< 5000\", \"5000-10000\", \"10001-15000\", \"> 15000\", \"Klage abgewiesen\".\n",
    "\n",
    "3. **Kategorisierung \"Sonstige\":**\n",
    "    Sollte im Tenor nichts über Abweisung oder Schadensersatz stehen (sondern Streitwertfestsetzung, Ablehnungsgesuche etc.), kategorisiere als \"Sonstige\"[cite: 33, 34]. Gib im Feld \"Urteil_Anmerkung\" die Begründung an.\n",
    "\n",
    "### Ausgabeformat:\n",
    "Antworte AUSSCHLIESSLICH als JSON-Liste mit einem Eintrag. Ignoriere Streitwerte und Zinsen.\n",
    "\"\"\"\n",
    "\n",
    "# --- 5. TEST: EINZELNES URTEIL PRÜFEN ---\n",
    "api_key = \"\" # Oder os.getenv(\"GEMINI_API_KEY\")\n",
    "genai.configure(api_key=api_key)\n",
    "model = genai.GenerativeModel(\"models/gemini-2.5-flash\")\n",
    "\n",
    "if not df_lg.empty:\n",
    "    test_row = df_lg.iloc[1]\n",
    "    test_input = f\"Kopf: {test_row['head']}\\nTenor: {test_row['tenor']}\\n\\n{COMPREHENSIVE_PROMPT}\"\n",
    "    \n",
    "    print(f\"Teste Extraktion für Case: {test_row['case_id']}...\")\n",
    "    response = model.generate_content(test_input)\n",
    "    print(\"\\nErgebnis des Einzeltests:\")\n",
    "    print(response.text)\n",
    "else:\n",
    "    print(\"Keine LG-Urteile zum Testen gefunden.\")\n",
    "\n",
    "# --- 6. BATCH-DATEI ERSTELLEN (AKTUELL AUSKOMMENTIERT) ---\n",
    "\"\"\"\n",
    "batch_file_path = \"gemini_batch_input_lg_comprehensive.jsonl\"\n",
    "with open(batch_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for _, row in df_lg.iterrows():\n",
    "        payload = {\n",
    "            \"custom_id\": f\"case_{row['case_id']}\",\n",
    "            \"contents\": [{\n",
    "                \"role\": \"user\",\n",
    "                \"parts\": [{\"text\": f\"Kopf: {row['head']}\\nTenor: {row['tenor']}\\n\\n{COMPRE_PROMPT}\"}]\n",
    "            }]\n",
    "        }\n",
    "        f.write(json.dumps(payload) + \"\\n\")\n",
    "\n",
    "# BATCH-JOB STARTEN\n",
    "print(\"Lade Batch-Datei hoch...\")\n",
    "input_file = genai.upload_file(path=batch_file_path, mime_type=\"application/jsonl\")\n",
    "batch_job = genai.create_batch_job(\n",
    "    model=\"models/gemini-1.5-pro\",\n",
    "    input_file=input_file.name,\n",
    "    output_file_name=\"ergebnisse_diesel_detailed\"\n",
    ")\n",
    "print(f\"Batch-Job gestartet: {batch_job.name}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "106dd774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modell-Name: models/gemini-2.5-flash\n",
      "Modell-Name: models/gemini-2.5-pro\n",
      "Modell-Name: models/gemini-2.0-flash-exp\n",
      "Modell-Name: models/gemini-2.0-flash\n",
      "Modell-Name: models/gemini-2.0-flash-001\n",
      "Modell-Name: models/gemini-2.0-flash-lite-001\n",
      "Modell-Name: models/gemini-2.0-flash-lite\n",
      "Modell-Name: models/gemini-2.0-flash-lite-preview-02-05\n",
      "Modell-Name: models/gemini-2.0-flash-lite-preview\n",
      "Modell-Name: models/gemini-exp-1206\n",
      "Modell-Name: models/gemini-2.5-flash-preview-tts\n",
      "Modell-Name: models/gemini-2.5-pro-preview-tts\n",
      "Modell-Name: models/gemma-3-1b-it\n",
      "Modell-Name: models/gemma-3-4b-it\n",
      "Modell-Name: models/gemma-3-12b-it\n",
      "Modell-Name: models/gemma-3-27b-it\n",
      "Modell-Name: models/gemma-3n-e4b-it\n",
      "Modell-Name: models/gemma-3n-e2b-it\n",
      "Modell-Name: models/gemini-flash-latest\n",
      "Modell-Name: models/gemini-flash-lite-latest\n",
      "Modell-Name: models/gemini-pro-latest\n",
      "Modell-Name: models/gemini-2.5-flash-lite\n",
      "Modell-Name: models/gemini-2.5-flash-image\n",
      "Modell-Name: models/gemini-2.5-flash-preview-09-2025\n",
      "Modell-Name: models/gemini-2.5-flash-lite-preview-09-2025\n",
      "Modell-Name: models/gemini-3-pro-preview\n",
      "Modell-Name: models/gemini-3-flash-preview\n",
      "Modell-Name: models/gemini-3-pro-image-preview\n",
      "Modell-Name: models/nano-banana-pro-preview\n",
      "Modell-Name: models/gemini-robotics-er-1.5-preview\n",
      "Modell-Name: models/gemini-2.5-computer-use-preview-10-2025\n",
      "Modell-Name: models/deep-research-pro-preview-12-2025\n"
     ]
    }
   ],
   "source": [
    "for m in genai.list_models():\n",
    "    if 'generateContent' in m.supported_generation_methods:\n",
    "        print(f\"Modell-Name: {m.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5af64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in c:\\users\\lena\\documents\\github\\ds_law\\.venv\\lib\\site-packages (0.8.6)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\lena\\documents\\github\\ds_law\\.venv\\lib\\site-packages (from google-generativeai) (2.29.0)\n",
      "Requirement already satisfied: pydantic in c:\\users\\lena\\documents\\github\\ds_law\\.venv\\lib\\site-packages (from google-generativeai) (2.12.5)\n",
      "Requirement already satisfied: protobuf in c:\\users\\lena\\documents\\github\\ds_law\\.venv\\lib\\site-packages (from google-generativeai) (5.29.5)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\lena\\documents\\github\\ds_law\\.venv\\lib\\site-packages (from google-generativeai) (2.47.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\lena\\documents\\github\\ds_law\\.venv\\lib\\site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in c:\\users\\lena\\documents\\github\\ds_law\\.venv\\lib\\site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\lena\\documents\\github\\ds_law\\.venv\\lib\\site-packages (from google-generativeai) (2.188.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\lena\\documents\\github\\ds_law\\.venv\\lib\\site-packages (from google-generativeai) (4.15.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\lena\\documents\\github\\ds_law\\.venv\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.27.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\lena\\documents\\github\\ds_law\\.venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\lena\\documents\\github\\ds_law\\.venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\lena\\documents\\github\\ds_law\\.venv\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.5)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\lena\\documents\\github\\ds_law\\.venv\\lib\\site-packages (from google-api-core->google-generativeai) (1.72.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\lena\\documents\\github\\ds_law\\.venv\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\lena\\documents\\github\\ds_law\\.venv\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.3.0)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\users\\lena\\documents\\github\\ds_law\\.venv\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.31.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\lena\\documents\\github\\ds_law\\.venv\\lib\\site-packages (from pydantic->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\lena\\documents\\github\\ds_law\\.venv\\lib\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\lena\\documents\\github\\ds_law\\.venv\\lib\\site-packages (from pydantic->google-generativeai) (2.41.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\lena\\documents\\github\\ds_law\\.venv\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\lena\\documents\\github\\ds_law\\.venv\\lib\\site-packages (from google-api-core->google-generativeai) (1.76.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\users\\lena\\documents\\github\\ds_law\\.venv\\lib\\site-packages (from google-api-core->google-generativeai) (1.71.2)\n",
      "Requirement already satisfied: pyparsing<4,>=3.1 in c:\\users\\lena\\documents\\github\\ds_law\\.venv\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.3.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\lena\\documents\\github\\ds_law\\.venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lena\\documents\\github\\ds_law\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lena\\documents\\github\\ds_law\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2026.1.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\lena\\documents\\github\\ds_law\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lena\\documents\\github\\ds_law\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "STATISTIK (Dein Regex-Filter)\n",
      "Gesamt eingelesen: 2375\n",
      "Gefilterte LGs:    2088\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "import sys\n",
    "!{sys.executable} -m pip install -U google-generativeai\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "\n",
    "# --- 1. SETUP & EINLESEN ---\n",
    "rows = []\n",
    "for fn in files:\n",
    "    case_id = fn.replace(\".txt\", \"\")\n",
    "    with open(os.path.join(DATA_DIR, fn), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        text = f.read()\n",
    "    rows.append({\"case_id\": case_id, \"text\": text})\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# --- 2. TEXT-EXTRAKTION ---\n",
    "df[\"head\"] = df[\"text\"].str.slice(0, 8000)\n",
    "\n",
    "def extract_tenor(text: str) -> str:\n",
    "    if not isinstance(text, str): return \"\"\n",
    "    m_start = re.search(r\"\\bTenor\\b\", text, flags=re.IGNORECASE)\n",
    "    if not m_start: return \"\"\n",
    "    start = m_start.end()\n",
    "    m_end = re.search(r\"\\b(Tatbestand|Gründe|Gruende|Entscheidungsgründe|Entscheidungsgruende)\\b\", \n",
    "                      text[start:], flags=re.IGNORECASE)\n",
    "    end = start + m_end.start() if m_end else min(len(text), start + 8000)\n",
    "    return text[start:end].strip()\n",
    "\n",
    "df[\"tenor\"] = df[\"text\"].apply(extract_tenor)\n",
    "\n",
    "\n",
    "# --- 3. DEIN PRÄZISER LG-FILTER ---\n",
    "# Wir nutzen dein Muster und filtern den Dataframe sofort\n",
    "lg_pattern = r\"\\bLandgericht\\b|\\bLG\\s+[A-ZÄÖÜa-zäöü]+\"\n",
    "df[\"is_landgericht\"] = df[\"head\"].str.contains(lg_pattern, case=False, regex=True, na=False)\n",
    "\n",
    "# Nur die Landgerichte in einen neuen Dataframe extrahieren\n",
    "df_lg = df[df[\"is_landgericht\"] == True].copy()\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(f\"STATISTIK (Dein Regex-Filter)\")\n",
    "print(f\"Gesamt eingelesen: {len(df)}\")\n",
    "print(f\"Gefilterte LGs:    {len(df_lg)}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# --- 4. BATCH-DATEI ERSTELLEN ---\n",
    "PROMPT_TEXT = \"\"\"\n",
    "Analysiere den Text präzise:\n",
    "1. Gerichtstyp: Bestimme das Gericht (NUR 'LG' oder 'OLG').\n",
    "2. Geldbetrag oder Abweisung: Betrag in Euro oder 'Klage abgewiesen'.\n",
    "3. Sonstige: 'Sonstige' bei Streitwertfestsetzungen.\n",
    "Antworte NUR als JSON: {\"Gerichtstyp\": \"LG/OLG\", \"Urteil\": \"Ergebnis\"}\n",
    "\"\"\"\n",
    "\n",
    "batch_file_path = \"gemini_batch_input_lg.jsonl\"\n",
    "with open(batch_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    # Wir nehmen nur die gefilterten LGs!\n",
    "    for _, row in df_lg.iterrows():\n",
    "        payload = {\n",
    "            \"custom_id\": f\"case_{row['case_id']}\",\n",
    "            \"contents\": [{\n",
    "                \"role\": \"user\",\n",
    "                \"parts\": [{\"text\": f\"Kopf: {row['head']}\\nTenor: {row['tenor']}\\n\\n{PROMPT_TEXT}\"}]\n",
    "            }]\n",
    "        }\n",
    "        f.write(json.dumps(payload) + \"\\n\")\n",
    "\n",
    "# --- 5. BATCH-JOB STARTEN (MIT VERSION-FIX) ---\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "if api_key:\n",
    "    genai.configure(api_key=api_key)\n",
    "    print(\"Lade Datei hoch...\")\n",
    "    input_file = genai.upload_file(path=batch_file_path, mime_type=\"application/jsonl\")\n",
    "    \n",
    "    # Da create_batch_job bei dir einen Fehler warf: \n",
    "    # Wir nutzen das Modell-Objekt direkt, das ist oft kompatibler\n",
    "    try:\n",
    "        model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "        # Falls dein SDK die Methode noch nicht kennt, hilft nur das Update im Terminal!\n",
    "        batch_job = genai.create_batch_job(\n",
    "            model=\"models/gemini-1.5-flash\",\n",
    "            input_file=input_file.name,\n",
    "            output_file_name=\"ergebnisse_diesel_final\"\n",
    "        )\n",
    "        print(f\"✓ Job erfolgreich gestartet! ID für Alina: {batch_job.name}\")\n",
    "    except AttributeError:\n",
    "        print(\"✗ FEHLER: Dein Paket 'google-generativeai' ist zu alt.\")\n",
    "        print(\"FIX: Tippe 'pip install -U google-generativeai' ins Terminal und RESTARTE den Kernel!\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d201e9",
   "metadata": {},
   "source": [
    "Die resultierende Datenstruktur umfasst 2375 gerichtliche Entscheidungen. Jede Zeile entspricht einem Urteil, das eindeutig über eine Fall-ID referenziert ist. Zusätzlich wurde die Textlänge der Urteile berechnet, um eine Plausibilitätsprüfung der Datengrundlage zu ermöglichen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0863fe26",
   "metadata": {},
   "source": [
    "### Schritt 3: Prompt zur Extrahierung der Zielvariablen\n",
    "Filterung nochmal nach LG (damit wir alle abfangen, die wir vorher nicht abfangen konnten) + Training in Batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2dbedc",
   "metadata": {},
   "source": [
    "### Schritt 1C: Einschränkung auf Entscheidungen der Landgerichte\n",
    "\n",
    "Gemäß der Aufgabenstellung wird der Datensatz auf Urteile deutscher Landgerichte beschränkt. Hintergrund ist, dass unterschiedliche\n",
    "Gerichtsebenen teils abweichende rechtliche Maßstäbe anwenden, was zu inkonsistenten Lernsituationen für das Modell führen kann. \n",
    "Zunächst wird heuristisch anhand typischer Gerichtsbezeichnungen im Kopfbereich der Entscheidung geprüft, ob es sich um ein Urteil eines deutschen Landgerichts handelt. Anschließend wird der thematische Bezug zum Dieselskandal anhand zentraler Schlüsselbegriffe identifiziert. Durch diese getrennte Markierung wird Transparenz über die Zusammensetzung des Datensatzes geschaffen und eine spätere Anpassung der Filterlogik ermöglicht, ohne frühzeitig Daten zu verwerfen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54abf8ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Lena\\Documents\\GitHub\\ds_law\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3811\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mpandas/_libs/index.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas/_libs/index.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'head'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m lg_pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbLandgericht\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb|\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbLG\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms+[A-ZÄÖÜa-zäöü]+\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_landgericht\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhead\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(lg_pattern, case\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_landgericht\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\n",
      "File \u001b[1;32mc:\\Users\\Lena\\Documents\\GitHub\\ds_law\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4113\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4115\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\Lena\\Documents\\GitHub\\ds_law\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3815\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3816\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3817\u001b[0m     ):\n\u001b[0;32m   3818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3820\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3821\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3822\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3823\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'head'"
     ]
    }
   ],
   "source": [
    "# lg_pattern = r\"\\bLandgericht\\b|\\bLG\\s+[A-ZÄÖÜa-zäöü]+\"\n",
    "\n",
    "# df[\"is_landgericht\"] = df[\"head\"].str.contains(lg_pattern, case=False, regex=True)\n",
    "\n",
    "# df[\"is_landgericht\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1fe770",
   "metadata": {},
   "source": [
    "### Schritt 1D: Finaler Analyse-Datensatz \n",
    "Der finale Analyse-Datensatz umfasst ausschließlich dieselbezogene Landgerichtsurteile und dient als Grundlage für die weitere Modellierung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e3af01",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'is_diesel_case'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\humme\\OneDrive\\Dokumente\\Uni Ulm\\ds_law\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3641\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3640\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3641\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3642\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:168\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:197\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7668\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7676\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'is_diesel_case'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_analysis = df[\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mis_diesel_case\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m & df[\u001b[33m\"\u001b[39m\u001b[33mis_landgericht\u001b[39m\u001b[33m\"\u001b[39m]].copy()\n\u001b[32m      2\u001b[39m df_analysis.shape\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\humme\\OneDrive\\Dokumente\\Uni Ulm\\ds_law\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4378\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4376\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4377\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4378\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4379\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4380\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\humme\\OneDrive\\Dokumente\\Uni Ulm\\ds_law\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3648\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3643\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3644\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3645\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3646\u001b[39m     ):\n\u001b[32m   3647\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3648\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3649\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3650\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3651\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3652\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3653\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'is_diesel_case'"
     ]
    }
   ],
   "source": [
    "#df_analysis = df[df[\"is_diesel_case\"] & df[\"is_landgericht\"]].copy()\n",
    "#df_analysis.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b418237",
   "metadata": {},
   "source": [
    "Zur methodischen Absicherung wurde überprüft, ob alle Dokumente entsprechende Schlüsselbegriffe enthalten. Die Analyse bestätigt, dass nahezu alle Urteile einen expliziten Bezug zum Dieselskandal aufweisen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d99411",
   "metadata": {},
   "source": [
    "### Schritt 2: Definition der Zielvariable\n",
    "\n",
    "Ziel der Analyse ist die Vorhersage, ob in einem Urteil ein Schadensersatz zugesprochen wurde oder nicht. \n",
    "Die Zielvariable wird binär modelliert (1 = Schadensersatz zugesprochen, 0 = kein Schadensersatz). \n",
    "Da strukturierte Labels nicht vorliegen, erfolgt die Ableitung regelbasiert anhand typischer Formulierungen im Tenor der Entscheidung.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f59973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0.0    1026\n",
       "1.0     715\n",
       "NaN     315\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def infer_target(tenor: str):\n",
    "    if not isinstance(tenor, str) or tenor.strip() == \"\":\n",
    "        return None\n",
    "\n",
    "    t = tenor.lower()\n",
    "\n",
    "    # Verurteilung zur Zahlung → Schadensersatz\n",
    "    positive_patterns = [\n",
    "        r\"wird verurteilt.*\\bzu zahlen\\b\",\n",
    "        r\"wird verurteilt.*\\ban den kläger\\b.*\\bzu zahlen\\b\",\n",
    "        r\"wird verurteilt.*\\ban die klägerin\\b.*\\bzu zahlen\\b\",\n",
    "        r\"\\bzu zahlen\\b.*(\\bEUR\\b|€)\",\n",
    "        r\"(\\bEUR\\b|€).*?\\bzu zahlen\\b\",\n",
    "        r\"schadensersatz\"\n",
    "    ]\n",
    "    if any(re.search(p, t, flags=re.DOTALL) for p in positive_patterns):\n",
    "        return 1\n",
    "\n",
    "    # Klage abgewiesen → kein Schadensersatz\n",
    "    negative_patterns = [\n",
    "        \"die klage wird abgewiesen\",\n",
    "        \"klage wird abgewiesen\",\n",
    "        \"die berufung wird zurückgewiesen\",\n",
    "        \"berufung wird zurückgewiesen\",\n",
    "        \"wird zurückgewiesen\",\n",
    "        \"wird verworfen\",\n",
    "        \"als unzulässig verworfen\",\n",
    "        \"wird als unzulässig verworfen\",\n",
    "    ]\n",
    "    if any(p in t for p in negative_patterns):\n",
    "        return 0\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "df_analysis[\"target\"] = df_analysis[\"tenor\"].apply(infer_target)\n",
    "df_analysis[\"target\"].value_counts(dropna=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a77a34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>target</th>\n",
       "      <th>tenor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>2274949</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1. Die Berufung der Klagepartei gegen das Urte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2074</th>\n",
       "      <td>2453299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1. Die Klage wird abgewiesen.2. Die Kosten des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319</th>\n",
       "      <td>2343116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1. Die Berufung des Klägers gegen das Urteil d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>2350176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Die Berufung der Klägerin gegen das am 30. Okt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>2306384</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Auf die Berufung der Beklagten wird das am 31....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>2205120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Die Klage wird abgewiesen.Die Klägerin trägt d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>2270509</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Die Klage wird abgewiesen.Die Kosten des Recht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>2394941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Die Berufung des Klägers gegen das am 16. Apri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>2378432</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1. Die Klage wird abgewiesen.2. Der Kläger hat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>2297195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1. Auf die Berufung der Beklagten wird das End...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>2297581</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1. Die Beklagte wird verurteilt, an den Kläger...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531</th>\n",
       "      <td>2363698</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1. Das Versäumnisurteil vom 5. November 2020 w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>2388563</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Die Berufung des Klägers gegen das am 08.12.20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>2260476</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I.\\t Die Beklagte wird verurteilt, an die Kläg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2286</th>\n",
       "      <td>2477665</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Die Berufung des Klägers gegen das Urteil der ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1414</th>\n",
       "      <td>2352164</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Auf die Berufung des Klägers wird das Urteil d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2148674</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1. Die Beklagte wird verurteilt, an den Kläger...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1614</th>\n",
       "      <td>2380506</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Die Berufung des Klägers gegen das am 20.10.20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>2294961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1. Die Berufung des Klägers gegen das Urteil d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1827</th>\n",
       "      <td>2395206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Die Berufung des Klägers gegen das Urteil des ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      case_id  target                                              tenor\n",
       "704   2274949     0.0  1. Die Berufung der Klagepartei gegen das Urte...\n",
       "2074  2453299     0.0  1. Die Klage wird abgewiesen.2. Die Kosten des...\n",
       "1319  2343116     0.0  1. Die Berufung des Klägers gegen das Urteil d...\n",
       "1396  2350176     0.0  Die Berufung der Klägerin gegen das am 30. Okt...\n",
       "984   2306384     1.0  Auf die Berufung der Beklagten wird das am 31....\n",
       "398   2205120     0.0  Die Klage wird abgewiesen.Die Klägerin trägt d...\n",
       "636   2270509     0.0  Die Klage wird abgewiesen.Die Kosten des Recht...\n",
       "1825  2394941     0.0  Die Berufung des Klägers gegen das am 16. Apri...\n",
       "1586  2378432     0.0  1. Die Klage wird abgewiesen.2. Der Kläger hat...\n",
       "858   2297195     0.0  1. Auf die Berufung der Beklagten wird das End...\n",
       "876   2297581     1.0  1. Die Beklagte wird verurteilt, an den Kläger...\n",
       "1531  2363698     1.0  1. Das Versäumnisurteil vom 5. November 2020 w...\n",
       "1726  2388563     0.0  Die Berufung des Klägers gegen das am 08.12.20...\n",
       "576   2260476     1.0  I.\\t Die Beklagte wird verurteilt, an die Kläg...\n",
       "2286  2477665     0.0  Die Berufung des Klägers gegen das Urteil der ...\n",
       "1414  2352164     1.0  Auf die Berufung des Klägers wird das Urteil d...\n",
       "88    2148674     1.0  1. Die Beklagte wird verurteilt, an den Kläger...\n",
       "1614  2380506     0.0  Die Berufung des Klägers gegen das am 20.10.20...\n",
       "791   2294961     0.0  1. Die Berufung des Klägers gegen das Urteil d...\n",
       "1827  2395206     0.0  Die Berufung des Klägers gegen das Urteil des ..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_analysis[df_analysis[\"target\"].notna()][[\"case_id\",\"target\",\"tenor\"]].sample(20, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb117fbb",
   "metadata": {},
   "source": [
    "Die regelbasierte Ableitung der Zielvariable wurde anhand einer zufälligen Stichprobe überprüft, wobei ausschließlich der jeweilige Tenor betrachtet wurde."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb435d9",
   "metadata": {},
   "source": [
    "**Umgang mit unklaren Fällen**\n",
    "\n",
    "Nicht alle Urteile enthalten eine eindeutig identifizierbare Tenorformulierung, aus der zweifelsfrei hervorgeht, ob ein Schadensersatz zugesprochen wurde oder nicht (z. B. bei Vergleichen oder rein prozessualen Entscheidungen).  \n",
    "Diese Fälle werden in der Zielvariable als *unklar* (`None`) gekennzeichnet und für die weitere Modellierung ausgeschlossen.  \n",
    "Durch diese Einschränkung wird sichergestellt, dass das Modell ausschließlich auf eindeutig gelabelten Entscheidungen trainiert wird und Verzerrungen durch unsichere Zuordnungen vermieden werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47abee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

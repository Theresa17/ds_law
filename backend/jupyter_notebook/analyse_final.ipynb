{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f87c4b39",
   "metadata": {},
   "source": [
    "## 1. Datenimport und Initialisierung\n",
    "\n",
    "In diesem Abschnitt werden die OpenJur-Urteilstexte aus dem Datenverzeichnis eingelesen und die technische Datenbasis f√ºr die nachfolgenden Verarbeitungsschritte geschaffen. Dazu werden die ben√∂tigten Bibliotheken importiert und die verf√ºgbaren Textdateien identifiziert.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972de4e7",
   "metadata": {},
   "source": [
    "### 1.1 Import der ben√∂tigten Bibliotheken\n",
    "\n",
    "Zu Beginn werden die f√ºr die weitere Verarbeitung erforderlichen Python-Bibliotheken importiert. Diese umfassen Funktionen f√ºr Dateizugriffe, regul√§re Ausdr√ºcke, Datenverarbeitung mit Pandas sowie den Export der Ergebnisse im JSON-Format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58f86b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61a736b",
   "metadata": {},
   "source": [
    "### 1.2 Einlesen der OpenJur-Urteilstexte \n",
    "\n",
    "In diesem Schritt werden alle identifizierten Urteilstexte aus dem Datenverzeichnis eingelesen. Jede Datei wird √ºber den Dateinamen einer eindeutigen Fallkennung (`case_id`) zugeordnet. Die Texte bilden die Rohdatenbasis f√ºr die nachfolgenden Extraktions- und Filterprozesse. Der Datenpfad wird im Code parametriert (`DATA_DIR`), um eine reproduzierbare Ausf√ºhrung zu gew√§hrleisten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bef8dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pfad: c:\\Users\\humme\\OneDrive\\Dokumente\\Uni Ulm\\ds_law\\backend\\data\\Gerichtsurteile_Openjur\n",
      "Anzahl .txt: 2375\n",
      "Erste 10 Dateien: ['2090187.txt', '2112111.txt', '2112115.txt', '2112117.txt', '2112118.txt', '2112119.txt', '2112121.txt', '2112123.txt', '2124977.txt', '2126821.txt']\n"
     ]
    }
   ],
   "source": [
    "# (.txt) Dateien einlesen\n",
    "DATA_DIR = \"../data/Gerichtsurteile_Openjur\" \n",
    "files = [f for f in os.listdir(DATA_DIR) if f.lower().endswith(\".txt\")]\n",
    "\n",
    "print(\"Pfad:\", os.path.abspath(DATA_DIR))\n",
    "print(\"Anzahl .txt:\", len(files))\n",
    "print(\"Erste 10 Dateien:\", files[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d494b356",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed94d8a",
   "metadata": {},
   "source": [
    "## 2. Extraktion relevanter Urteilsbestandteile und Selektion der Landgerichtsurteile\n",
    "\n",
    "In diesem Abschnitt werden die eingelesenen Urteilstexte weiterverarbeitet, um f√ºr die nachfolgende Analyse relevante Textbestandteile gezielt zu extrahieren. Hierzu z√§hlen insbesondere ein begrenzter Kopfbereich zur Voranalyse sowie der Tenor als Kern der gerichtlichen Entscheidung. Die strukturierte Aufbereitung dieser Textsegmente bildet die Grundlage f√ºr Filter-, Klassifikations- und Extraktionsschritte in den folgenden Abschnitten."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c915ba",
   "metadata": {},
   "source": [
    "### 2.1 Aufbau des DataFrames und Extraktion eines Kopfbereichs\n",
    "\n",
    "Die eingelesenen Texte werden in einem DataFrame (`df`) gespeichert. Zus√§tzlich wird ein begrenzter Kopfbereich (`head`) aus den ersten Zeichen extrahiert, da strukturelle Metadaten wie Gerichtstyp, Entscheidungsart und Zitierzeilen typischerweise am Anfang des Dokuments auftreten. Dieser Kopfbereich dient als effizienter Suchraum f√ºr die sp√§tere Identifikation von Landgerichtsurteilen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28198986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gesamt eingelesen: 2375\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "for fn in files:\n",
    "    case_id = fn.replace(\".txt\", \"\")\n",
    "    path = os.path.join(DATA_DIR, fn)\n",
    "    with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        text = f.read()\n",
    "    rows.append({\"case_id\": case_id, \"text\": text})\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(\"Gesamt eingelesen:\", len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99a88600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head-L√§nge (Beispiel): 8000\n"
     ]
    }
   ],
   "source": [
    "HEAD_CHARS = 8000\n",
    "df[\"head\"] = df[\"text\"].astype(str).str.slice(0, HEAD_CHARS)\n",
    "\n",
    "print(\"Head-L√§nge (Beispiel):\", len(df.loc[0, \"head\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b62f66",
   "metadata": {},
   "source": [
    "### 2.2 Extraktion des Tenors\n",
    "\n",
    "Der Tenor enth√§lt die eigentliche gerichtliche Entscheidung und ist daher f√ºr die inhaltliche Bewertung besonders relevant. Mithilfe regul√§rer Ausdr√ºcke wird der Textabschnitt zwischen der √úberschrift ‚ÄûTenor‚Äú und den nachfolgenden Abschnitten (z. B. ‚ÄûTatbestand‚Äú oder ‚ÄûGr√ºnde‚Äú) extrahiert und in einer separaten Spalte gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6fae0b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tenor vorhanden: 2362 von 2375\n"
     ]
    }
   ],
   "source": [
    "def extract_tenor(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    m_start = re.search(r\"\\bTenor\\b\", text, flags=re.IGNORECASE)\n",
    "    if not m_start:\n",
    "        return \"\"\n",
    "\n",
    "    start = m_start.end()\n",
    "\n",
    "    # Begrenztes Suchfenster nach dem Tenor (robuster gegen Navigation)\n",
    "    window = text[start:start + 20000]\n",
    "\n",
    "    m_end = re.search(\n",
    "        r\"\\b(Tatbestand|Gr√ºnde|Gruende|Entscheidungsgr√ºnde|Entscheidungsgruende)\\b\",\n",
    "        window,\n",
    "        flags=re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    end = start + m_end.start() if m_end else min(len(text), start + 8000)\n",
    "    return text[start:end].strip()\n",
    "df[\"tenor\"] = df[\"text\"].apply(extract_tenor)\n",
    "print(\"Tenor vorhanden:\", (df[\"tenor\"].str.len() > 0).sum(), \"von\", len(df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2481ec6a",
   "metadata": {},
   "source": [
    "### 2.3 Identifikation von Landgerichtsurteilen (LG)\n",
    "\n",
    "Die Selektion der Landgerichtsurteile erfolgt anhand einer OpenJur-spezifischen Zitierzeile im Kopfbereich (Regex: ‚ÄûEinfach‚Äú gefolgt von ‚ÄûLG‚Äú). Auf dieser Grundlage wird eine boolesche Variable erzeugt und der Teilkorpus df_lg gebildet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f6ff89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "‚úÖ Echte LG-Urteile (√ºber Zitierzeile): 1189\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Wir suchen nach der Zeile, die mit \"Einfach\" beginnt, gefolgt von \"LG\"\n",
    "# Der Regex r\"Einfach\\s*\\n\\s*LG\" stellt sicher, dass LG direkt darunter steht\n",
    "pattern_zitierung_lg = r\"Einfach\\s*\\n\\s*LG\"\n",
    "\n",
    "# Wir wenden das auf die Spalte an, die den Kopftext enth√§lt\n",
    "df[\"is_landgericht\"] = df[\"head\"].str.contains(pattern_zitierung_lg, regex=True, na=False)\n",
    "\n",
    "# Jetzt erstellen wir den sauberen Dataframe\n",
    "df_lg = df[df[\"is_landgericht\"] == True].copy()\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(f\"‚úÖ Echte LG-Urteile (√ºber Zitierzeile): {len(df_lg)}\")\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85194c82",
   "metadata": {},
   "source": [
    "### 2.4 Segmentierung der Urteile in juristische Abschnitte\n",
    "F√ºr die sp√§tere Extraktion werden die Urteile in juristisch sinnvolle Teile zerlegt: Rubrum, Tenor, Tatbestand und Entscheidungsgr√ºnde. Dadurch kann das Modell gezielt relevante Passagen verarbeiten.\n",
    "Die Segmentierung dient dazu, sp√§tere Analysen gezielt auf entscheidungsrelevante Abschnitte (insb. Tenor und Entscheidungsgr√ºnde) zu fokussieren.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "870d2bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_judgment(text):\n",
    "    \"\"\"\n",
    "    Teilt ein Urteil in Rubrum, Tenor, Tatbestand und Entscheidungsgr√ºnde auf.\n",
    "    \"\"\"\n",
    "    segments = {\n",
    "        \"rubrum\": \"\",\n",
    "        \"tenor\": \"\",\n",
    "        \"tatbestand\": \"\",\n",
    "        \"entscheidungsgruende\": \"\"\n",
    "    }\n",
    "    \n",
    "    # Muster f√ºr die Abschnitts√ºberschriften\n",
    "    # Das Rubrum ist alles vor dem Tenor\n",
    "    m_tenor = re.search(r\"\\bTenor\\b\", text, re.IGNORECASE)\n",
    "    m_tatbestand = re.search(r\"\\bTatbestand\\b\", text, re.IGNORECASE)\n",
    "    m_gruende = re.search(r\"\\b(Entscheidungsgr√ºnde|Gr√ºnde)\\b\", text, re.IGNORECASE)\n",
    "    \n",
    "    if m_tenor:\n",
    "        segments[\"rubrum\"] = text[:m_tenor.start()].strip()\n",
    "        \n",
    "        # Tenor bis Tatbestand\n",
    "        if m_tatbestand:\n",
    "            segments[\"tenor\"] = text[m_tenor.end():m_tatbestand.start()].strip()\n",
    "            \n",
    "            # Tatbestand bis Gr√ºnde\n",
    "            if m_gruende:\n",
    "                segments[\"tatbestand\"] = text[m_tatbestand.end():m_gruende.start()].strip()\n",
    "                segments[\"entscheidungsgruende\"] = text[m_gruende.end():].strip()\n",
    "            else:\n",
    "                segments[\"tatbestand\"] = text[m_tatbestand.end():].strip()\n",
    "        else:\n",
    "            # Falls kein Tatbestand gefunden wird, Tenor bis zum Ende oder Gr√ºnden\n",
    "            if m_gruende:\n",
    "                segments[\"tenor\"] = text[m_tenor.end():m_gruende.start()].strip()\n",
    "                segments[\"entscheidungsgruende\"] = text[m_gruende.end():].strip()\n",
    "            else:\n",
    "                segments[\"tenor\"] = text[m_tenor.end():].strip()\n",
    "                \n",
    "    return segments\n",
    "\n",
    "# Beispielanwendung auf den Dataframe\n",
    "df_lg['segments'] = df_lg['text'].apply(split_judgment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78144122",
   "metadata": {},
   "source": [
    "## 3 Prompt-Generierung und Pilotierung der LLM-Extraktion (Gemini Batch)\n",
    "Um API- und Token-Limits zu ber√ºcksichtigen, werden OpenJur-spezifische Navigationselemente aus dem Rubrum entfernt und alle Abschnitte in ihrer L√§nge begrenzt. Auf Basis dieser vorverarbeiteten Textsegmente wird ein standardisierter Prompt generiert, der die Extraktion der abgestimmten Variablen im JSON-Format steuert.\n",
    "Die segmentweise L√§ngenbegrenzung dient der Einhaltung von Token-Limits sowie der Reduktion von Kosten und Laufzeit, ohne entscheidungsrelevante Passagen (insb. Tenor und Entscheidungsgr√ºnde) zu verlieren.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d039d706",
   "metadata": {},
   "source": [
    "### 3.1 Aufbereitung der Segmente und Definition des Extraktions-Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af70046",
   "metadata": {},
   "source": [
    "Der Prompt wurde so konzipiert, dass er neben technischen Features (Motor, Kilometer) gezielt die Anforderungen der Aufgabenstellung erf√ºllt. Kernaspekte sind die Identifikation des Gerichtstyps sowie die Differenzierung der Zielvariable in Schadensersatz, Klageabweisung und prozessuale Sonderf√§lle (‚ÄûSonstige‚Äú). Durch explizite Anweisungen zum Ausschluss von Zinsen und zur Erkennung von Streitwertbeschl√ºssen wird eine hohe Datenqualit√§t f√ºr das anschlie√üende Machine Learning sichergestellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed232f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_rubrum(rubrum: str) -> str:\n",
    "    if not isinstance(rubrum, str):\n",
    "        return \"\"\n",
    "\n",
    "    blacklist = [\n",
    "        \"rechtsprechung\", \"aktuell\", \"trending\", \"filter\",\n",
    "        \"√ºber openjur\", \"spenden\", \"api\", \"hilfe\",\n",
    "        \"startseite\", \"bundesland\", \"gerichtsbarkeit\",\n",
    "        \"impressum\", \"datenschutz\", \"nutzungsbedingungen\",\n",
    "        \"fachzeitschriften\", \"suchen\", \"changelog\", \"einfach\",\n",
    "        \"json\", \"bibtex\", \"ris\"\n",
    "    ]\n",
    "\n",
    "    lines = []\n",
    "    for line in rubrum.splitlines():\n",
    "        l = line.strip().lower()\n",
    "        if not l:\n",
    "            continue\n",
    "        if any(b in l for b in blacklist):\n",
    "            continue\n",
    "        lines.append(line.strip())\n",
    "\n",
    "    return \"\\n\".join(lines[:5])   \n",
    "\n",
    "def slim_segments(segments):\n",
    "    return {\n",
    "        \"rubrum\": clean_rubrum(segments.get(\"rubrum\") or \"\")[:2500],\n",
    "        \"tenor\": (segments.get(\"tenor\") or \"\")[:4000],\n",
    "        \"tatbestand\": (segments.get(\"tatbestand\") or \"\")[:3500],\n",
    "        \"entscheidungsgruende\": (segments.get(\"entscheidungsgruende\") or \"\")[:7000],\n",
    "    }\n",
    "def get_gemini_prompt(segments):\n",
    "    \"\"\"\n",
    "    Erstellt den finalen Prompt basierend auf den Urteilssegmenten.\n",
    "    \"\"\"\n",
    "    s = slim_segments(segments)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Analysiere die folgenden Abschnitte eines Gerichtsurteils zum Dieselskandal und extrahiere die Variablen pr√§zise als JSON-Liste. \n",
    "\n",
    "### URTEILS-BESTANDTEILE:\n",
    "RUBRUM (Kopfbereich mit Gericht & Datum): \n",
    "{s['rubrum']}\n",
    "\n",
    "TENOR (Ergebnis): \n",
    "{s['tenor']}\n",
    "\n",
    "TATBESTAND (Sachverhalt): \n",
    "{s['tatbestand']}\n",
    "\n",
    "ENTSCHEIDUNGSGR√úNDE (Rechtliche W√ºrdigung): \n",
    "{s['entscheidungsgruende']}\n",
    "\n",
    "### EXTRAKTIONS-AUFGABE:\n",
    "Extrahiere folgende Variablen (bei Nichtfinden 'null' angeben):\n",
    "\n",
    "WICHTIG (Validierung & Datenqualit√§t):\n",
    "1) **Gerichtstyp** muss explizit angegeben werden (z.B. \"Landgericht\", \"Oberlandesgericht\", \"Amtsgericht\").  \n",
    "2) **Sonstige-Kategorie (prozessuale Dokumente):** Falls das Dokument **keine materielle Entscheidung √ºber einen Schadensersatzanspruch** enth√§lt (z.B. nur Streitwertfestsetzung/-beschluss, Prozesskostenhilfe/PKH, Kostenentscheidung ohne Sachentscheidung, Ablehnungsgesuch/Befangenheit, rein prozessualer Beschluss), dann setze zwingend:\n",
    "   - LABEL_Anspruch_Schadensersatz = false\n",
    "   - LABEL_Schadensersatzhoehe_Betrag = null\n",
    "   - LABEL_Schadensersatzhoehe_Range = \"Sonstige\"\n",
    "3) **Betrag ohne Zinsen:** LABEL_Schadensersatzhoehe_Betrag ist **ohne Zinsen/Verzugszinsen/Nebenforderungen** anzugeben.\n",
    "\n",
    "1. **Input-Variablen (Features):**\n",
    "   - Gerichtstyp\n",
    "   - Dieselmotor_Typ\n",
    "   - Art_Abschalteinrichtung\n",
    "   - KBA_Rueckruf\n",
    "   - Fahrzeugstatus\n",
    "   - Fahrzeugmodell_Baureihe\n",
    "   - Update_Status\n",
    "   - Kilometerstand_Kauf\n",
    "   - Kilometerstand_Klageerhebung\n",
    "   - Erwartete_Gesamtlaufleistung\n",
    "   - Kaufdatum\n",
    "   - Uebergabedatum\n",
    "   - Datum_Klageerhebung\n",
    "   - Nachweis_Aufklaerung\n",
    "   - Beklagten_Typ\n",
    "   - Datum_Urteil\n",
    "   - Kaufpreis\n",
    "   - Nacherfuellungsverlangen_Fristsetzung\n",
    "   - Klageziel\n",
    "   - Rechtsgrundlage\n",
    "\n",
    "2. **Zielvariablen (Labels):**\n",
    "   - LABEL_Anspruch_Schadensersatz\n",
    "   - LABEL_Schadensersatzhoehe_Betrag\n",
    "   - LABEL_Schadensersatzhoehe_Range\n",
    "\n",
    "### AUSGABEFORMAT:\n",
    "Antworte NUR mit einem validen JSON-Objekt in einer Liste:\n",
    "[{{\n",
    "  \"case_id\": \"...\",\n",
    "  \"Gerichtstyp\": null,\n",
    "  \"Dieselmotor_Typ\": null,\n",
    "  \"Art_Abschalteinrichtung\": null,\n",
    "  \"KBA_Rueckruf\": null,\n",
    "  \"Fahrzeugstatus\": null,\n",
    "  \"Fahrzeugmodell_Baureihe\": null,\n",
    "  \"Update_Status\": null,\n",
    "  \"Kilometerstand_Kauf\": null,\n",
    "  \"Kilometerstand_Klageerhebung\": null,\n",
    "  \"Erwartete_Gesamtlaufleistung\": null,\n",
    "  \"Kaufdatum\": null,\n",
    "  \"Uebergabedatum\": null,\n",
    "  \"Datum_Klageerhebung\": null,\n",
    "  \"Nachweis_Aufklaerung\": null,\n",
    "  \"Beklagten_Typ\": null,\n",
    "  \"Datum_Urteil\": null,\n",
    "  \"Kaufpreis\": null,\n",
    "  \"Nacherfuellungsverlangen_Fristsetzung\": null,\n",
    "  \"Klageziel\": null,\n",
    "  \"Rechtsgrundlage\": null,\n",
    "  \"LABEL_Anspruch_Schadensersatz\": null,\n",
    "  \"LABEL_Schadensersatzhoehe_Betrag\": null,\n",
    "  \"LABEL_Schadensersatzhoehe_Range\": null\n",
    "}}]\n",
    "\"\"\".strip()\n",
    "\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a84b7b",
   "metadata": {},
   "source": [
    "### 3.2 Erstellung eines Pilot-Inputs im JSONL-Format\n",
    "Zur technischen Validierung der Analysepipeline wird ein Pilotdatensatz erzeugt, der eine begrenzte Anzahl von Landgerichtsurteilen umfasst. F√ºr jedes ausgew√§hlte Urteil werden die zuvor definierten Textsegmente extrahiert, zu einem standardisierten Analyse-Prompt zusammengef√ºhrt und im JSONL-Format gespeichert. Diese Pilotdatei dient als Testeingabe f√ºr die nachgelagerte Verarbeitung √ºber die Gemini-API, bevor eine Skalierung auf den vollst√§ndigen Datensatz erfolgt.\n",
    "Der Pilot dient ausschlie√ülich der technischen Validierung der Prompt-Struktur und der Batch-Pipeline und ist nicht f√ºr eine inhaltliche Evaluation der Extraktionsergebnisse vorgesehen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f6ac57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Pilot erstellt: gemini_batch_input_pilot_10.jsonl\n"
     ]
    }
   ],
   "source": [
    "PILOT_N = 10\n",
    "pilot_path = \"gemini_batch_input_pilot_10.jsonl\"\n",
    "\n",
    "with open(pilot_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for _, row in df_lg.head(PILOT_N).iterrows():\n",
    "        segments = row[\"segments\"]\n",
    "        full_prompt = get_gemini_prompt(segments)\n",
    "\n",
    "        payload = {\n",
    "            \"custom_id\": f\"case_{row['case_id']}\",\n",
    "            \"contents\": [{\n",
    "                \"role\": \"user\",\n",
    "                \"parts\": [{\"text\": full_prompt}]\n",
    "            }]\n",
    "        }\n",
    "        f.write(json.dumps(payload, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(\"‚úÖ Pilot erstellt:\", pilot_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26beec66",
   "metadata": {},
   "source": [
    "Der Code dient der inhaltlichen und technischen Validierung der erzeugten Pilotdatei. Hierzu wird der erste Eintrag der JSONL-Datei geladen und exemplarisch ausgegeben, um Struktur, Inhalt und L√§nge des generierten Analyse-Prompts zu √ºberpr√ºfen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8773a064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case_2090187\n",
      "Analysiere die folgenden Abschnitte eines Gerichtsurteils zum Dieselskandal und extrahiere die Variablen pr√§zise als JSON-Liste. \n",
      "\n",
      "### URTEILS-BESTANDTEILE:\n",
      "RUBRUM (Kopfbereich mit Gericht & Datum): \n",
      "Rechtsgebiet\n",
      "Gericht\n",
      "Informationen\n",
      "Urschrift des Grundgesetzes\n",
      "Abk√ºrzungen\n",
      "\n",
      "TENOR (Ergebnis): \n",
      "I. Die Klage wird abgewiesen.II. Der Kl√§ger hat die Kosten des Rechtsstreits zu tragen.III. Das Urteil ist gegen Sicherheitsleistung in H√∂he des 1,1-fachen des zu vollstreckenden Betrags vorl√§ufig vollstreckbar.IV. Der Streitwert wird auf 31.234,00 ‚Ç¨ festgesetzt.\n",
      "\n",
      "TATBESTAND (Sachverhalt): \n",
      "Der Kl√§ger begehrt Lieferung eines mangelfreien Pkw.Der Kl√§ger erwarb von der Beklagten im Jahr 2014 einen Neuwagen VW Passat 2,0 l TDI f√ºr 31.234,00 ‚Ç¨. Der Pkw ist von dem \"VW-Abgasskandal\" betroffen. Der Kl√§ger \n",
      "Prompt-L√§nge: 9736\n"
     ]
    }
   ],
   "source": [
    "with open(\"gemini_batch_input_pilot_10.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    first = json.loads(f.readline())\n",
    "\n",
    "print(first[\"custom_id\"])\n",
    "print(first[\"contents\"][0][\"parts\"][0][\"text\"][:800])\n",
    "print(\"Prompt-L√§nge:\", len(first[\"contents\"][0][\"parts\"][0][\"text\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966495f0",
   "metadata": {},
   "source": [
    "### 3.3 Upload und Start eines Pilot-Batch-Jobs\n",
    "In diesem Schritt wird die zuvor erzeugte Pilot-JSONL-Datei als Eingabe f√ºr die Gemini-API hochgeladen. Die Datei enth√§lt strukturierte Analyseanfragen f√ºr mehrere Urteile und wird auf den Servern bereitgestellt, sodass sie anschlie√üend im Rahmen einer Batch- oder sequenziellen Verarbeitung vom Sprachmodell verarbeitet werden kann. Der Upload erzeugt eine referenzierbare Eingabedatei, die anschlie√üend einem eindeutig benannten Batch-Job zugewiesen wird und damit eine reproduzierbare Verarbeitung durch das Sprachmodell erm√∂glicht.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371274c8",
   "metadata": {},
   "source": [
    "Initialisierung des API-Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7cb802c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client initialisiert\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "import os\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise RuntimeError(\"GEMINI_API_KEY ist nicht gesetzt\")\n",
    "\n",
    "client = genai.Client(api_key=api_key)\n",
    "print(\"Client initialisiert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d462c1",
   "metadata": {},
   "source": [
    "Upload der JSONL-Datei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee753d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload: files/hsy9zbjk70j2\n"
     ]
    }
   ],
   "source": [
    "uploaded = client.files.upload(\n",
    "    file=\"gemini_batch_input_pilot_10.jsonl\",\n",
    "    config={\n",
    "        \"display_name\": \"diesel-lg-pilot-10\",\n",
    "        \"mime_type\": \"text/plain\"\n",
    "    }\n",
    ")\n",
    "print(\"Upload:\", uploaded.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55e7aedb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mClientError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m job = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatches\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodels/gemini-2.5-flash\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m=\u001b[49m\u001b[43muploaded\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdisplay_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdiesel-lg-pilot-10\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBatch gestartet:\u001b[39m\u001b[33m\"\u001b[39m, job.name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\humme\\OneDrive\\Dokumente\\Uni Ulm\\ds_law\\.venv\\Lib\\site-packages\\google\\genai\\batches.py:1965\u001b[39m, in \u001b[36mBatches.create\u001b[39m\u001b[34m(self, model, src, config)\u001b[39m\n\u001b[32m   1963\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create(model=model, src=src, config=config)\n\u001b[32m   1964\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1965\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m=\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\humme\\OneDrive\\Dokumente\\Uni Ulm\\ds_law\\.venv\\Lib\\site-packages\\google\\genai\\batches.py:1552\u001b[39m, in \u001b[36mBatches._create\u001b[39m\u001b[34m(self, model, src, config)\u001b[39m\n\u001b[32m   1549\u001b[39m request_dict = _common.convert_to_dict(request_dict)\n\u001b[32m   1550\u001b[39m request_dict = _common.encode_unserializable_types(request_dict)\n\u001b[32m-> \u001b[39m\u001b[32m1552\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1553\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\n\u001b[32m   1554\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1556\u001b[39m response_dict = {} \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m response.body \u001b[38;5;28;01melse\u001b[39;00m json.loads(response.body)\n\u001b[32m   1558\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._api_client.vertexai:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\humme\\OneDrive\\Dokumente\\Uni Ulm\\ds_law\\.venv\\Lib\\site-packages\\google\\genai\\_api_client.py:1386\u001b[39m, in \u001b[36mBaseApiClient.request\u001b[39m\u001b[34m(self, http_method, path, request_dict, http_options)\u001b[39m\n\u001b[32m   1376\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrequest\u001b[39m(\n\u001b[32m   1377\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1378\u001b[39m     http_method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1381\u001b[39m     http_options: Optional[HttpOptionsOrDict] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1382\u001b[39m ) -> SdkHttpResponse:\n\u001b[32m   1383\u001b[39m   http_request = \u001b[38;5;28mself\u001b[39m._build_request(\n\u001b[32m   1384\u001b[39m       http_method, path, request_dict, http_options\n\u001b[32m   1385\u001b[39m   )\n\u001b[32m-> \u001b[39m\u001b[32m1386\u001b[39m   response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1387\u001b[39m   response_body = (\n\u001b[32m   1388\u001b[39m       response.response_stream[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m response.response_stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1389\u001b[39m   )\n\u001b[32m   1390\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m SdkHttpResponse(headers=response.headers, body=response_body)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\humme\\OneDrive\\Dokumente\\Uni Ulm\\ds_law\\.venv\\Lib\\site-packages\\google\\genai\\_api_client.py:1222\u001b[39m, in \u001b[36mBaseApiClient._request\u001b[39m\u001b[34m(self, http_request, http_options, stream)\u001b[39m\n\u001b[32m   1219\u001b[39m     retry = tenacity.Retrying(**retry_kwargs)\n\u001b[32m   1220\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retry(\u001b[38;5;28mself\u001b[39m._request_once, http_request, stream)  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1222\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_once\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\humme\\OneDrive\\Dokumente\\Uni Ulm\\ds_law\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    475\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\humme\\OneDrive\\Dokumente\\Uni Ulm\\ds_law\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    376\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\humme\\OneDrive\\Dokumente\\Uni Ulm\\ds_law\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:420\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    418\u001b[39m retry_exc = \u001b[38;5;28mself\u001b[39m.retry_error_cls(fut)\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\humme\\OneDrive\\Dokumente\\Uni Ulm\\ds_law\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:187\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> t.NoReturn:\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\humme\\OneDrive\\Dokumente\\Uni Ulm\\ds_law\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m         result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    482\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\humme\\OneDrive\\Dokumente\\Uni Ulm\\ds_law\\.venv\\Lib\\site-packages\\google\\genai\\_api_client.py:1199\u001b[39m, in \u001b[36mBaseApiClient._request_once\u001b[39m\u001b[34m(self, http_request, stream)\u001b[39m\n\u001b[32m   1191\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1192\u001b[39m   response = \u001b[38;5;28mself\u001b[39m._httpx_client.request(\n\u001b[32m   1193\u001b[39m       method=http_request.method,\n\u001b[32m   1194\u001b[39m       url=http_request.url,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1197\u001b[39m       timeout=http_request.timeout,\n\u001b[32m   1198\u001b[39m   )\n\u001b[32m-> \u001b[39m\u001b[32m1199\u001b[39m   \u001b[43merrors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAPIError\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1200\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[32m   1201\u001b[39m       response.headers, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response.text]\n\u001b[32m   1202\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\humme\\OneDrive\\Dokumente\\Uni Ulm\\ds_law\\.venv\\Lib\\site-packages\\google\\genai\\errors.py:121\u001b[39m, in \u001b[36mAPIError.raise_for_response\u001b[39m\u001b[34m(cls, response)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    119\u001b[39m   response_json = response.body_segments[\u001b[32m0\u001b[39m].get(\u001b[33m'\u001b[39m\u001b[33merror\u001b[39m\u001b[33m'\u001b[39m, {})\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraise_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\humme\\OneDrive\\Dokumente\\Uni Ulm\\ds_law\\.venv\\Lib\\site-packages\\google\\genai\\errors.py:146\u001b[39m, in \u001b[36mAPIError.raise_error\u001b[39m\u001b[34m(cls, status_code, response_json, response)\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Raises an appropriate APIError subclass based on the status code.\u001b[39;00m\n\u001b[32m    133\u001b[39m \n\u001b[32m    134\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    143\u001b[39m \u001b[33;03m  APIError: For other error status codes.\u001b[39;00m\n\u001b[32m    144\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m400\u001b[39m <= status_code < \u001b[32m500\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[32m500\u001b[39m <= status_code < \u001b[32m600\u001b[39m:\n\u001b[32m    148\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ServerError(status_code, response_json, response)\n",
      "\u001b[31mClientError\u001b[39m: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource has been exhausted (e.g. check quota).', 'status': 'RESOURCE_EXHAUSTED'}}"
     ]
    }
   ],
   "source": [
    "job = client.batches.create(\n",
    "    model=\"models/gemini-2.5-flash\",\n",
    "    src=uploaded.name,\n",
    "    config={\"display_name\": \"diesel-lg-pilot-10\"}\n",
    ")\n",
    "\n",
    "print(\"Batch gestartet:\", job.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f99f72e",
   "metadata": {},
   "source": [
    "## 4 Verarbeitung der Modellantworten und Erstellung des Extraktions-Datensatzes\n",
    "\n",
    "In diesem Abschnitt werden die Batch-Ausgaben der Gemini-API eingelesen, validiert und in ein tabellarisches Format √ºberf√ºhrt. Zum Zeitpunkt der aktuellen Notebook-Version liegt lediglich der Pilot-Workflow vor; der Code zur Verarbeitung des vollst√§ndigen Batch-Outputs wird nach Abschluss des Batch-Jobs erg√§nzt.\n",
    "\n",
    "(gemini_batch_input_NUR_LG.jsonl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbaca577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System bereit f√ºr Import von: gemini_batch_output_pilot_10.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Zentrale Konfiguration f√ºr den Datenimport\n",
    "# Wenn wir den echten Batch machen, m√ºssen wir den Dateinamen hier anpassen\n",
    "BATCH_OUTPUT_FILENAME = \"gemini_batch_output_pilot_10.jsonl\" \n",
    "DATA_INPUT_DIR = \"./\" # Verzeichnis, in dem die Batch-Datei liegt\n",
    "\n",
    "print(f\"System bereit f√ºr Import von: {BATCH_OUTPUT_FILENAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8b810e",
   "metadata": {},
   "source": [
    "### 4.1 Download/Export der Batch-Ausgabedatei (JSONL) (Platzhalter)\n",
    "\n",
    "Nach der in Abschnitt 2 beschriebenen Aufbereitung der Urteilstexte liegt der vollst√§ndige Analyse-Datensatz in Form einer strukturierten JSONL-Datei vor. Diese Datei dient in diesem Schritt als Eingabe f√ºr die automatisierte Verarbeitung durch ein gro√ües Sprachmodell.\n",
    "\n",
    "Die JSONL-Datei wird zun√§chst in das Batch-System hochgeladen. Anschlie√üend wird ein Batch-Verarbeitungsjob gestartet, der die hochgeladene Datei als Eingabequelle verwendet. F√ºr jedes enthaltene Dokument erzeugt das Modell eine strukturierte Antwort gem√§√ü den im Prompt definierten Extraktionsvorgaben.\n",
    "\n",
    "Als Ergebnis des Batch-Jobs stellt die API eine Ausgabedatei bereit, die die Modellantworten zu allen verarbeiteten Urteilen enth√§lt. Diese Ausgabedatei liegt ebenfalls im JSONL-Format vor und bildet die Grundlage f√ºr die weitere Aufbereitung und Auswertung der Ergebnisse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a57fa105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå FEHLER: Datei nicht gefunden unter ./gemini_batch_output_pilot_10.jsonl\n",
      "Bitte pr√ºfe den Dateinamen oder lade die .jsonl Datei in das Verzeichnis hoch.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 1. Konfiguration (Pfade m√ºssen zu deiner Umgebung passen)\n",
    "# BATCH_OUTPUT_FILENAME ist der Name der Datei, die du von Gemini erhalten hast\n",
    "full_batch_path = os.path.join(DATA_INPUT_DIR, BATCH_OUTPUT_FILENAME)\n",
    "\n",
    "# 2. Existenzpr√ºfung: Sicherstellen, dass die Datei vorhanden ist\n",
    "if os.path.exists(full_batch_path):\n",
    "    # 3. Einlesen der Batch-Ausgabedatei (JSONL-Format)\n",
    "    # Wir lesen zeilenweise ein, um den Speicher bei vielen Urteilen zu schonen\n",
    "    with open(full_batch_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        # Jede Zeile der JSONL ist ein String, der sp√§ter in 4.2 geparst wird\n",
    "        raw_batch_lines = [line.strip() for line in f if line.strip()]\n",
    "    \n",
    "    print(f\"‚úÖ Datei erfolgreich lokalisiert: {full_batch_path}\")\n",
    "    print(f\"üìä Anzahl der geladenen KI-Antworten: {len(raw_batch_lines)}\")\n",
    "    \n",
    "    # Kurzer Blick auf die Rohdaten zur Kontrolle\n",
    "    if len(raw_batch_lines) > 0:\n",
    "        print(\"\\nErste Zeile Rohdaten (Vorschau):\")\n",
    "        print(raw_batch_lines[0][:150] + \"...\")\n",
    "else:\n",
    "    print(f\"‚ùå FEHLER: Datei nicht gefunden unter {full_batch_path}\")\n",
    "    print(\"Bitte pr√ºfe den Dateinamen oder lade die .jsonl Datei in das Verzeichnis hoch.\")\n",
    "    raw_batch_lines = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ee941142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_batch_lines: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"raw_batch_lines:\", len(raw_batch_lines))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a7cbd2",
   "metadata": {},
   "source": [
    "### 4.2 Parsing, Validierung und Tabellierung der Extraktionen (Platzhalter)\n",
    "\n",
    "Die im vorherigen Schritt erzeugte Ausgabedatei des Batch-Jobs liegt zun√§chst als Rohdaten im JSONL-Format vor. Jede Zeile dieser Datei enth√§lt die strukturierte Modellantwort zu einem einzelnen Landgerichtsurteil.\n",
    "\n",
    "Diese Rohdaten werden lokal gespeichert und anschlie√üend in ein tabellarisches Format √ºberf√ºhrt. Hierzu werden die relevanten Felder aus den JSON-Strukturen extrahiert und in einer einheitlichen Datenstruktur zusammengef√ºhrt, beispielsweise in Form einer CSV-Datei. \n",
    "Der so erzeugte Datensatz bildet die Grundlage f√ºr die weitere statistische Auswertung und Analyse in den folgenden Abschnitten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "32e48e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 4.2 abgeschlossen: 0 Datens√§tze extrahiert\n",
      "‚ö†Ô∏è Parsing-Fehler: 0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def extract_json_from_llm(text: str):\n",
    "    \"\"\"\n",
    "    Extrahiert den ersten JSON-Block aus einer LLM-Antwort und parsed ihn.\n",
    "    Erwartet typischerweise eine Liste mit einem Objekt: [ { ... } ]\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        raise ValueError(\"LLM-Output ist kein String\")\n",
    "\n",
    "    # Entfernt ```json ... ``` falls vorhanden\n",
    "    text = re.sub(r\"^```json\\s*|\\s*```$\", \"\", text.strip(), flags=re.MULTILINE)\n",
    "\n",
    "    # Falls au√üenrum Text steht: ersten JSON-Block (Liste oder Objekt) extrahieren\n",
    "    m = re.search(r\"(\\[\\s*\\{.*?\\}\\s*\\]|\\{.*?\\})\", text, flags=re.DOTALL)\n",
    "    if not m:\n",
    "        raise ValueError(\"Kein JSON-Block in LLM-Output gefunden\")\n",
    "\n",
    "    return json.loads(m.group(1))\n",
    "\n",
    "def to_num(val):\n",
    "    \"\"\"\n",
    "    Konvertiert textuelle Betr√§ge (DE/EN Formate) robust in numerische Werte.\n",
    "    Beispiele: '25.900,50 EUR', '25,900.50', '25900,50'.\n",
    "    \"\"\"\n",
    "    if val is None:\n",
    "        return None\n",
    "\n",
    "    s = str(val).strip().lower()\n",
    "    if s in {\"null\", \"nan\", \"none\", \"\"}:\n",
    "        return None\n",
    "\n",
    "    # Entfernt W√§hrungszeichen und Textreste, beh√§lt nur Ziffern und Trenner\n",
    "    s = re.sub(r\"[^\\d.,]\", \"\", s)\n",
    "\n",
    "    # Behandlung von Mischformaten (Deutsch vs. Englisch)\n",
    "    if \",\" in s and \".\" in s:\n",
    "        # Deutsch: 25.900,50 -> 25900.50\n",
    "        s = s.replace(\".\", \"\").replace(\",\", \".\") if s.find(\".\") < s.find(\",\") else s.replace(\",\", \"\")\n",
    "    elif \",\" in s:\n",
    "        # Reines Kommaformat -> Dezimalpunkt\n",
    "        s = s.replace(\",\", \".\")\n",
    "\n",
    "    try:\n",
    "        return float(s)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "# Container f√ºr erfolgreiche Extraktionen und Parsing-Fehler\n",
    "rows, errs = [], []\n",
    "\n",
    "# Iteration √ºber jede Zeile der Batch-Ausgabedatei (JSONL)\n",
    "for line in raw_batch_lines:\n",
    "    case_id = None\n",
    "    try:\n",
    "        # 1) Parsen der JSONL-Zeile (Batch-Wrapper)\n",
    "        b = json.loads(line)\n",
    "\n",
    "        # 2) Extraktion der eindeutigen Fall-ID\n",
    "        case_id = b.get(\"custom_id\", \"\").replace(\"case_\", \"\").strip()\n",
    "\n",
    "        # 3) Extraktion des reinen Modelltexts aus dem Batch-Wrapper\n",
    "        raw = b[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "        # 4) JSON-Extraktion aus der Modellantwort\n",
    "        d = extract_json_from_llm(raw)\n",
    "\n",
    "        # Normalisierung: Prompt liefert meist eine Liste mit genau einem Objekt\n",
    "        d = d[0] if isinstance(d, list) else d\n",
    "        if not isinstance(d, dict):\n",
    "            raise ValueError(\"Extrahiertes JSON ist kein Objekt (dict)\")\n",
    "\n",
    "        # 5) Sicherung der Fall-ID f√ºr sp√§tere Zusammenf√ºhrung\n",
    "        d[\"case_id\"] = case_id\n",
    "\n",
    "        # 6) Feature Engineering: numerische Betr√§ge\n",
    "        d[\"Schadensersatz_Betrag_num\"] = to_num(d.get(\"LABEL_Schadensersatzhoehe_Betrag\"))\n",
    "        d[\"Kaufpreis_num\"] = to_num(d.get(\"Kaufpreis\"))\n",
    "\n",
    "        # 7) Konsistenzregeln & Zielklassenbildung (robust)\n",
    "        is_sonstige = str(d.get(\"LABEL_Schadensersatzhoehe_Range\", \"\")).strip().lower() == \"sonstige\"\n",
    "        if is_sonstige:\n",
    "            d.update({\n",
    "                \"target_label\": \"Sonstige\",\n",
    "                \"LABEL_Anspruch_Schadensersatz\": False,\n",
    "                \"LABEL_Schadensersatzhoehe_Betrag\": None,\n",
    "                \"Schadensersatz_Betrag_num\": None\n",
    "            })\n",
    "        else:\n",
    "            val = d.get(\"LABEL_Anspruch_Schadensersatz\")\n",
    "            is_true = (val is True) or (isinstance(val, str) and val.strip().lower() == \"true\")\n",
    "\n",
    "            if is_true:\n",
    "                d[\"target_label\"] = \"Schadensersatz\"\n",
    "            else:\n",
    "                d[\"target_label\"] = \"Abgewiesen\"\n",
    "\n",
    "        # Erfolgreich verarbeiteter Datensatz\n",
    "        rows.append(d)\n",
    "\n",
    "    except Exception as e:\n",
    "        # Fehlerhafte Batch-Zeilen werden dokumentiert, nicht verworfen\n",
    "        errs.append({\"case_id\": case_id, \"error\": str(e)})\n",
    "\n",
    "# 8) √úberf√ºhrung der bereinigten Extraktionen in ein tabellarisches Format\n",
    "df_extracted = pd.DataFrame(rows)\n",
    "\n",
    "# Wichtig: Damit 4.3 nicht an assert(case_id) scheitert, auch wenn rows leer ist\n",
    "if df_extracted.empty:\n",
    "    df_extracted = pd.DataFrame(columns=[\"case_id\"])\n",
    "\n",
    "# Kurzer Qualit√§tsreport\n",
    "print(f\"‚úÖ 4.2 abgeschlossen: {len(df_extracted)} Datens√§tze extrahiert\")\n",
    "print(f\"‚ö†Ô∏è Parsing-Fehler: {len(errs)}\")\n",
    "\n",
    "# Optional: Fehlerliste kurz anzeigen\n",
    "if len(errs) > 0:\n",
    "    print(\"Beispiel-Fehler:\", errs[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2911c4f4",
   "metadata": {},
   "source": [
    "### 4.3 Zusammenf√ºhrung mit Metadaten und Speicherung (CSV/Parquet) (Platzhalter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500c339b",
   "metadata": {},
   "source": [
    "In diesem finalen Schritt der Datenextraktion werden die bereinigten Modellantworten (df_clean_labels) mit den urspr√ºnglichen Metadaten und Urteilstexten der Landgerichte (df_lg) zusammengef√ºhrt. Die Verkn√ºpfung erfolgt √ºber die eindeutige case_id, um eine konsistente Zuordnung zwischen den technischen Features (z. B. Motortyp, Kilometerstand) und den Zielvariablen (Schadensersatzh√∂he, Anspruchsstatus) zu gew√§hrleisten.\n",
    "Der resultierende Gesamtdatensatz wird in zwei Formaten exportiert:\n",
    "* CSV-Format: Zur einfachen manuellen √úberpr√ºfung der Extraktionsergebnisse in Tabellenkalkulationsprogrammen.\n",
    "* Parquet-Format: Zur effizienten Weiterverarbeitung in der Machine-Learning-Phase (Kapitel 5), da dieses Format Datentypen (z. B. numerische Betr√§ge ohne Zinsen) verlustfrei speichert.\n",
    "Damit ist die Datenbasis f√ºr die nachfolgende semantische Analyse und Modellierung vollst√§ndig vorbereitet.---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcf0d07",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "df_extracted enth√§lt keine case_id",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 1) Sicherstellen, dass case_id in beiden DataFrames existiert\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcase_id\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df_lg.columns, \u001b[33m\"\u001b[39m\u001b[33mdf_lg enth√§lt keine case_id\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcase_id\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df_extracted.columns, \u001b[33m\"\u001b[39m\u001b[33mdf_extracted enth√§lt keine case_id\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# 2) Zusammenf√ºhrung: Urteilstexte + Metadaten + extrahierte Labels\u001b[39;00m\n\u001b[32m      6\u001b[39m df_dataset = pd.merge(\n\u001b[32m      7\u001b[39m     df_lg,\n\u001b[32m      8\u001b[39m     df_extracted,\n\u001b[32m      9\u001b[39m     on=\u001b[33m\"\u001b[39m\u001b[33mcase_id\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     10\u001b[39m     how=\u001b[33m\"\u001b[39m\u001b[33minner\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     11\u001b[39m )\n",
      "\u001b[31mAssertionError\u001b[39m: df_extracted enth√§lt keine case_id"
     ]
    }
   ],
   "source": [
    "# 1) Sicherstellen, dass case_id in beiden DataFrames existiert (l√§uft erst mit echtem Batch)\n",
    "assert \"case_id\" in df_lg.columns, \"df_lg enth√§lt keine case_id\"\n",
    "assert \"case_id\" in df_extracted.columns, \"df_extracted enth√§lt keine case_id\"\n",
    "\n",
    "# 2) Zusammenf√ºhrung: Urteilstexte + Metadaten + extrahierte Labels\n",
    "df_dataset = pd.merge(\n",
    "    df_lg,\n",
    "    df_extracted,\n",
    "    on=\"case_id\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Merge abgeschlossen: {df_dataset.shape[0]} Urteile im Gesamtdatensatz\")\n",
    "\n",
    "# 3) Sanity-Checks\n",
    "print(df_dataset[\"target_label\"].value_counts(dropna=False))\n",
    "\n",
    "# 4) Export\n",
    "OUTPUT_BASENAME = \"lg_diesel_urteile_final\"\n",
    "df_dataset.to_csv(f\"{OUTPUT_BASENAME}.csv\", index=False, encoding=\"utf-8\")\n",
    "df_dataset.to_parquet(f\"{OUTPUT_BASENAME}.parquet\", index=False)\n",
    "\n",
    "print(\"Export abgeschlossen: CSV & Parquet erstellt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f899d3",
   "metadata": {},
   "source": [
    "## 5. Datenaufbereitung f√ºr maschinelles Lernen\n",
    "\n",
    "In diesem Abschnitt werden die Urteilstexte f√ºr die nachgelagerte pr√§diktive Modellierung aufbereitet. Hierzu erfolgt zun√§chst eine juristisch angepasste Textvorverarbeitung und die Ableitung numerischer Textrepr√§sentationen. Die f√ºr die supervised Lernphase erforderlichen Zielvariablen werden im Rahmen der LLM-basierten Extraktion (Abschnitt 4) erzeugt und anschlie√üend mit den Textmerkmalen zusammengef√ºhrt (Abschnitt 5.4).\n",
    "Ziel der Datenaufbereitung ist es, die extrahierten Merkmale in eine konsistente, auswertbare Form zu √ºberf√ºhren, fehlende oder uneinheitliche Angaben zu behandeln und die Zielvariablen f√ºr die sp√§tere Analyse eindeutig zu definieren."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8ab869",
   "metadata": {},
   "source": [
    "### 5.1 Juristische Textvorverarbeitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b021aba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 1. Setup: Spezialisiertes deutsches Sprachmodell laden\n",
    "try:\n",
    "    nlp = spacy.load(\"de_core_news_lg\", disable=[\"ner\", \"parser\"])\n",
    "except Exception:\n",
    "    print(\"Bitte installiere das spacy Modell: python -m spacy download de_core_news_lg\")\n",
    "\n",
    "# --- 2. JURISTISCHE TEXTVORVERARBEITUNG ---\n",
    "def legal_preprocess(text):\n",
    "    \"\"\"\n",
    "    Bereitet juristische Texte auf, indem Rauschen entfernt wird, \n",
    "    w√§hrend rechtlich relevante Zahlen und Kontexte gesch√ºtzt werden.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str) or not text:\n",
    "        return \"\"\n",
    "\n",
    "    # NEU: START DES URTEILS FINDEN (Rauschschnitt Anfang) ---\n",
    "    # Wir schneiden Webseiten-Men√ºs (\"trending\", \"suche\" etc.) weg\n",
    "    start_keywords = [\"tenor\", \"entscheidungsgr√ºnde\", \"tatbestand\", \"urteil\", \"beschluss\", \"endurteil\"]\n",
    "    text_lower_start = text.lower()\n",
    "    \n",
    "    # Finde die fr√ºheste Position eines der Keywords\n",
    "    found_positions = [text_lower_start.find(kw) for kw in start_keywords if text_lower_start.find(kw) != -1]\n",
    "    if found_positions:\n",
    "        text = text[min(found_positions):]\n",
    "\n",
    "    # NEU: ENDE DES URTEILS FINDEN (Rauschschnitt Ende) ---\n",
    "    # Wir schneiden Impressum und Footer weg\n",
    "    end_keywords = [\"impressum\", \"nutzungsbedingungen\", \"nach oben\", \"datenschutz\"]\n",
    "    text_lower_end = text.lower()\n",
    "    for ekw in end_keywords:\n",
    "        e_pos = text_lower_end.find(ekw)\n",
    "        if e_pos != -1:\n",
    "            text = text[:e_pos]\n",
    "            break\n",
    "\n",
    "    # 1. Bereinigung von Rauschen (HTML-Tags, Sonderzeichen)\n",
    "    text = re.sub(r'<.*?>', ' ', text)\n",
    "\n",
    "    # 2. Schutz von Zahlen & Paragraphen (Platzhalter statt L√∂schen)\n",
    "    # Euro-Betr√§ge sch√ºtzen\n",
    "    text = re.sub(r'\\d{1,3}(?:\\.\\d{3})*(?:,\\d+)?\\s*(?:EUR|‚Ç¨|Euro)', ' PLATZHALTER_BETRAG ', text)\n",
    "    # Paragraphen sch√ºtzen\n",
    "    text = re.sub(r'¬ß+\\s*\\d+[a-z]?\\s*(?:\\w+)?', ' PLATZHALTER_PARAGRAPH ', text)\n",
    "    # Jahreszahlen sch√ºtzen\n",
    "    text = re.sub(r'\\b(19|20)\\d{2}\\b', ' PLATZHALTER_JAHR ', text)\n",
    "\n",
    "    # 3. Kleinschreibung zur Reduktion der Varianz\n",
    "    text = text.lower()\n",
    "\n",
    "    # 4. Tokenisierung und Lemmatisierung mit SpaCy\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # 5. Kontextsensitive Stoppwort-Entfernung\n",
    "    # Wichtige juristische Negationen sch√ºtzen\n",
    "    protected_negations = {\"nicht\", \"kein\", \"ohne\", \"gegen\", \"trotz\"}\n",
    "    custom_stop_words = nlp.Defaults.stop_words - protected_negations\n",
    "    \n",
    "    # Extraktion der Lemmata (Grundformen)\n",
    "    tokens = [\n",
    "        token.lemma_ for token in doc \n",
    "        if token.lemma_ not in custom_stop_words \n",
    "        and not token.is_punct \n",
    "        and not token.is_space\n",
    "        and len(token.text) > 1 # Token mit L√§nge 1 entfernen\n",
    "    ]\n",
    "    \n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# --- 2.5 HILFSFUNKTIONEN: Simulation + echtes Batch lesen ---\n",
    "def get_llm_text(r: dict) -> str:\n",
    "    # Simulation (simulated_batch_output.jsonl)\n",
    "    if \"text\" in r:\n",
    "        return r[\"text\"]\n",
    "    # Echtes Batch (sp√§ter)\n",
    "    if \"response\" in r:\n",
    "        return r[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"]\n",
    "    raise KeyError(\"Unbekanntes Ergebnisformat (kein 'text' und kein 'response').\")\n",
    "\n",
    "def parse_llm_json(text: str) -> dict:\n",
    "    # Entfernt ```json ... ``` falls vorhanden\n",
    "    text = re.sub(r\"^```json\\s*|\\s*```$\", \"\", text.strip(), flags=re.MULTILINE)\n",
    "    # Falls au√üenrum Text steht: ersten JSON-Block extrahieren\n",
    "    m = re.search(r\"(\\{.*\\})\", text, flags=re.DOTALL)\n",
    "    if m:\n",
    "        text = m.group(1)\n",
    "    return json.loads(text)\n",
    "\n",
    "# --- 3. MERGING DER DATEN (URTEILE + EXTRAKTIONEN) ---\n",
    "def merge_and_finalize(judgment_file, batch_results_file):\n",
    "    \"\"\"\n",
    "    F√ºhrt die urspr√ºnglichen Urteilstexte mit den Gemini-Extraktionen zusammen.\n",
    "    \"\"\"\n",
    "    # 1. Laden der aufbereiteten LG-Urteile\n",
    "    df_judgments = pd.read_json(judgment_file, lines=True)\n",
    "    df_judgments['case_id'] = df_judgments['custom_id'].str.replace('case_', '')\n",
    "\n",
    "    # 2. Laden der Gemini-Batch-Ergebnisse\n",
    "    with open(batch_results_file, 'r', encoding='utf-8') as f:\n",
    "        results = [json.loads(line) for line in f]\n",
    "    \n",
    "    extracted_rows = []\n",
    "    for r in results:\n",
    "        try:\n",
    "            case_id = r['custom_id'].replace('case_', '')\n",
    "            llm_text = get_llm_text(r)\n",
    "            content = parse_llm_json(llm_text)\n",
    "            content['case_id'] = case_id\n",
    "            extracted_rows.append(content)\n",
    "        except Exception:\n",
    "            continue\n",
    "            \n",
    "    df_extracted = pd.DataFrame(extracted_rows)\n",
    "\n",
    "    # 3. Zusammenf√ºhrung √ºber case_id \n",
    "    df_final = pd.merge(df_judgments, df_extracted, on='case_id', how='inner')\n",
    "\n",
    "    # 4. Textverarbeitung anwenden\n",
    "    print(\"Starte Textvorverarbeitung...\")\n",
    "    df_final['cleaned_text'] = df_final['text'].apply(legal_preprocess)\n",
    "\n",
    "    return df_final\n",
    "\n",
    "# --- 4. MODELL-VORBEREITUNG (TF-IDF) ---\n",
    "tfidf = TfidfVectorizer(\n",
    "    ngram_range=(1, 2),   # Bigramme erhalten Wortzusammenh√§nge\n",
    "    max_features=1000,    # Reduktion der Komplexit√§t\n",
    "    min_df=5              # Seltene Begriffe ignorieren\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca2d51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lena\\AppData\\Local\\Temp\\ipykernel_24492\\33365220.py:100: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df_judgments = pd.read_json(judgment_file, lines=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected object or value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m RESULTS_FILE \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimulated_batch_output.jsonl\u001b[39m\u001b[38;5;124m\"\u001b[39m   \u001b[38;5;66;03m# sp√§ter echte Batch-Output-Datei\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_final \u001b[38;5;241m=\u001b[39m \u001b[43mmerge_and_finalize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjudgment_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlg_judgments.jsonl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_results_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRESULTS_FILE\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 100\u001b[0m, in \u001b[0;36mmerge_and_finalize\u001b[1;34m(judgment_file, batch_results_file)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;124;03mF√ºhrt die urspr√ºnglichen Urteilstexte mit den Gemini-Extraktionen zusammen.\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# 1. Laden der aufbereiteten LG-Urteile\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m df_judgments \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjudgment_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m df_judgments[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcase_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_judgments[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustom_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcase_\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m# 2. Laden der Gemini-Batch-Ergebnisse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lena\\Documents\\GitHub\\ds_law\\.venv\\lib\\site-packages\\pandas\\io\\json\\_json.py:815\u001b[0m, in \u001b[0;36mread_json\u001b[1;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m json_reader\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 815\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lena\\Documents\\GitHub\\ds_law\\.venv\\lib\\site-packages\\pandas\\io\\json\\_json.py:1012\u001b[0m, in \u001b[0;36mJsonReader.read\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1010\u001b[0m         data \u001b[38;5;241m=\u001b[39m ensure_str(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)\n\u001b[0;32m   1011\u001b[0m         data_lines \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1012\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_object_parser\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_combine_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_lines\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1014\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_object_parser(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)\n",
      "File \u001b[1;32mc:\\Users\\Lena\\Documents\\GitHub\\ds_law\\.venv\\lib\\site-packages\\pandas\\io\\json\\_json.py:1040\u001b[0m, in \u001b[0;36mJsonReader._get_object_parser\u001b[1;34m(self, json)\u001b[0m\n\u001b[0;32m   1038\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1040\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43mFrameParser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseries\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1043\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Lena\\Documents\\GitHub\\ds_law\\.venv\\lib\\site-packages\\pandas\\io\\json\\_json.py:1176\u001b[0m, in \u001b[0;36mParser.parse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   1175\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m-> 1176\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lena\\Documents\\GitHub\\ds_law\\.venv\\lib\\site-packages\\pandas\\io\\json\\_json.py:1392\u001b[0m, in \u001b[0;36mFrameParser._parse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1388\u001b[0m orient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morient\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m orient \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1391\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m DataFrame(\n\u001b[1;32m-> 1392\u001b[0m         \u001b[43mujson_loads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecise_float\u001b[49m\u001b[43m)\u001b[49m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1393\u001b[0m     )\n\u001b[0;32m   1394\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m orient \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1395\u001b[0m     decoded \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1396\u001b[0m         \u001b[38;5;28mstr\u001b[39m(k): v\n\u001b[0;32m   1397\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m ujson_loads(json, precise_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecise_float)\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   1398\u001b[0m     }\n",
      "\u001b[1;31mValueError\u001b[0m: Expected object or value"
     ]
    }
   ],
   "source": [
    "RESULTS_FILE = \"simulated_batch_output.jsonl\"   # sp√§ter echte Batch-Output-Datei\n",
    "df_final = merge_and_finalize(\n",
    "    judgment_file=\"lg_judgments.jsonl\",\n",
    "    batch_results_file=RESULTS_FILE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c4388ff7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m tqdm.pandas()\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Kapitel 5 arbeitet ausschlie√ülich auf dem final gemergten Datensatz\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m df_text = \u001b[43mdf_dataset\u001b[49m.copy()\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# 1) Sicherstellen, dass Segmente existieren\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33msegments\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m df_text.columns:\n",
      "\u001b[31mNameError\u001b[39m: name 'df_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# Kapitel 5 arbeitet ausschlie√ülich auf dem final gemergten Datensatz\n",
    "df_text = df_dataset.copy()\n",
    "\n",
    "# 1) Sicherstellen, dass Segmente existieren\n",
    "if \"segments\" not in df_text.columns:\n",
    "    df_text[\"segments\"] = df_text[\"text\"].apply(split_judgment)\n",
    "\n",
    "# 2) Textbasis f√ºr ML: TENOR + ENTSCHEIDUNGSGR√úNDE\n",
    "def build_text_for_embedding(s):\n",
    "    if not isinstance(s, dict):\n",
    "        return \"\"\n",
    "    return (s.get(\"tenor\") or \"\") + \"\\n\" + (s.get(\"entscheidungsgruende\") or \"\")\n",
    "\n",
    "df_text[\"text_for_embedding\"] = df_text[\"segments\"].apply(build_text_for_embedding)\n",
    "\n",
    "# 3) L√§nge begrenzen (Token-/Laufzeitkontrolle)\n",
    "MAX_CHARS = 12000\n",
    "df_text[\"text_for_embedding\"] = (\n",
    "    df_text[\"text_for_embedding\"]\n",
    "    .astype(str)\n",
    "    .str.slice(0, MAX_CHARS)\n",
    ")\n",
    "\n",
    "# 4) Juristisches Preprocessing\n",
    "df_text[\"cleaned_text\"] = df_text[\"text_for_embedding\"].progress_apply(legal_preprocess)\n",
    "\n",
    "# 5) Sanity-Checks\n",
    "print(\"df_text shape:\", df_text.shape)\n",
    "print(\n",
    "    \"non-empty cleaned_text:\",\n",
    "    (df_text[\"cleaned_text\"].str.len() > 0).sum()\n",
    ")\n",
    "\n",
    "print(\"\\nBeispiel cleaned_text:\\n\")\n",
    "print(df_text[\"cleaned_text\"].iloc[0][:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f3b2a0",
   "metadata": {},
   "source": [
    "### 5.2 Text-Vektorisierung mittels Word2Vec\n",
    "In diesem Schritt transformieren wir die bereinigten Urteilstexte mithilfe des TF-IDF-Verfahrens in ein numerisches Format, das f√ºr Machine-Learning-Algorithmen lesbar ist. Im Gegensatz zu abstrakten Embeddings bietet TF-IDF eine hohe Interpretierbarkeit, da jedes Merkmal einem konkreten juristischen Begriff oder einer Wortkombination (N-Gramm) entspricht. Durch die Begrenzung auf die 1.000 relevantesten Begriffe reduzieren wir das Rauschen im Datensatz und bereiten die Daten optimal auf den in der Aufgabenstellung empfohlenen Entscheidungsbaum vor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f41b4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Richtige Datenbasis: finaler Datensatz inkl. Labels\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df = \u001b[43mdf_text\u001b[49m  \u001b[38;5;66;03m# df_text = df_dataset.copy() aus 5.1\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Preprocessing nur, falls noch nicht vorhanden\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcleaned_text\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m df.columns:\n",
      "\u001b[31mNameError\u001b[39m: name 'df_text' is not defined"
     ]
    }
   ],
   "source": [
    "# Word2Vec auf Tenor + Gr√ºnde\n",
    "#  Richtige Datenbasis: finaler Datensatz inkl. Labels\n",
    "df = df_text  # df_text = df_dataset.copy() aus 5.1\n",
    "\n",
    "# Preprocessing nur, falls noch nicht vorhanden\n",
    "if \"cleaned_text\" not in df.columns:\n",
    "    print(\"Spalte 'cleaned_text' fehlt. Starte Preprocessing...\")\n",
    "    df[\"cleaned_text\"] = df[\"text_for_embedding\"].apply(legal_preprocess)\n",
    "\n",
    "# X und y f√ºr Word2Vec\n",
    "X = df[\"cleaned_text\"]\n",
    "y = df[\"LABEL_Anspruch_Schadensersatz\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed316e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'cleaned_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Lena\\Documents\\GitHub\\ds_law\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3811\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mpandas/_libs/index.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas/_libs/index.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'cleaned_text'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 13\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m classification_report, accuracy_score, precision_score, recall_score\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# --- 1. DATEN SPLITTEN ---\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# y ist dein Label (Schadensersatz Ja/Nein)\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcleaned_text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \n\u001b[0;32m     14\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLABEL_Anspruch_Schadensersatz\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m     16\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, stratify\u001b[38;5;241m=\u001b[39my)\n",
      "File \u001b[1;32mc:\\Users\\Lena\\Documents\\GitHub\\ds_law\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4113\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4115\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\Lena\\Documents\\GitHub\\ds_law\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3815\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3816\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3817\u001b[0m     ):\n\u001b[0;32m   3818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3820\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3821\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3822\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3823\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'cleaned_text'"
     ]
    }
   ],
   "source": [
    "# wichtig: wir m√ºssen vor dem Word2Vec den Datensatz in Trainings-, Test- und Validierungsdatensatz aufteilen\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score\n",
    "\n",
    "# --- 1. DATEN SPLITTEN ---\n",
    "# y ist dein Label (Schadensersatz Ja/Nein)\n",
    "X = df['cleaned_text'] \n",
    "y = df['LABEL_Anspruch_Schadensersatz'].astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# --- 2. WORD2VEC SCHNITTSTELLE ---\n",
    "# Tokenisierung (Urteile in Wortlisten umwandeln)\n",
    "train_tokens = [doc.split() for doc in X_train]\n",
    "w2v_model = Word2Vec(sentences=train_tokens, vector_size=100, window=5, min_count=2, workers=4) # k√∂nnen wir anpassen, um Kennzahlen zu √§ndern\n",
    "\n",
    "def get_doc_vector(doc):\n",
    "    # Durchschnittsvektor aller W√∂rter im Urteil bilden\n",
    "    words = [w for w in doc.split() if w in w2v_model.wv]\n",
    "    return np.mean(w2v_model.wv[words], axis=0) if words else np.zeros(100)\n",
    "\n",
    "X_train_vec = np.array([get_doc_vector(doc) for doc in X_train])\n",
    "X_test_vec = np.array([get_doc_vector(doc) for doc in X_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9df7450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature-Matrix erstellt: 1189 Urteile, 1000 Begriffe.\n"
     ]
    }
   ],
   "source": [
    "'''''\n",
    "# Semantische Repr√§sentation mittels TF-IDF (statt Word2Vec)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Wir nehmen Unigramme und Bigramme, um Begriffe wie \"Klage abgewiesen\" zu erfassen.\n",
    "tfidf = TfidfVectorizer(\n",
    "    ngram_range=(1, 2), \n",
    "    max_features=1000,  # Reduziert die Komplexit√§t f√ºr den Baum\n",
    "    min_df=5,           # Wort muss in mind. 5 Urteilen vorkommen\n",
    "    stop_words=None      # Stoppw√∂rter wurden bereits im Preprocessing entfernt\n",
    ")\n",
    "\n",
    "# Erstellt die Feature-Matrix\n",
    "X_tfidf = tfidf.fit_transform(df_final[\"cleaned_text\"].fillna(\"\"))\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "\n",
    "print(f\"Feature-Matrix erstellt: {X_tfidf.shape[0]} Urteile, {X_tfidf.shape[1]} Begriffe.\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a77edb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Tokenisierte Texte f√ºr Word2Vec\n",
    "sentences = [str(t).split() for t in df_final[\"cleaned_text\"].dropna()]\n",
    "# Skip-Gram Word2Vec Modell trainieren\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "w2v_model = Word2Vec(\n",
    "    sentences=sentences,\n",
    "    vector_size=200,   # Dimension der Wortvektoren\n",
    "    window=8,          # Kontextfenster\n",
    "    min_count=5,       # sehr seltene W√∂rter ignorieren\n",
    "    workers=4,\n",
    "    sg=1,              # <-- Skip-Gram (besser f√ºr Fachbegriffe, pr√ºfen) \n",
    "    epochs=10\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34222237",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Dokumenten-Vektor durch Mittelung der Wortvektoren\n",
    "import numpy as np\n",
    "\n",
    "def document_vector(doc, model):\n",
    "    if not isinstance(doc, str) or not doc.strip():\n",
    "        return np.zeros(model.vector_size)\n",
    "    words = doc.split()\n",
    "    vectors = [model.wv[w] for w in words if w in model.wv]\n",
    "    if len(vectors) == 0:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(vectors, axis=0)\n",
    "\n",
    "# Alle Urteile vektorisieren\n",
    "X_embeddings = np.vstack(\n",
    "    df_final[\"cleaned_text\"].apply(lambda x: document_vector(x, w2v_model))\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718bee56",
   "metadata": {},
   "source": [
    "### 5.3 Aufbau des Analyse-Datensatzes\n",
    "Nach der Vektorisierung f√ºhren wir die mathematischen Ergebnisse in einer strukturierten Feature-Matrix zusammen. Wir wandeln die Sparse-Matrix in einen √ºbersichtlichen DataFrame um und verkn√ºpfen jedes Urteil √ºber die eindeutige case_id mit seinen Textmerkmalen. Diese Struktur ist essentiell, um im n√§chsten Schritt die durch das LLM extrahierten Zielvariablen (Schadensersatz oder Abweisung) pr√§zise jeder Beobachtung zuordnen zu k√∂nnen. Damit stellen wir sicher, dass der Datensatz modellunabh√§ngig konzipiert ist und eine solide Basis f√ºr die nachgelagerte pr√§diktive Modellierung bietet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9dfb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyse-Datensatz bereit f√ºr Merge mit Labels.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# Aufbau des Analyse-Datensatzes\n",
    "df_features = pd.DataFrame(X_tfidf.toarray(), columns=feature_names)\n",
    "df_features.insert(0, \"case_id\", df_final[\"case_id\"].reset_index(drop=True).values)\n",
    "\n",
    "print(\"Analyse-Datensatz bereit f√ºr Merge mit Labels.\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ae8dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate case_id: 0\n",
      "df_features shape: (1189, 201)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>emb_0</th>\n",
       "      <th>emb_1</th>\n",
       "      <th>emb_2</th>\n",
       "      <th>emb_3</th>\n",
       "      <th>emb_4</th>\n",
       "      <th>emb_5</th>\n",
       "      <th>emb_6</th>\n",
       "      <th>emb_7</th>\n",
       "      <th>emb_8</th>\n",
       "      <th>...</th>\n",
       "      <th>emb_190</th>\n",
       "      <th>emb_191</th>\n",
       "      <th>emb_192</th>\n",
       "      <th>emb_193</th>\n",
       "      <th>emb_194</th>\n",
       "      <th>emb_195</th>\n",
       "      <th>emb_196</th>\n",
       "      <th>emb_197</th>\n",
       "      <th>emb_198</th>\n",
       "      <th>emb_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2090187</td>\n",
       "      <td>0.250946</td>\n",
       "      <td>-0.085170</td>\n",
       "      <td>-0.077979</td>\n",
       "      <td>0.067161</td>\n",
       "      <td>0.045174</td>\n",
       "      <td>-0.117252</td>\n",
       "      <td>0.026742</td>\n",
       "      <td>0.338049</td>\n",
       "      <td>-0.066355</td>\n",
       "      <td>...</td>\n",
       "      <td>0.252053</td>\n",
       "      <td>-0.100552</td>\n",
       "      <td>-0.040251</td>\n",
       "      <td>0.036985</td>\n",
       "      <td>0.116042</td>\n",
       "      <td>0.050408</td>\n",
       "      <td>0.117557</td>\n",
       "      <td>-0.174982</td>\n",
       "      <td>0.145307</td>\n",
       "      <td>-0.103645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2112111</td>\n",
       "      <td>0.153605</td>\n",
       "      <td>-0.026422</td>\n",
       "      <td>-0.052017</td>\n",
       "      <td>0.074121</td>\n",
       "      <td>0.080924</td>\n",
       "      <td>-0.139465</td>\n",
       "      <td>0.046904</td>\n",
       "      <td>0.301640</td>\n",
       "      <td>-0.142989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.321192</td>\n",
       "      <td>-0.029686</td>\n",
       "      <td>-0.143408</td>\n",
       "      <td>-0.017632</td>\n",
       "      <td>0.122290</td>\n",
       "      <td>0.097659</td>\n",
       "      <td>0.064443</td>\n",
       "      <td>-0.189771</td>\n",
       "      <td>0.047694</td>\n",
       "      <td>-0.111056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2112115</td>\n",
       "      <td>0.136315</td>\n",
       "      <td>-0.025062</td>\n",
       "      <td>-0.109175</td>\n",
       "      <td>0.101436</td>\n",
       "      <td>0.050286</td>\n",
       "      <td>-0.100476</td>\n",
       "      <td>0.035225</td>\n",
       "      <td>0.296332</td>\n",
       "      <td>-0.106090</td>\n",
       "      <td>...</td>\n",
       "      <td>0.290144</td>\n",
       "      <td>-0.037600</td>\n",
       "      <td>-0.191303</td>\n",
       "      <td>-0.034134</td>\n",
       "      <td>0.092126</td>\n",
       "      <td>0.030850</td>\n",
       "      <td>0.090835</td>\n",
       "      <td>-0.202326</td>\n",
       "      <td>0.123173</td>\n",
       "      <td>-0.049215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2112117</td>\n",
       "      <td>0.186155</td>\n",
       "      <td>-0.042643</td>\n",
       "      <td>-0.134721</td>\n",
       "      <td>0.094874</td>\n",
       "      <td>0.091750</td>\n",
       "      <td>-0.127567</td>\n",
       "      <td>0.039464</td>\n",
       "      <td>0.250757</td>\n",
       "      <td>-0.089840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.278760</td>\n",
       "      <td>0.046854</td>\n",
       "      <td>-0.186929</td>\n",
       "      <td>-0.020912</td>\n",
       "      <td>0.052867</td>\n",
       "      <td>0.069045</td>\n",
       "      <td>0.042035</td>\n",
       "      <td>-0.145879</td>\n",
       "      <td>0.133028</td>\n",
       "      <td>-0.009825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2112118</td>\n",
       "      <td>0.154466</td>\n",
       "      <td>-0.023952</td>\n",
       "      <td>-0.102075</td>\n",
       "      <td>0.090335</td>\n",
       "      <td>0.067065</td>\n",
       "      <td>-0.124268</td>\n",
       "      <td>0.064659</td>\n",
       "      <td>0.283858</td>\n",
       "      <td>-0.130580</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319533</td>\n",
       "      <td>-0.029580</td>\n",
       "      <td>-0.175624</td>\n",
       "      <td>-0.066235</td>\n",
       "      <td>0.086168</td>\n",
       "      <td>0.086307</td>\n",
       "      <td>0.083033</td>\n",
       "      <td>-0.165920</td>\n",
       "      <td>0.103637</td>\n",
       "      <td>-0.077417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   case_id     emb_0     emb_1     emb_2     emb_3     emb_4     emb_5  \\\n",
       "0  2090187  0.250946 -0.085170 -0.077979  0.067161  0.045174 -0.117252   \n",
       "1  2112111  0.153605 -0.026422 -0.052017  0.074121  0.080924 -0.139465   \n",
       "2  2112115  0.136315 -0.025062 -0.109175  0.101436  0.050286 -0.100476   \n",
       "3  2112117  0.186155 -0.042643 -0.134721  0.094874  0.091750 -0.127567   \n",
       "4  2112118  0.154466 -0.023952 -0.102075  0.090335  0.067065 -0.124268   \n",
       "\n",
       "      emb_6     emb_7     emb_8  ...   emb_190   emb_191   emb_192   emb_193  \\\n",
       "0  0.026742  0.338049 -0.066355  ...  0.252053 -0.100552 -0.040251  0.036985   \n",
       "1  0.046904  0.301640 -0.142989  ...  0.321192 -0.029686 -0.143408 -0.017632   \n",
       "2  0.035225  0.296332 -0.106090  ...  0.290144 -0.037600 -0.191303 -0.034134   \n",
       "3  0.039464  0.250757 -0.089840  ...  0.278760  0.046854 -0.186929 -0.020912   \n",
       "4  0.064659  0.283858 -0.130580  ...  0.319533 -0.029580 -0.175624 -0.066235   \n",
       "\n",
       "    emb_194   emb_195   emb_196   emb_197   emb_198   emb_199  \n",
       "0  0.116042  0.050408  0.117557 -0.174982  0.145307 -0.103645  \n",
       "1  0.122290  0.097659  0.064443 -0.189771  0.047694 -0.111056  \n",
       "2  0.092126  0.030850  0.090835 -0.202326  0.123173 -0.049215  \n",
       "3  0.052867  0.069045  0.042035 -0.145879  0.133028 -0.009825  \n",
       "4  0.086168  0.086307  0.083033 -0.165920  0.103637 -0.077417  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Aufbau des Analyse-Datensatzes\n",
    "\n",
    "# Feature-Namen f√ºr die Embeddings\n",
    "emb_cols = [f\"emb_{i}\" for i in range(X_embeddings.shape[1])]\n",
    "\n",
    "# Embeddings als DataFrame\n",
    "df_features = pd.DataFrame(X_embeddings, columns=emb_cols)\n",
    "\n",
    "# case_id erg√§nzen (f√ºr sp√§tere Joins mit Labels)\n",
    "df_features.insert(0, \"case_id\", df_final[\"case_id\"].reset_index(drop=True).values)\n",
    "\n",
    "# optional: Duplikate pr√ºfen (sollte 0 sein)\n",
    "print(\"Duplicate case_id:\", df_features[\"case_id\"].duplicated().sum())\n",
    "\n",
    "print(\"df_features shape:\", df_features.shape)\n",
    "df_features[[\"case_id\"] + [c for c in df_features.columns if c.startswith(\"emb_\")]].head()\n",
    "'''\n",
    "\n",
    "\n",
    "# angepasst f√ºr Training und Test:\n",
    "# 1. Word2Vec-Vektoren in DataFrames umwandeln (f√ºr Train und Test separat)\n",
    "emb_cols = [f\"emb_{i}\" for i in range(X_train_vec.shape[1])]\n",
    "\n",
    "df_train_features = pd.DataFrame(X_train_vec, columns=emb_cols)\n",
    "df_test_features = pd.DataFrame(X_test_vec, columns=emb_cols)\n",
    "\n",
    "# 2. Jetzt mit den strukturierten Daten (Kaufpreis, Motor-Typ etc.) zusammenf√ºhren\n",
    "# Hinweis: Nutze reset_index(drop=True), um sicherzustellen, dass die Zeilen korrekt matchen\n",
    "X_train_final = pd.concat([X_train_structured.reset_index(drop=True), df_train_features], axis=1)\n",
    "X_test_final = pd.concat([X_test_structured.reset_index(drop=True), df_test_features], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32ca574",
   "metadata": {},
   "source": [
    "Der Analyse-Datensatz besteht aus 1.189 Beobachtungen (Urteilen) mit jeweils 200 numerischen Merkmalen, die den semantischen Gehalt der Entscheidungsgr√ºnde abbilden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e457d4a6",
   "metadata": {},
   "source": [
    "### 5.4 Modellierung und Evaluation (nach Verf√ºgbarkeit der Labels)\n",
    "Auf Grundlage des in Abschnitt 5.3 aufgebauten Analyse-Datensatzes erfolgt im Folgenden die pr√§diktive Modellierung. Hierzu werden die semantischen Dokumenten-Embeddings mit den aus der automatisierten Extraktion gewonnenen Zielvariablen verkn√ºpft und f√ºr den Einsatz √ºberwachter Lernverfahren vorbereitet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b18330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5.4 (wird aktiviert sobald df_labels aus Batch da ist) ---\n",
    "\n",
    "# df_ml = df_features.merge(df_labels, on=\"case_id\", how=\"inner\")\n",
    "# X = df_ml.filter(like=\"emb_\").values\n",
    "# y = df_ml[\"LABEL_Anspruch_Schadensersatz\"].astype(int).values\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.2, random_state=42, stratify=y\n",
    "# )\n",
    "\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# rf = RandomForestClassifier(n_estimators=300, random_state=42, n_jobs=-1, class_weight=\"balanced\")\n",
    "# rf.fit(X_train, y_train)\n",
    "\n",
    "# from sklearn.metrics import classification_report, confusion_matrix\n",
    "# y_pred = rf.predict(X_test)\n",
    "# print(confusion_matrix(y_test, y_pred))\n",
    "# print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05160c8f",
   "metadata": {},
   "source": [
    "## 6. Analyse und Auswertung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4af3ec",
   "metadata": {},
   "source": [
    "Entscheidungsbaum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb49984b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Modell initialisieren und trainieren\n",
    "dt_model = DecisionTreeClassifier(max_depth=10, random_state=42, class_weight=\"balanced\")\n",
    "dt_model.fit(X_train_vec, y_train)\n",
    "\n",
    "# Vorhersage\n",
    "y_pred_dt = dt_model.predict(X_test_vec)\n",
    "\n",
    "# Ausgabe der Metriken (Accuracy, Precision, Recall wie gefordert)\n",
    "print(\"--- Ergebnisse: Entscheidungsbaum ---\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_dt):.4f}\")\n",
    "print(classification_report(y_test, y_pred_dt))\n",
    "\n",
    "# Feature Importance visualisieren (die Top-Dimensionen des Word2Vec)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(len(dt_model.feature_importances_)), dt_model.feature_importances_)\n",
    "plt.title(\"Feature Importance - Decision Tree (Word2Vec Dimensionen)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4755b724",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c129f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Modell initialisieren und trainieren (Anzahl B√§ume gem√§√ü Vorlesung optimieren)\n",
    "rf_model = RandomForestClassifier(n_estimators=300, random_state=42, n_jobs=-1, class_weight=\"balanced\")\n",
    "rf_model.fit(X_train_vec, y_train)\n",
    "\n",
    "# Vorhersage\n",
    "y_pred_rf = rf_model.predict(X_test_vec)\n",
    "\n",
    "# Ausgabe der Metriken\n",
    "print(\"--- Ergebnisse: Random Forest ---\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# Feature Importance\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(len(rf_model.feature_importances_)), rf_model.feature_importances_)\n",
    "plt.title(\"Feature Importance - Random Forest (Word2Vec Dimensionen)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d992e1a2",
   "metadata": {},
   "source": [
    "Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d134f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Modell initialisieren und trainieren\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "gb_model.fit(X_train_vec, y_train)\n",
    "\n",
    "# Vorhersage\n",
    "y_pred_gb = gb_model.predict(X_test_vec)\n",
    "\n",
    "# Ausgabe der Metriken\n",
    "print(\"--- Ergebnisse: Gradient Boosting ---\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_gb):.4f}\")\n",
    "print(classification_report(y_test, y_pred_gb))\n",
    "\n",
    "# Feature Importance\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(len(gb_model.feature_importances_)), gb_model.feature_importances_)\n",
    "plt.title(\"Feature Importance - Gradient Boosting (Word2Vec Dimensionen)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4bce4b",
   "metadata": {},
   "source": [
    "evtl. SHAP Werte f√ºr Erkl√§rbarkeit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

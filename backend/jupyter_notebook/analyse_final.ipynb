{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f87c4b39",
   "metadata": {},
   "source": [
    "## 1. Aufbereitung der Urteilstexte und Vorbereitung des Analyse-Datensatzes\n",
    "\n",
    "In diesem Abschnitt werden die eingelesenen OpenJur-Urteilstexte weiterverarbeitet und strukturiert. Ziel ist es, relevante Textbestandteile wie den Kopfbereich und den Tenor zu extrahieren, Landgerichtsurteile zu identifizieren und die Daten schließlich in ein geeignetes JSONL-Format für die nachgelagerte automatische Analyse zu überführen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972de4e7",
   "metadata": {},
   "source": [
    "### 1.1 Import der benötigten Bibliotheken\n",
    "\n",
    "Zu Beginn werden die für die weitere Verarbeitung erforderlichen Python-Bibliotheken importiert. Diese umfassen Funktionen für Dateizugriffe, reguläre Ausdrücke, Datenverarbeitung mit Pandas sowie den Export der Ergebnisse im JSON-Format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58f86b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61a736b",
   "metadata": {},
   "source": [
    "### 1.2 Einlesen der Urteilstexte und Aufbau des DataFrames\n",
    "\n",
    "In diesem Schritt werden alle zuvor identifizierten Textdateien zeilenweise eingelesen. Für jede Datei wird eine eindeutige Fall-ID aus dem Dateinamen erzeugt und gemeinsam mit dem vollständigen Text in einem Pandas-DataFrame gespeichert. Der DataFrame bildet die zentrale Datenstruktur für die weitere Analyse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bef8dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pfad: c:\\Users\\humme\\OneDrive\\Dokumente\\Uni Ulm\\ds_law\\backend\\data\\Gerichtsurteile_Openjur\n",
      "Anzahl .txt: 2375\n",
      "Erste 10 Dateien: ['2090187.txt', '2112111.txt', '2112115.txt', '2112117.txt', '2112118.txt', '2112119.txt', '2112121.txt', '2112123.txt', '2124977.txt', '2126821.txt']\n"
     ]
    }
   ],
   "source": [
    "# (.txt) Dateien einlesen\n",
    "DATA_DIR = \"../data/Gerichtsurteile_Openjur\" \n",
    "files = [f for f in os.listdir(DATA_DIR) if f.lower().endswith(\".txt\")]\n",
    "\n",
    "print(\"Pfad:\", os.path.abspath(DATA_DIR))\n",
    "print(\"Anzahl .txt:\", len(files))\n",
    "print(\"Erste 10 Dateien:\", files[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d494b356",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed94d8a",
   "metadata": {},
   "source": [
    "## 2. Textvorverarbeitung und Extraktion zentraler Urteilsbestandteile\n",
    "\n",
    "In diesem Abschnitt werden die eingelesenen Urteilstexte weiterverarbeitet, um für die nachfolgende Analyse relevante Textbestandteile gezielt zu extrahieren. Hierzu zählen insbesondere ein begrenzter Kopfbereich zur Voranalyse sowie der Tenor als Kern der gerichtlichen Entscheidung. Die strukturierte Aufbereitung dieser Textsegmente bildet die Grundlage für Filter-, Klassifikations- und Extraktionsschritte in den folgenden Abschnitten."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c915ba",
   "metadata": {},
   "source": [
    "### 2.1 Erzeugung eines Kopfbereichs zur Voranalyse\n",
    "\n",
    "Da relevante Metadaten wie Gericht, Entscheidungsart und Datum typischerweise am Anfang eines Urteilstextes stehen, wird ein begrenzter Kopfbereich (`head`) aus den ersten Zeichen des Dokuments extrahiert. Dieser verkürzte Textausschnitt dient als effizienter Suchraum für Filter- und Klassifikationsschritte.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28198986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gesamt eingelesen: 2375\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "for fn in files:\n",
    "    case_id = fn.replace(\".txt\", \"\")\n",
    "    path = os.path.join(DATA_DIR, fn)\n",
    "    with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        text = f.read()\n",
    "    rows.append({\"case_id\": case_id, \"text\": text})\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(\"Gesamt eingelesen:\", len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99a88600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head-Länge (Beispiel): 8000\n"
     ]
    }
   ],
   "source": [
    "HEAD_CHARS = 8000\n",
    "df[\"head\"] = df[\"text\"].astype(str).str.slice(0, HEAD_CHARS)\n",
    "\n",
    "print(\"Head-Länge (Beispiel):\", len(df.loc[0, \"head\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b62f66",
   "metadata": {},
   "source": [
    "### 2.2 Extraktion des Tenors\n",
    "\n",
    "Der Tenor enthält die eigentliche gerichtliche Entscheidung und ist daher für die inhaltliche Bewertung besonders relevant. Mithilfe regulärer Ausdrücke wird der Textabschnitt zwischen der Überschrift „Tenor“ und den nachfolgenden Abschnitten (z. B. „Tatbestand“ oder „Gründe“) extrahiert und in einer separaten Spalte gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8326393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tenor vorhanden: 2362 von 2375\n"
     ]
    }
   ],
   "source": [
    "def extract_tenor(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    m_start = re.search(r\"\\bTenor\\b\", text, flags=re.IGNORECASE)\n",
    "    if not m_start:\n",
    "        return \"\"\n",
    "    start = m_start.end()\n",
    "    m_end = re.search(\n",
    "        r\"\\b(Tatbestand|Gründe|Gruende|Entscheidungsgründe|Entscheidungsgruende)\\b\",\n",
    "        text[start:],\n",
    "        flags=re.IGNORECASE\n",
    "    )\n",
    "    end = start + m_end.start() if m_end else min(len(text), start + 8000)\n",
    "    return text[start:end].strip()\n",
    "\n",
    "df[\"tenor\"] = df[\"text\"].apply(extract_tenor)\n",
    "\n",
    "print(\"Tenor vorhanden:\", (df[\"tenor\"].str.len() > 0).sum(), \"von\", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2481ec6a",
   "metadata": {},
   "source": [
    "### 2.3 Identifikation von Landgerichtsurteilen (LG)\n",
    "\n",
    "Im nächsten Schritt werden die Urteile anhand des Kopfbereichs danach gefiltert, ob es sich um Entscheidungen eines Landgerichts handelt. Dazu wird geprüft, ob charakteristische Begriffe wie „Landgericht“ oder die Abkürzung „LG“ im Kopfbereich vorkommen. Auf dieser Grundlage wird eine boolesche Variable erzeugt, die zur Selektion der relevanten Fälle dient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f6ff89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "✅ Echte LG-Urteile (über Zitierzeile): 1189\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Wir suchen nach der Zeile, die mit \"Einfach\" beginnt, gefolgt von \"LG\"\n",
    "# Der Regex r\"Einfach\\s*\\n\\s*LG\" stellt sicher, dass LG direkt darunter steht\n",
    "pattern_zitierung_lg = r\"Einfach\\s*\\n\\s*LG\"\n",
    "\n",
    "# Wir wenden das auf die Spalte an, die den Kopftext enthält\n",
    "df[\"is_landgericht\"] = df[\"head\"].str.contains(pattern_zitierung_lg, regex=True, na=False)\n",
    "\n",
    "# Jetzt erstellen wir den sauberen Dataframe\n",
    "df_lg = df[df[\"is_landgericht\"] == True].copy()\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(f\"✅ Echte LG-Urteile (über Zitierzeile): {len(df_lg)}\")\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85194c82",
   "metadata": {},
   "source": [
    "### 2.4 Segmentierung der Urteile in juristische Abschnitte\n",
    "Für die spätere Extraktion werden die Urteile in juristisch sinnvolle Teile zerlegt: Rubrum, Tenor, Tatbestand und Entscheidungsgründe. Dadurch kann das Modell gezielt relevante Passagen verarbeiten.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "870d2bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_judgment(text):\n",
    "    \"\"\"\n",
    "    Teilt ein Urteil in Rubrum, Tenor, Tatbestand und Entscheidungsgründe auf.\n",
    "    \"\"\"\n",
    "    segments = {\n",
    "        \"rubrum\": \"\",\n",
    "        \"tenor\": \"\",\n",
    "        \"tatbestand\": \"\",\n",
    "        \"entscheidungsgruende\": \"\"\n",
    "    }\n",
    "    \n",
    "    # Muster für die Abschnittsüberschriften\n",
    "    # Das Rubrum ist alles vor dem Tenor\n",
    "    m_tenor = re.search(r\"\\bTenor\\b\", text, re.IGNORECASE)\n",
    "    m_tatbestand = re.search(r\"\\bTatbestand\\b\", text, re.IGNORECASE)\n",
    "    m_gruende = re.search(r\"\\b(Entscheidungsgründe|Gründe)\\b\", text, re.IGNORECASE)\n",
    "    \n",
    "    if m_tenor:\n",
    "        segments[\"rubrum\"] = text[:m_tenor.start()].strip()\n",
    "        \n",
    "        # Tenor bis Tatbestand\n",
    "        if m_tatbestand:\n",
    "            segments[\"tenor\"] = text[m_tenor.end():m_tatbestand.start()].strip()\n",
    "            \n",
    "            # Tatbestand bis Gründe\n",
    "            if m_gruende:\n",
    "                segments[\"tatbestand\"] = text[m_tatbestand.end():m_gruende.start()].strip()\n",
    "                segments[\"entscheidungsgruende\"] = text[m_gruende.end():].strip()\n",
    "            else:\n",
    "                segments[\"tatbestand\"] = text[m_tatbestand.end():].strip()\n",
    "        else:\n",
    "            # Falls kein Tatbestand gefunden wird, Tenor bis zum Ende oder Gründen\n",
    "            if m_gruende:\n",
    "                segments[\"tenor\"] = text[m_tenor.end():m_gruende.start()].strip()\n",
    "                segments[\"entscheidungsgruende\"] = text[m_gruende.end():].strip()\n",
    "            else:\n",
    "                segments[\"tenor\"] = text[m_tenor.end():].strip()\n",
    "                \n",
    "    return segments\n",
    "\n",
    "# Beispielanwendung auf den Dataframe\n",
    "df_lg['segments'] = df_lg['text'].apply(split_judgment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78144122",
   "metadata": {},
   "source": [
    "### 2.5 Aufbereitung der Textsegmente und Definition des Analyse-Prompts\n",
    "Um API- und Token-Limits zu berücksichtigen, werden OpenJur-spezifische Navigationselemente aus dem Rubrum entfernt und alle Abschnitte in ihrer Länge begrenzt. Auf Basis dieser vorverarbeiteten Textsegmente wird ein standardisierter Prompt generiert, der die Extraktion der abgestimmten Variablen im JSON-Format steuert.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "753fa8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_rubrum(rubrum: str) -> str:\n",
    "    if not isinstance(rubrum, str):\n",
    "        return \"\"\n",
    "\n",
    "    blacklist = [\n",
    "        \"rechtsprechung\", \"aktuell\", \"trending\", \"filter\",\n",
    "        \"über openjur\", \"spenden\", \"api\", \"hilfe\",\n",
    "        \"startseite\", \"bundesland\", \"gerichtsbarkeit\",\n",
    "        \"impressum\", \"datenschutz\", \"nutzungsbedingungen\",\n",
    "        \"fachzeitschriften\", \"suchen\", \"changelog\", \"einfach\",\n",
    "        \"json\", \"bibtex\", \"ris\"\n",
    "    ]\n",
    "\n",
    "    lines = []\n",
    "    for line in rubrum.splitlines():\n",
    "        l = line.strip().lower()\n",
    "        if not l:\n",
    "            continue\n",
    "        if any(b in l for b in blacklist):\n",
    "            continue\n",
    "        lines.append(line.strip())\n",
    "\n",
    "    return \"\\n\".join(lines[:3])   \n",
    "\n",
    "def slim_segments(segments):\n",
    "    return {\n",
    "        \"rubrum\": clean_rubrum(segments.get(\"rubrum\") or \"\")[:2500],\n",
    "        \"tenor\": (segments.get(\"tenor\") or \"\")[:4000],\n",
    "        \"tatbestand\": (segments.get(\"tatbestand\") or \"\")[:3500],\n",
    "        \"entscheidungsgruende\": (segments.get(\"entscheidungsgruende\") or \"\")[:7000],\n",
    "    }\n",
    "\n",
    "def get_gemini_prompt(segments):\n",
    "    \"\"\"\n",
    "    Erstellt den finalen Prompt basierend auf den Urteilssegmenten.\n",
    "    \"\"\"\n",
    "    s = slim_segments(segments)   # <--- DAS ist der entscheidende Schritt\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Analysiere die folgenden Abschnitte eines Gerichtsurteils zum Dieselskandal und extrahiere die Variablen präzise als JSON-Liste. \n",
    "\n",
    "### URTEILS-BESTANDTEILE:\n",
    "RUBRUM (Kopfbereich mit Gericht & Datum): \n",
    "{s['rubrum']}\n",
    "\n",
    "TENOR (Ergebnis): \n",
    "{s['tenor']}\n",
    "\n",
    "TATBESTAND (Sachverhalt): \n",
    "{s['tatbestand']}\n",
    "\n",
    "ENTSCHEIDUNGSGRÜNDE (Rechtliche Würdigung): \n",
    "{s['entscheidungsgruende']}\n",
    "\n",
    "### EXTRAKTIONS-AUFGABE:\n",
    "Extrahiere folgende Variablen (bei Nichtfinden 'null' angeben):\n",
    "\n",
    "1. **Input-Variablen (Features):**\n",
    "   - Dieselmotor_Typ\n",
    "   - Art_Abschalteinrichtung\n",
    "   - KBA_Rueckruf\n",
    "   - Fahrzeugstatus\n",
    "   - Fahrzeugmodell_Baureihe\n",
    "   - Update_Status\n",
    "   - Kilometerstand_Kauf\n",
    "   - Kilometerstand_Klageerhebung\n",
    "   - Erwartete_Gesamtlaufleistung\n",
    "   - Kaufdatum\n",
    "   - Uebergabedatum\n",
    "   - Datum_Klageerhebung\n",
    "   - Nachweis_Aufklaerung\n",
    "   - Beklagten_Typ\n",
    "   - Datum_Urteil\n",
    "   - Kaufpreis\n",
    "   - Nacherfuellungsverlangen_Fristsetzung\n",
    "   - Klageziel\n",
    "   - Rechtsgrundlage\n",
    "\n",
    "2. **Zielvariablen (Labels):**\n",
    "   - LABEL_Anspruch_Schadensersatz\n",
    "   - LABEL_Schadensersatzhoehe_Betrag\n",
    "   - LABEL_Schadensersatzhoehe_Range\n",
    "\n",
    "### AUSGABEFORMAT:\n",
    "Antworte NUR mit einem validen JSON-Objekt in einer Liste:\n",
    "[{{\n",
    "  \"case_id\": \"...\",\n",
    "  \"Dieselmotor_Typ\": null,\n",
    "  \"Art_Abschalteinrichtung\": null,\n",
    "  \"KBA_Rueckruf\": null,\n",
    "  \"Fahrzeugstatus\": null,\n",
    "  \"Fahrzeugmodell_Baureihe\": null,\n",
    "  \"Update_Status\": null,\n",
    "  \"Kilometerstand_Kauf\": null,\n",
    "  \"Kilometerstand_Klageerhebung\": null,\n",
    "  \"Erwartete_Gesamtlaufleistung\": null,\n",
    "  \"Kaufdatum\": null,\n",
    "  \"Uebergabedatum\": null,\n",
    "  \"Datum_Klageerhebung\": null,\n",
    "  \"Nachweis_Aufklaerung\": null,\n",
    "  \"Beklagten_Typ\": null,\n",
    "  \"Datum_Urteil\": null,\n",
    "  \"Kaufpreis\": null,\n",
    "  \"Nacherfuellungsverlangen_Fristsetzung\": null,\n",
    "  \"Klageziel\": null,\n",
    "  \"Rechtsgrundlage\": null,\n",
    "  \"LABEL_Anspruch_Schadensersatz\": null,\n",
    "  \"LABEL_Schadensersatzhoehe_Betrag\": null,\n",
    "  \"LABEL_Schadensersatzhoehe_Range\": null\n",
    "}}]\n",
    "\"\"\".strip()\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a84b7b",
   "metadata": {},
   "source": [
    "### 2.7 Erstellung eines Pilot-Inputs im JSONL-Format (Batch-Input):\n",
    "Zur technischen Validierung der Analysepipeline wird ein Pilotdatensatz erzeugt, der eine begrenzte Anzahl von Landgerichtsurteilen umfasst. Für jedes ausgewählte Urteil werden die zuvor definierten Textsegmente extrahiert, zu einem standardisierten Analyse-Prompt zusammengeführt und im JSONL-Format gespeichert. Diese Pilotdatei dient als Testeingabe für die nachgelagerte Verarbeitung über die Gemini-API, bevor eine Skalierung auf den vollständigen Datensatz erfolgt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4f6ac57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pilot erstellt: gemini_batch_input_pilot_10.jsonl\n"
     ]
    }
   ],
   "source": [
    "PILOT_N = 10\n",
    "pilot_path = \"gemini_batch_input_pilot_10.jsonl\"\n",
    "\n",
    "with open(pilot_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for _, row in df_lg.head(PILOT_N).iterrows():\n",
    "        segments = split_judgment(row[\"text\"])\n",
    "        full_prompt = get_gemini_prompt(segments)\n",
    "\n",
    "        payload = {\n",
    "            \"custom_id\": f\"case_{row['case_id']}\",\n",
    "            \"contents\": [{\n",
    "                \"role\": \"user\",\n",
    "                \"parts\": [{\"text\": full_prompt}]\n",
    "            }]\n",
    "        }\n",
    "        f.write(json.dumps(payload, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(\"✅ Pilot erstellt:\", pilot_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26beec66",
   "metadata": {},
   "source": [
    "Der Code dient der inhaltlichen und technischen Validierung der erzeugten Pilotdatei. Hierzu wird der erste Eintrag der JSONL-Datei geladen und exemplarisch ausgegeben, um Struktur, Inhalt und Länge des generierten Analyse-Prompts zu überprüfen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8773a064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case_2090187\n",
      "Analysiere die folgenden Abschnitte eines Gerichtsurteils zum Dieselskandal und extrahiere die Variablen präzise als JSON-Liste. \n",
      "\n",
      "### URTEILS-BESTANDTEILE:\n",
      "RUBRUM (Kopfbereich mit Gericht & Datum): \n",
      "Rechtsgebiet\n",
      "Gericht\n",
      "Informationen\n",
      "\n",
      "TENOR (Ergebnis): \n",
      "I. Die Klage wird abgewiesen.II. Der Kläger hat die Kosten des Rechtsstreits zu tragen.III. Das Urteil ist gegen Sicherheitsleistung in Höhe des 1,1-fachen des zu vollstreckenden Betrags vorläufig vollstreckbar.IV. Der Streitwert wird auf 31.234,00 € festgesetzt.\n",
      "\n",
      "TATBESTAND (Sachverhalt): \n",
      "Der Kläger begehrt Lieferung eines mangelfreien Pkw.Der Kläger erwarb von der Beklagten im Jahr 2014 einen Neuwagen VW Passat 2,0 l TDI für 31.234,00 €. Der Pkw ist von dem \"VW-Abgasskandal\" betroffen. Der Kläger hat die Beklagte im Jahr 2016 durch Anwa\n",
      "Prompt-Länge: 8908\n"
     ]
    }
   ],
   "source": [
    "with open(\"gemini_batch_input_pilot_10.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    first = json.loads(f.readline())\n",
    "\n",
    "print(first[\"custom_id\"])\n",
    "print(first[\"contents\"][0][\"parts\"][0][\"text\"][:800])\n",
    "print(\"Prompt-Länge:\", len(first[\"contents\"][0][\"parts\"][0][\"text\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b8f56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client initialisiert\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "966495f0",
   "metadata": {},
   "source": [
    "## 3.Übergabe an Gemini und Verarbeitung: \n",
    "In diesem Schritt wird die zuvor erzeugte Pilot-JSONL-Datei als Eingabe für die Gemini-API hochgeladen. Die Datei enthält strukturierte Analyseanfragen für mehrere Urteile und wird auf den Servern bereitgestellt, sodass sie anschließend im Rahmen einer Batch- oder sequenziellen Verarbeitung vom Sprachmodell verarbeitet werden kann. Der Upload stellt damit die technische Schnittstelle zwischen der lokalen Vorverarbeitung und der automatisierten Modellanalyse dar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371274c8",
   "metadata": {},
   "source": [
    "### 3.1 Initialisierung des API-Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "17e2b329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client initialisiert\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "import os\n",
    "\n",
    "client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "print(\"Client initialisiert\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d462c1",
   "metadata": {},
   "source": [
    "### 3.2 Upload der JSONL-Datei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ee753d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload: files/6v2xn4ygp6zq\n"
     ]
    }
   ],
   "source": [
    "uploaded = client.files.upload(\n",
    "    file=\"gemini_batch_input_pilot_10.jsonl\",\n",
    "    config={\n",
    "        \"display_name\": \"diesel-lg-pilot-10\",\n",
    "        \"mime_type\": \"text/plain\"\n",
    "    }\n",
    ")\n",
    "print(\"Upload:\", uploaded.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e7aedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = client.batches.create(\n",
    "    model=\"models/gemini-2.5-flash\",\n",
    "    src=uploaded.name,\n",
    "    config={\"display_name\": \"diesel-lg-pilot-10\"}\n",
    ")\n",
    "\n",
    "print(\"Batch gestartet:\", job.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f99f72e",
   "metadata": {},
   "source": [
    "## 4. Aufbereitung der Modellantworten und Erstellung des Analyse-Datensatzes\n",
    "\n",
    "Die in Abschnitt 2 aufbereiteten und gefilterten Urteilstexte liegen bereits in Form einer strukturierten JSONL-Datei vor.\n",
    "Diese Datei dient als direkter Input für die nachgelagerte automatisierte Analyse und wird im Folgenden in das Batch-Verarbeitungssystem eingelesen.\n",
    "\n",
    "(gemini_batch_input_NUR_LG.jsonl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaca577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier Code einfügen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8b810e",
   "metadata": {},
   "source": [
    "### 4.2 Übergabe des Analyse-Datensatzes an die Batch-API\n",
    "\n",
    "Nach der in Abschnitt 2 beschriebenen Aufbereitung der Urteilstexte liegt der vollständige Analyse-Datensatz in Form einer strukturierten JSONL-Datei vor. Diese Datei dient in diesem Schritt als Eingabe für die automatisierte Verarbeitung durch ein großes Sprachmodell.\n",
    "\n",
    "Die JSONL-Datei wird zunächst in das Batch-System hochgeladen. Anschließend wird ein Batch-Verarbeitungsjob gestartet, der die hochgeladene Datei als Eingabequelle verwendet. Für jedes enthaltene Dokument erzeugt das Modell eine strukturierte Antwort gemäß den im Prompt definierten Extraktionsvorgaben.\n",
    "\n",
    "Als Ergebnis des Batch-Jobs stellt die API eine Ausgabedatei bereit, die die Modellantworten zu allen verarbeiteten Urteilen enthält. Diese Ausgabedatei liegt ebenfalls im JSONL-Format vor und bildet die Grundlage für die weitere Aufbereitung und Auswertung der Ergebnisse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f543fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier Code einfügen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a7cbd2",
   "metadata": {},
   "source": [
    "### 4.3 Aufbereitung der Batch-Ergebnisse und Erstellung des Analyse-Datensatzes\n",
    "\n",
    "Die im vorherigen Schritt erzeugte Ausgabedatei des Batch-Jobs liegt zunächst als Rohdaten im JSONL-Format vor. Jede Zeile dieser Datei enthält die strukturierte Modellantwort zu einem einzelnen Landgerichtsurteil.\n",
    "\n",
    "Diese Rohdaten werden lokal gespeichert und anschließend in ein tabellarisches Format überführt. Hierzu werden die relevanten Felder aus den JSON-Strukturen extrahiert und in einer einheitlichen Datenstruktur zusammengeführt, beispielsweise in Form einer CSV-Datei. \n",
    "Der so erzeugte Datensatz bildet die Grundlage für die weitere statistische Auswertung und Analyse in den folgenden Abschnitten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e032793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier Code einfügen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500c339b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f899d3",
   "metadata": {},
   "source": [
    "## 5. Datenaufbereitung\n",
    "\n",
    "In diesem Abschnitt werden die im vorherigen Schritt erzeugten Analyseergebnisse weiterverarbeitet und für die nachgelagerte statistische Auswertung vorbereitet. Grundlage hierfür ist der aus den Batch-Ergebnissen abgeleitete strukturierte Datensatz, der die vom Sprachmodell extrahierten Informationen zu den einzelnen Urteilen enthält.\n",
    "\n",
    "Ziel der Datenaufbereitung ist es, die extrahierten Merkmale in eine konsistente, auswertbare Form zu überführen, fehlende oder uneinheitliche Angaben zu behandeln und die Zielvariablen für die spätere Analyse eindeutig zu definieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b021aba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 1. Setup: Spezialisiertes deutsches Sprachmodell laden\n",
    "try:\n",
    "    nlp = spacy.load(\"de_core_news_lg\")\n",
    "except Exception:\n",
    "    print(\"Bitte installiere das spacy Modell: python -m spacy download de_core_news_lg\")\n",
    "\n",
    "# --- 2. JURISTISCHE TEXTVORVERARBEITUNG ---\n",
    "def legal_preprocess(text):\n",
    "    \"\"\"\n",
    "    Bereitet juristische Texte auf, indem Rauschen entfernt wird, \n",
    "    während rechtlich relevante Zahlen und Kontexte geschützt werden.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str) or not text:\n",
    "        return \"\"\n",
    "\n",
    "    # NEU: START DES URTEILS FINDEN (Rauschschnitt Anfang) ---\n",
    "    # Wir schneiden Webseiten-Menüs (\"trending\", \"suche\" etc.) weg\n",
    "    start_keywords = [\"tenor\", \"entscheidungsgründe\", \"tatbestand\", \"urteil\", \"beschluss\", \"endurteil\"]\n",
    "    text_lower_start = text.lower()\n",
    "    \n",
    "    # Finde die früheste Position eines der Keywords\n",
    "    found_positions = [text_lower_start.find(kw) for kw in start_keywords if text_lower_start.find(kw) != -1]\n",
    "    if found_positions:\n",
    "        text = text[min(found_positions):]\n",
    "\n",
    "    # NEU: ENDE DES URTEILS FINDEN (Rauschschnitt Ende) ---\n",
    "    # Wir schneiden Impressum und Footer weg\n",
    "    end_keywords = [\"impressum\", \"nutzungsbedingungen\", \"nach oben\", \"datenschutz\"]\n",
    "    text_lower_end = text.lower()\n",
    "    for ekw in end_keywords:\n",
    "        e_pos = text_lower_end.find(ekw)\n",
    "        if e_pos != -1:\n",
    "            text = text[:e_pos]\n",
    "            break\n",
    "\n",
    "    # 1. Bereinigung von Rauschen (HTML-Tags, Sonderzeichen)\n",
    "    text = re.sub(r'<.*?>', ' ', text)\n",
    "\n",
    "    # 2. Schutz von Zahlen & Paragraphen (Platzhalter statt Löschen)\n",
    "    # Euro-Beträge schützen\n",
    "    text = re.sub(r'\\d{1,3}(?:\\.\\d{3})*(?:,\\d+)?\\s*(?:EUR|€|Euro)', ' PLATZHALTER_BETRAG ', text)\n",
    "    # Paragraphen schützen\n",
    "    text = re.sub(r'§+\\s*\\d+[a-z]?\\s*(?:\\w+)?', ' PLATZHALTER_PARAGRAPH ', text)\n",
    "    # Jahreszahlen schützen\n",
    "    text = re.sub(r'\\b(19|20)\\d{2}\\b', ' PLATZHALTER_JAHR ', text)\n",
    "\n",
    "    # 3. Kleinschreibung zur Reduktion der Varianz\n",
    "    text = text.lower()\n",
    "\n",
    "    # 4. Tokenisierung und Lemmatisierung mit SpaCy\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # 5. Kontextsensitive Stoppwort-Entfernung\n",
    "    # Wichtige juristische Negationen schützen\n",
    "    protected_negations = {\"nicht\", \"kein\", \"ohne\", \"gegen\", \"trotz\"}\n",
    "    custom_stop_words = nlp.Defaults.stop_words - protected_negations\n",
    "    \n",
    "    # Extraktion der Lemmata (Grundformen)\n",
    "    tokens = [\n",
    "        token.lemma_ for token in doc \n",
    "        if token.text not in custom_stop_words \n",
    "        and not token.is_punct \n",
    "        and not token.is_space\n",
    "        and len(token.text) > 1 # Token mit Länge 1 entfernen\n",
    "    ]\n",
    "    \n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# --- 2.5 HILFSFUNKTIONEN: Simulation + echtes Batch lesen ---\n",
    "def get_llm_text(r: dict) -> str:\n",
    "    # Simulation (simulated_batch_output.jsonl)\n",
    "    if \"text\" in r:\n",
    "        return r[\"text\"]\n",
    "    # Echtes Batch (später)\n",
    "    if \"response\" in r:\n",
    "        return r[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"]\n",
    "    raise KeyError(\"Unbekanntes Ergebnisformat (kein 'text' und kein 'response').\")\n",
    "\n",
    "def parse_llm_json(text: str) -> dict:\n",
    "    # Entfernt ```json ... ``` falls vorhanden\n",
    "    text = re.sub(r\"^```json\\s*|\\s*```$\", \"\", text.strip(), flags=re.MULTILINE)\n",
    "    # Falls außenrum Text steht: ersten JSON-Block extrahieren\n",
    "    m = re.search(r\"(\\{.*\\})\", text, flags=re.DOTALL)\n",
    "    if m:\n",
    "        text = m.group(1)\n",
    "    return json.loads(text)\n",
    "\n",
    "# --- 3. MERGING DER DATEN (URTEILE + EXTRAKTIONEN) ---\n",
    "def merge_and_finalize(judgment_file, batch_results_file):\n",
    "    \"\"\"\n",
    "    Führt die ursprünglichen Urteilstexte mit den Gemini-Extraktionen zusammen.\n",
    "    \"\"\"\n",
    "    # 1. Laden der aufbereiteten LG-Urteile\n",
    "    df_judgments = pd.read_json(judgment_file, lines=True)\n",
    "    df_judgments['case_id'] = df_judgments['custom_id'].str.replace('case_', '')\n",
    "\n",
    "    # 2. Laden der Gemini-Batch-Ergebnisse\n",
    "    with open(batch_results_file, 'r', encoding='utf-8') as f:\n",
    "        results = [json.loads(line) for line in f]\n",
    "    \n",
    "    extracted_rows = []\n",
    "    for r in results:\n",
    "        try:\n",
    "            case_id = r['custom_id'].replace('case_', '')\n",
    "            llm_text = get_llm_text(r)\n",
    "            content = parse_llm_json(llm_text)\n",
    "            content['case_id'] = case_id\n",
    "            extracted_rows.append(content)\n",
    "        except Exception:\n",
    "            continue\n",
    "            \n",
    "    df_extracted = pd.DataFrame(extracted_rows)\n",
    "\n",
    "    # 3. Zusammenführung über case_id \n",
    "    df_final = pd.merge(df_judgments, df_extracted, on='case_id', how='inner')\n",
    "\n",
    "    # 4. Textverarbeitung anwenden\n",
    "    print(\"Starte Textvorverarbeitung...\")\n",
    "    df_final['cleaned_text'] = df_final['text'].apply(legal_preprocess)\n",
    "\n",
    "    return df_final\n",
    "\n",
    "# --- 4. MODELL-VORBEREITUNG (TF-IDF) ---\n",
    "tfidf = TfidfVectorizer(\n",
    "    ngram_range=(1, 2),   # Bigramme erhalten Wortzusammenhänge\n",
    "    max_features=1000,    # Reduktion der Komplexität\n",
    "    min_df=5              # Seltene Begriffe ignorieren\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8f2b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_FILE = \"simulated_batch_output.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245b4500",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = merge_and_finalize(\n",
    "    judgment_file=\"lg_judgments.jsonl\",\n",
    "    batch_results_file=RESULTS_FILE\n",
    ")\n",
    "\n",
    "print(df_final.shape)\n",
    "df_final.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80ca0eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Datei gefunden: 2090187.txt\n",
      "----------------------------------------\n",
      "Endurteil 23.05. Platzhalter_jahr 21 658 16 Zitierung einfach lg Bayreuth Endurteil 23.05. Platzhalter_jahr 21 658 16 M. Fundstelle lg Bayreuth Endurteil 23.05. Platzhalter_jahr 21 658 16 Openjur Platzhalter_jahr 9516 Bibtex ris json lg Bayreuth Endurteil 23.05. Platzhalter_jahr 21 658 16 fundstell Openjur Platzhalter_jahr 9516 Rechtskraft Option Zitierung Version Tenor i. Klage abgewiesen.ii Kläger Kosten rechtsstreit tragen.iii Urteil gegen Sicherheitsleistung Höhe 1,1-fache vollstreckend betr...\n"
     ]
    }
   ],
   "source": [
    "##Test der Datenvorverarbeitung auf einzelne Datei\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Pfad zu den Gerichtsurteilen\n",
    "base_path = Path.cwd().parent \n",
    "pfad_zu_urteilen = base_path / \"data\" / \"Gerichtsurteile_Openjur\"\n",
    "\n",
    "# Test mit einer Datei aus deiner Liste\n",
    "test_datei_name = \"2090187.txt\" \n",
    "voller_pfad = pfad_zu_urteilen / test_datei_name\n",
    "\n",
    "try:\n",
    "    with open(voller_pfad, \"r\", encoding=\"utf-8\") as f:\n",
    "        original_text = f.read()\n",
    "    \n",
    "    # Schneller Test mit 2.000 Zeichen\n",
    "    test_schnipsel = original_text[:2000]\n",
    "    gereinigter_text = legal_preprocess(test_schnipsel)\n",
    "    \n",
    "    print(f\"✅ Datei gefunden: {test_datei_name}\")\n",
    "    print(\"-\" * 40)\n",
    "    print(gereinigter_text[:500] + \"...\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Pfad falsch. Er sucht hier: {voller_pfad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb42f4d",
   "metadata": {},
   "source": [
    "Nachweis der Daten-Pipeline (Schritt 1 & 2)\n",
    "Pfad-Validierung: Python-Skript versteht die Ordnerstruktur und kann die über 2.300 .txt-Dateien einlesen. \n",
    "Filter-Logik: Die Statistik zeigt, dass dein Code erfolgreich zwischen Landgerichten (LG) und Oberlandesgerichten (OLG) unterscheidet. \n",
    "Rauschschnitt (Slicing): Die Menüführung der Webseite (Trending, Spenden, Suche) ist abgeschnitten\n",
    "Abstraktion durch Platzhalter: Dass PLATZHALTER_JAHR auftaucht, bestätigt, dass deine Regex-Logik funktioniert. Das Modell wird dadurch gezwungen, juristische Muster (wie „Klage abgewiesen“) zu lernen, statt sich an unwichtigen spezifischen Zahlen festzubeißen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05160c8f",
   "metadata": {},
   "source": [
    "## 6. Analyse und Auswertung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb49984b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

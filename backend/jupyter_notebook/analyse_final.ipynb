{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f87c4b39",
   "metadata": {},
   "source": [
    "## 1. Datenimport und Initialisierung\n",
    "\n",
    "In diesem Abschnitt werden die OpenJur-Urteilstexte aus dem Datenverzeichnis eingelesen und die technische Datenbasis f√ºr die nachfolgenden Verarbeitungsschritte geschaffen. Dazu werden die ben√∂tigten Bibliotheken importiert und die verf√ºgbaren Textdateien identifiziert.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972de4e7",
   "metadata": {},
   "source": [
    "### 1.1 Import der ben√∂tigten Bibliotheken\n",
    "\n",
    "Zu Beginn werden die f√ºr die weitere Verarbeitung erforderlichen Python-Bibliotheken importiert. Diese umfassen Funktionen f√ºr Dateizugriffe, regul√§re Ausdr√ºcke, Datenverarbeitung mit Pandas sowie den Export der Ergebnisse im JSON-Format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "58f86b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61a736b",
   "metadata": {},
   "source": [
    "### 1.2 Einlesen der OpenJur-Urteilstexte \n",
    "\n",
    "In diesem Schritt werden alle identifizierten Urteilstexte aus dem Datenverzeichnis eingelesen. Jede Datei wird √ºber den Dateinamen einer eindeutigen Fallkennung (`case_id`) zugeordnet. Die Texte bilden die Rohdatenbasis f√ºr die nachfolgenden Extraktions- und Filterprozesse. Der Datenpfad wird im Code parametriert (`DATA_DIR`), um eine reproduzierbare Ausf√ºhrung zu gew√§hrleisten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1bef8dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pfad: c:\\Users\\humme\\OneDrive\\Dokumente\\Uni Ulm\\ds_law\\backend\\data\\Gerichtsurteile_Openjur\n",
      "Anzahl .txt: 2375\n",
      "Erste 10 Dateien: ['2090187.txt', '2112111.txt', '2112115.txt', '2112117.txt', '2112118.txt', '2112119.txt', '2112121.txt', '2112123.txt', '2124977.txt', '2126821.txt']\n"
     ]
    }
   ],
   "source": [
    "# (.txt) Dateien einlesen\n",
    "DATA_DIR = \"../data/Gerichtsurteile_Openjur\" \n",
    "files = [f for f in os.listdir(DATA_DIR) if f.lower().endswith(\".txt\")]\n",
    "\n",
    "print(\"Pfad:\", os.path.abspath(DATA_DIR))\n",
    "print(\"Anzahl .txt:\", len(files))\n",
    "print(\"Erste 10 Dateien:\", files[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d494b356",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed94d8a",
   "metadata": {},
   "source": [
    "## 2. Extraktion relevanter Urteilsbestandteile und Selektion der Landgerichtsurteile\n",
    "\n",
    "In diesem Abschnitt werden die eingelesenen Urteilstexte weiterverarbeitet, um f√ºr die nachfolgende Analyse relevante Textbestandteile gezielt zu extrahieren. Hierzu z√§hlen insbesondere ein begrenzter Kopfbereich zur Voranalyse sowie der Tenor als Kern der gerichtlichen Entscheidung. Die strukturierte Aufbereitung dieser Textsegmente bildet die Grundlage f√ºr Filter-, Klassifikations- und Extraktionsschritte in den folgenden Abschnitten."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c915ba",
   "metadata": {},
   "source": [
    "### 2.1 Aufbau des DataFrames und Extraktion eines Kopfbereichs\n",
    "\n",
    "Die eingelesenen Texte werden in einem DataFrame (`df`) gespeichert. Zus√§tzlich wird ein begrenzter Kopfbereich (`head`) aus den ersten Zeichen extrahiert, da strukturelle Metadaten wie Gerichtstyp, Entscheidungsart und Zitierzeilen typischerweise am Anfang des Dokuments auftreten. Dieser Kopfbereich dient als effizienter Suchraum f√ºr die sp√§tere Identifikation von Landgerichtsurteilen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "28198986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gesamt eingelesen: 2375\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "for fn in files:\n",
    "    case_id = fn.replace(\".txt\", \"\")\n",
    "    path = os.path.join(DATA_DIR, fn)\n",
    "    with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        text = f.read()\n",
    "    rows.append({\"case_id\": case_id, \"text\": text})\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(\"Gesamt eingelesen:\", len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "99a88600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head-L√§nge (Beispiel): 8000\n"
     ]
    }
   ],
   "source": [
    "HEAD_CHARS = 8000\n",
    "df[\"head\"] = df[\"text\"].astype(str).str.slice(0, HEAD_CHARS)\n",
    "\n",
    "print(\"Head-L√§nge (Beispiel):\", len(df.loc[0, \"head\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b62f66",
   "metadata": {},
   "source": [
    "### 2.2 Extraktion des Tenors\n",
    "\n",
    "Der Tenor enth√§lt die eigentliche gerichtliche Entscheidung und ist daher f√ºr die inhaltliche Bewertung besonders relevant. Mithilfe regul√§rer Ausdr√ºcke wird der Textabschnitt zwischen der √úberschrift ‚ÄûTenor‚Äú und den nachfolgenden Abschnitten (z. B. ‚ÄûTatbestand‚Äú oder ‚ÄûGr√ºnde‚Äú) extrahiert und in einer separaten Spalte gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6fae0b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tenor vorhanden: 2362 von 2375\n"
     ]
    }
   ],
   "source": [
    "def extract_tenor(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    m_start = re.search(r\"\\bTenor\\b\", text, flags=re.IGNORECASE)\n",
    "    if not m_start:\n",
    "        return \"\"\n",
    "\n",
    "    start = m_start.end()\n",
    "\n",
    "    # Begrenztes Suchfenster nach dem Tenor (robuster gegen Navigation)\n",
    "    window = text[start:start + 20000]\n",
    "\n",
    "    m_end = re.search(\n",
    "        r\"\\b(Tatbestand|Gr√ºnde|Gruende|Entscheidungsgr√ºnde|Entscheidungsgruende)\\b\",\n",
    "        window,\n",
    "        flags=re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    end = start + m_end.start() if m_end else min(len(text), start + 8000)\n",
    "    return text[start:end].strip()\n",
    "df[\"tenor\"] = df[\"text\"].apply(extract_tenor)\n",
    "print(\"Tenor vorhanden:\", (df[\"tenor\"].str.len() > 0).sum(), \"von\", len(df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2481ec6a",
   "metadata": {},
   "source": [
    "### 2.3 Identifikation von Landgerichtsurteilen (LG)\n",
    "\n",
    "Die Selektion der Landgerichtsurteile erfolgt anhand einer OpenJur-spezifischen Zitierzeile im Kopfbereich (Regex: ‚ÄûEinfach‚Äú gefolgt von ‚ÄûLG‚Äú). Auf dieser Grundlage wird eine boolesche Variable erzeugt und der Teilkorpus df_lg gebildet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8f6ff89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "‚úÖ Echte LG-Urteile (√ºber Zitierzeile): 1189\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Wir suchen nach der Zeile, die mit \"Einfach\" beginnt, gefolgt von \"LG\"\n",
    "# Der Regex r\"Einfach\\s*\\n\\s*LG\" stellt sicher, dass LG direkt darunter steht\n",
    "pattern_zitierung_lg = r\"Einfach\\s*\\n\\s*LG\"\n",
    "\n",
    "# Wir wenden das auf die Spalte an, die den Kopftext enth√§lt\n",
    "df[\"is_landgericht\"] = df[\"head\"].str.contains(pattern_zitierung_lg, regex=True, na=False)\n",
    "\n",
    "# Jetzt erstellen wir den sauberen Dataframe\n",
    "df_lg = df[df[\"is_landgericht\"] == True].copy()\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(f\"‚úÖ Echte LG-Urteile (√ºber Zitierzeile): {len(df_lg)}\")\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85194c82",
   "metadata": {},
   "source": [
    "### 2.4 Segmentierung der Urteile in juristische Abschnitte\n",
    "F√ºr die sp√§tere Extraktion werden die Urteile in juristisch sinnvolle Teile zerlegt: Rubrum, Tenor, Tatbestand und Entscheidungsgr√ºnde. Dadurch kann das Modell gezielt relevante Passagen verarbeiten.\n",
    "Die Segmentierung dient dazu, sp√§tere Analysen gezielt auf entscheidungsrelevante Abschnitte (insb. Tenor und Entscheidungsgr√ºnde) zu fokussieren.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "870d2bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_judgment(text):\n",
    "    \"\"\"\n",
    "    Teilt ein Urteil in Rubrum, Tenor, Tatbestand und Entscheidungsgr√ºnde auf.\n",
    "    \"\"\"\n",
    "    segments = {\n",
    "        \"rubrum\": \"\",\n",
    "        \"tenor\": \"\",\n",
    "        \"tatbestand\": \"\",\n",
    "        \"entscheidungsgruende\": \"\"\n",
    "    }\n",
    "    \n",
    "    # Muster f√ºr die Abschnitts√ºberschriften\n",
    "    # Das Rubrum ist alles vor dem Tenor\n",
    "    m_tenor = re.search(r\"\\bTenor\\b\", text, re.IGNORECASE)\n",
    "    m_tatbestand = re.search(r\"\\bTatbestand\\b\", text, re.IGNORECASE)\n",
    "    m_gruende = re.search(r\"\\b(Entscheidungsgr√ºnde|Entscheidungsgruende|Gr√ºnde|Gruende)\\b\", text, re.IGNORECASE)\n",
    "    \n",
    "    if m_tenor:\n",
    "        segments[\"rubrum\"] = text[:m_tenor.start()].strip()\n",
    "        \n",
    "        # Tenor bis Tatbestand\n",
    "        if m_tatbestand:\n",
    "            segments[\"tenor\"] = text[m_tenor.end():m_tatbestand.start()].strip()\n",
    "            \n",
    "            # Tatbestand bis Gr√ºnde\n",
    "            if m_gruende:\n",
    "                segments[\"tatbestand\"] = text[m_tatbestand.end():m_gruende.start()].strip()\n",
    "                segments[\"entscheidungsgruende\"] = text[m_gruende.end():].strip()\n",
    "            else:\n",
    "                segments[\"tatbestand\"] = text[m_tatbestand.end():].strip()\n",
    "        else:\n",
    "            # Falls kein Tatbestand gefunden wird, Tenor bis zum Ende oder Gr√ºnden\n",
    "            if m_gruende:\n",
    "                segments[\"tenor\"] = text[m_tenor.end():m_gruende.start()].strip()\n",
    "                segments[\"entscheidungsgruende\"] = text[m_gruende.end():].strip()\n",
    "            else:\n",
    "                segments[\"tenor\"] = text[m_tenor.end():].strip()\n",
    "                \n",
    "    return segments\n",
    "\n",
    "# Beispielanwendung auf den Dataframe\n",
    "df_lg['segments'] = df_lg['text'].apply(split_judgment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78144122",
   "metadata": {},
   "source": [
    "## 3 Prompt-Generierung und Pilotierung der LLM-Extraktion (Gemini Batch)\n",
    "Um API- und Token-Limits zu ber√ºcksichtigen, werden OpenJur-spezifische Navigationselemente aus dem Rubrum entfernt und alle Abschnitte in ihrer L√§nge begrenzt. Auf Basis dieser vorverarbeiteten Textsegmente wird ein standardisierter Prompt generiert, der die Extraktion der abgestimmten Variablen im JSON-Format steuert.\n",
    "Die segmentweise L√§ngenbegrenzung dient der Einhaltung von Token-Limits sowie der Reduktion von Kosten und Laufzeit, ohne entscheidungsrelevante Passagen (insb. Tenor und Entscheidungsgr√ºnde) zu verlieren.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d039d706",
   "metadata": {},
   "source": [
    "### 3.1 Aufbereitung der Segmente und Definition des Extraktions-Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af70046",
   "metadata": {},
   "source": [
    "Der Prompt wurde so konzipiert, dass er neben technischen Features (Motor, Kilometer) gezielt die Anforderungen der Aufgabenstellung erf√ºllt. Kernaspekte sind die Identifikation des Gerichtstyps sowie die Differenzierung der Zielvariable in Schadensersatz, Klageabweisung und prozessuale Sonderf√§lle (‚ÄûSonstige‚Äú). Durch explizite Anweisungen zum Ausschluss von Zinsen und zur Erkennung von Streitwertbeschl√ºssen wird eine hohe Datenqualit√§t f√ºr das anschlie√üende Machine Learning sichergestellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ed232f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_rubrum(rubrum: str) -> str:\n",
    "    if not isinstance(rubrum, str):\n",
    "        return \"\"\n",
    "\n",
    "    blacklist = [\n",
    "        \"rechtsprechung\", \"aktuell\", \"trending\", \"filter\",\n",
    "        \"√ºber openjur\", \"spenden\", \"api\", \"hilfe\",\n",
    "        \"startseite\", \"bundesland\", \"gerichtsbarkeit\",\n",
    "        \"impressum\", \"datenschutz\", \"nutzungsbedingungen\",\n",
    "        \"fachzeitschriften\", \"suchen\", \"changelog\", \"einfach\",\n",
    "        \"json\", \"bibtex\", \"ris\"\n",
    "    ]\n",
    "\n",
    "    lines = []\n",
    "    for line in rubrum.splitlines():\n",
    "        l = line.strip().lower()\n",
    "        if not l:\n",
    "            continue\n",
    "        if any(b in l for b in blacklist):\n",
    "            continue\n",
    "        lines.append(line.strip())\n",
    "\n",
    "    return \"\\n\".join(lines[:5])   \n",
    "\n",
    "def slim_segments(segments):\n",
    "    return {\n",
    "        \"rubrum\": clean_rubrum(segments.get(\"rubrum\") or \"\")[:2500],\n",
    "        \"tenor\": (segments.get(\"tenor\") or \"\")[:4000],\n",
    "        \"tatbestand\": (segments.get(\"tatbestand\") or \"\")[:3500],\n",
    "        \"entscheidungsgruende\": (segments.get(\"entscheidungsgruende\") or \"\")[:7000],\n",
    "    }\n",
    "def get_gemini_prompt(segments):\n",
    "    \"\"\"\n",
    "    Erstellt den finalen Prompt basierend auf den Urteilssegmenten.\n",
    "    \"\"\"\n",
    "    s = slim_segments(segments)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Analysiere die folgenden Abschnitte eines Gerichtsurteils zum Dieselskandal und extrahiere die Variablen pr√§zise als JSON-Liste. \n",
    "\n",
    "### URTEILS-BESTANDTEILE:\n",
    "RUBRUM (Kopfbereich mit Gericht & Datum): \n",
    "{s['rubrum']}\n",
    "\n",
    "TENOR (Ergebnis): \n",
    "{s['tenor']}\n",
    "\n",
    "TATBESTAND (Sachverhalt): \n",
    "{s['tatbestand']}\n",
    "\n",
    "ENTSCHEIDUNGSGR√úNDE (Rechtliche W√ºrdigung): \n",
    "{s['entscheidungsgruende']}\n",
    "\n",
    "### EXTRAKTIONS-AUFGABE:\n",
    "Extrahiere folgende Variablen (bei Nichtfinden 'null' angeben):\n",
    "\n",
    "WICHTIG (Validierung & Datenqualit√§t):\n",
    "1) **Gerichtstyp** muss explizit angegeben werden (z.B. \"Landgericht\", \"Oberlandesgericht\", \"Amtsgericht\").  \n",
    "2) **Sonstige-Kategorie (prozessuale Dokumente):** Falls das Dokument **keine materielle Entscheidung √ºber einen Schadensersatzanspruch** enth√§lt (z.B. nur Streitwertfestsetzung/-beschluss, Prozesskostenhilfe/PKH, Kostenentscheidung ohne Sachentscheidung, Ablehnungsgesuch/Befangenheit, rein prozessualer Beschluss), dann setze zwingend:\n",
    "   - LABEL_Anspruch_Schadensersatz = false\n",
    "   - LABEL_Schadensersatzhoehe_Betrag = null\n",
    "   - LABEL_Schadensersatzhoehe_Range = \"Sonstige\"\n",
    "3) **Betrag ohne Zinsen:** LABEL_Schadensersatzhoehe_Betrag ist **ohne Zinsen/Verzugszinsen/Nebenforderungen** anzugeben.\n",
    "\n",
    "1. **Input-Variablen (Features):**\n",
    "   - Dieselmotor_Typ: (Beispiel: \"EA 189\", \"EA 288\")\n",
    "   - Art_Abschalteinrichtung: (Beispiel: \"Umschaltlogik\", \"Thermofenster\")\n",
    "   - KBA_Rueckruf: (Boolean: true/false - Beispiel: true)\n",
    "   - Fahrzeugstatus: (\"Neuwagen\" oder \"Gebrauchtwagen\")\n",
    "   - Fahrzeugmodell_Baureihe: (Beispiel: \"VW Golf 2.0 TDI\")\n",
    "   - Update_Status: (Boolean: true/false/null - Beispiel: false)\n",
    "   - Kilometerstand_Kauf: (Integer - Beispiel: 15200)\n",
    "   - Kilometerstand_Klageerhebung: (Integer - Beispiel: 45000)\n",
    "   - Erwartete_Gesamtlaufleistung: (Integer - Beispiel: 250000)\n",
    "   - Kaufdatum: (Date YYYY-MM-DD - Beispiel: 2014-05-12)\n",
    "   - Uebergabedatum: (Date YYYY-MM-DD - Beispiel: 2014-05-20)\n",
    "   - Datum_Klageerhebung: (Date YYYY-MM-DD - Beispiel: 2018-11-03)\n",
    "   - Beklagten_Typ: (\"H√§ndler\" oder \"Hersteller\")\n",
    "   - Datum_Urteil: (Date YYYY-MM-DD - Beispiel: 2019-12-17)\n",
    "   - Kaufpreis: (Float in EUR - Beispiel: 25900.00)\n",
    "   - Nacherfuellungsverlangen_Fristsetzung: (\"Ja\", \"Nein\", \"Entbehrlich\")\n",
    "   - Klageziel: (\"R√ºckabwicklung\", \"Minderung\", \"Schadensersatz\")\n",
    "   - Rechtsgrundlage: (Beispiel: \"¬ß 826 BGB\", \"¬ß 437 BGB\")\n",
    "\n",
    "2. **Zielvariablen (Labels):**\n",
    "   - LABEL_Anspruch_Schadensersatz (Boolean: true/false - Beispiel: true)\n",
    "   - LABEL_Schadensersatzhoehe_Betrag (Float in EUR - Beispiel: 18450.50)\n",
    "   - LABEL_Schadensersatzhoehe_Range (Beispiel: \"< 5000\", \"5000-10000\", \"10000-15000\", \"15000-20000\", \"20000-25000\", \"> 25000\", \"Klage abgewiesen\")\n",
    "\n",
    "### AUSGABEFORMAT:\n",
    "Antworte NUR mit einem validen JSON-Objekt in einer Liste:\n",
    "[{{\n",
    "  \"case_id\": \"...\",\n",
    "  \"Gerichtstyp\": null,\n",
    "  \"Dieselmotor_Typ\": null,\n",
    "  \"Art_Abschalteinrichtung\": null,\n",
    "  \"KBA_Rueckruf\": null,\n",
    "  \"Fahrzeugstatus\": null,\n",
    "  \"Fahrzeugmodell_Baureihe\": null,\n",
    "  \"Update_Status\": null,\n",
    "  \"Kilometerstand_Kauf\": null,\n",
    "  \"Kilometerstand_Klageerhebung\": null,\n",
    "  \"Erwartete_Gesamtlaufleistung\": null,\n",
    "  \"Kaufdatum\": null,\n",
    "  \"Uebergabedatum\": null,\n",
    "  \"Datum_Klageerhebung\": null,\n",
    "  \"Nachweis_Aufklaerung\": null,\n",
    "  \"Beklagten_Typ\": null,\n",
    "  \"Datum_Urteil\": null,\n",
    "  \"Kaufpreis\": null,\n",
    "  \"Nacherfuellungsverlangen_Fristsetzung\": null,\n",
    "  \"Klageziel\": null,\n",
    "  \"Rechtsgrundlage\": null,\n",
    "  \"LABEL_Anspruch_Schadensersatz\": null,\n",
    "  \"LABEL_Schadensersatzhoehe_Betrag\": null,\n",
    "  \"LABEL_Schadensersatzhoehe_Range\": null\n",
    "}}]\n",
    "\"\"\".strip()\n",
    "\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbbbf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "from google import genai\n",
    "\n",
    "# --- 1. EINSTELLUNGEN ---\n",
    "# Wir nutzen dein gew√ºnschtes Modell. \n",
    "# Durch deine Kreditkarte fallen die strengen Limits weg.\n",
    "MODEL_NAME = \"models/gemini-2.5-flash\"\n",
    "\n",
    "# API Key Client starten\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\") \n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "# --- 2. HILFSFUNKTIONEN ---\n",
    "# Diese Funktion holt das saubere JSON aus der KI-Antwort\n",
    "def extract_json_from_llm(text: str):\n",
    "    text = re.sub(r\"^```json\\s*|\\s*```$\", \"\", text.strip(), flags=re.MULTILINE)\n",
    "    m = re.search(r\"(\\[\\s*\\{.*?\\}\\s*\\]|\\{.*?\\})\", text, flags=re.DOTALL)\n",
    "    if not m: raise ValueError(\"Kein JSON gefunden\")\n",
    "    return json.loads(m.group(1))\n",
    "\n",
    "# --- 3. DER HAUPT-LAUF ---\n",
    "# Wir kopieren deine Daten zur Sicherheit\n",
    "# HINWEIS: Stelle sicher, dass 'df_lg' aus den vorherigen Kapiteln geladen ist!\n",
    "working_df = df_lg.copy() \n",
    "results = []\n",
    "errors = []\n",
    "\n",
    "print(f\"üöÄ Starte 'Pay-as-you-go' Lauf f√ºr {len(working_df)} F√§lle mit {MODEL_NAME}...\")\n",
    "print(\"Das wird jetzt einige Minuten dauern. Du kannst zuschauen, wie der Z√§hler hochgeht.\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for index, row in working_df.iterrows():\n",
    "    case_id = row['case_id']\n",
    "    \n",
    "    # Sicherung: Falls mal das Internet wackelt, 3x probieren\n",
    "    for attempt in range(3):\n",
    "        try:\n",
    "            # 1. Prompt bauen (nutzt deine Funktion aus Kapitel 3)\n",
    "            prompt = get_gemini_prompt(row[\"segments\"])\n",
    "            \n",
    "            # 2. Anfrage an Google (Direkt, ohne Batch-Upload)\n",
    "            response = client.models.generate_content(\n",
    "                model=MODEL_NAME,\n",
    "                contents=prompt\n",
    "            )\n",
    "            \n",
    "            # 3. Antwort verarbeiten\n",
    "            data = extract_json_from_llm(response.text)\n",
    "            \n",
    "            # Falls die KI eine Liste [{...}] schickt, packen wir sie aus\n",
    "            if isinstance(data, list):\n",
    "                data = data[0]\n",
    "            \n",
    "            # Case ID hinzuf√ºgen, damit wir wissen, welches Urteil das ist\n",
    "            data[\"case_id\"] = case_id\n",
    "            results.append(data)\n",
    "            \n",
    "            # Fortschrittsanzeige alle 20 F√§lle\n",
    "            if (index + 1) % 20 == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                print(f\"‚úÖ {index + 1} von {len(working_df)} geschafft. (Dauer: {elapsed:.1f}s)\")\n",
    "            \n",
    "            # Erfolg! Wir brechen den Retry-Versuch ab und gehen zum n√§chsten Fall\n",
    "            break \n",
    "\n",
    "        except Exception as e:\n",
    "            error_msg = str(e)\n",
    "            # Falls Google \"Stop\" sagt (429), warten wir kurz\n",
    "            if \"429\" in error_msg or \"RESOURCE_EXHAUSTED\" in error_msg:\n",
    "                if attempt < 2:\n",
    "                    time.sleep(5) # 5 Sekunden warten\n",
    "                    continue # N√§chster Versuch\n",
    "                else:\n",
    "                    print(f\"‚ùå Limit-Fehler bei Fall {case_id} (√ºbersprungen).\")\n",
    "                    errors.append({\"case_id\": case_id, \"error\": \"429 Limit\"})\n",
    "            else:\n",
    "                # Anderer Fehler (z.B. Text zu lang)\n",
    "                print(f\"‚ö†Ô∏è Fehler bei Fall {case_id}: {error_msg}\")\n",
    "                errors.append({\"case_id\": case_id, \"error\": error_msg})\n",
    "                break\n",
    "\n",
    "print(\"\\nüéâ FERTIG!\")\n",
    "print(f\"Erfolgreich extrahiert: {len(results)}\")\n",
    "\n",
    "# --- 4. SPEICHERN ---\n",
    "# Wir speichern das Ergebnis sofort als CSV\n",
    "df_final = pd.DataFrame(results)\n",
    "filename = \"gemini_results_paid_complete.csv\"\n",
    "df_final.to_csv(filename, index=False)\n",
    "print(f\"‚úÖ Daten gespeichert als: {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f99f72e",
   "metadata": {},
   "source": [
    "## 4 Verarbeitung der Modellantworten und Erstellung des Extraktions-Datensatzes\n",
    "\n",
    "In diesem Abschnitt werden die Batch-Ausgaben der Gemini-API eingelesen, validiert und in ein tabellarisches Format √ºberf√ºhrt. Zum Zeitpunkt der aktuellen Notebook-Version liegt lediglich der Pilot-Workflow vor; der Code zur Verarbeitung des vollst√§ndigen Batch-Outputs wird nach Abschluss des Batch-Jobs erg√§nzt.\n",
    "\n",
    "(gemini_batch_input_NUR_LG.jsonl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9979e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- NEUER ABSCHNITT 4 (Zusammengefasst) ---\n",
    "# Konfiguration: Wir nutzen die CSV aus dem bezahlten Lauf\n",
    "RESULTS_FILENAME = \"gemini_results_paid_complete.csv\"\n",
    "\n",
    "print(f\"System pr√ºft Import von: {RESULTS_FILENAME}\")\n",
    "\n",
    "# Pr√ºfung und Laden\n",
    "if os.path.exists(RESULTS_FILENAME):\n",
    "    # 1. CSV laden\n",
    "    df_extracted = pd.read_csv(RESULTS_FILENAME)\n",
    "    \n",
    "    # 2. WICHTIG: case_id muss f√ºr den Merge ein String sein\n",
    "    df_extracted[\"case_id\"] = df_extracted[\"case_id\"].astype(str)\n",
    "    \n",
    "    print(f\"‚úÖ Erfolgreich geladen: {len(df_extracted)} Zeilen\")\n",
    "    print(\"Vorschau:\")\n",
    "    print(df_extracted.head(3))\n",
    "    \n",
    "    # Hier simulieren wir die Variablen, die der alte Code erwartet h√§tte,\n",
    "    # damit Abschnitt 4.3 (Merge) gleich fehlerfrei l√§uft.\n",
    "    print(\"\\nDaten sind bereit f√ºr die Zusammenf√ºhrung (Merge) in Abschnitt 4.3.\")\n",
    "\n",
    "else:\n",
    "    print(f\"‚ùå FEHLER: Datei '{RESULTS_FILENAME}' nicht gefunden.\")\n",
    "    print(\"Bitte stelle sicher, dass der Code-Block 'DER HAUPT-LAUF' (Kapitel 3.3) komplett durchgelaufen ist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2911c4f4",
   "metadata": {},
   "source": [
    "### 4.3 Zusammenf√ºhrung mit Metadaten und Speicherung (CSV/Parquet) (Platzhalter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500c339b",
   "metadata": {},
   "source": [
    "In diesem finalen Schritt der Datenextraktion werden die bereinigten Modellantworten (df_clean_labels) mit den urspr√ºnglichen Metadaten und Urteilstexten der Landgerichte (df_lg) zusammengef√ºhrt. Die Verkn√ºpfung erfolgt √ºber die eindeutige case_id, um eine konsistente Zuordnung zwischen den technischen Features (z. B. Motortyp, Kilometerstand) und den Zielvariablen (Schadensersatzh√∂he, Anspruchsstatus) zu gew√§hrleisten.\n",
    "Der resultierende Gesamtdatensatz wird in zwei Formaten exportiert:\n",
    "* CSV-Format: Zur einfachen manuellen √úberpr√ºfung der Extraktionsergebnisse in Tabellenkalkulationsprogrammen.\n",
    "* Parquet-Format: Zur effizienten Weiterverarbeitung in der Machine-Learning-Phase (Kapitel 5), da dieses Format Datentypen (z. B. numerische Betr√§ge ohne Zinsen) verlustfrei speichert.\n",
    "Damit ist die Datenbasis f√ºr die nachfolgende semantische Analyse und Modellierung vollst√§ndig vorbereitet.---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffac4ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Datentypen angleichen (WICHTIG f√ºr den Merge)\n",
    "# Wir machen beide IDs zu Strings, damit sie sicher zueinander finden\n",
    "df_lg[\"case_id\"] = df_lg[\"case_id\"].astype(str)\n",
    "df_extracted[\"case_id\"] = df_extracted[\"case_id\"].astype(str)\n",
    "\n",
    "# 2. Merge durchf√ºhren\n",
    "df_dataset = pd.merge(\n",
    "    df_lg,\n",
    "    df_extracted,\n",
    "    on=\"case_id\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Merge abgeschlossen: {df_dataset.shape[0]} Urteile im Gesamtdatensatz\")\n",
    "\n",
    "# 3. FEHLENDE SPALTE \"target_label\" ERSTELLEN\n",
    "\n",
    "def determine_label(row):\n",
    "    # Fall 1: Sonstige (Prozessuale Urteile)\n",
    "    if str(row.get(\"LABEL_Schadensersatzhoehe_Range\")).lower() == \"sonstige\":\n",
    "        return \"Sonstige\"\n",
    "    \n",
    "    # Fall 2: Anspruch bejaht (True)\n",
    "    val = row.get(\"LABEL_Anspruch_Schadensersatz\")\n",
    "    # Manchmal ist es ein String \"true\" oder ein echtes Boolean True\n",
    "    if str(val).lower() == \"true\":\n",
    "        return \"Schadensersatz\"\n",
    "    \n",
    "    # Fall 3: Alles andere ist Abgewiesen\n",
    "    return \"Abgewiesen\"\n",
    "\n",
    "df_dataset[\"target_label\"] = df_dataset.apply(determine_label, axis=1)\n",
    "\n",
    "# 4. Numerische Spalten sicherstellen (f√ºr Machine Learning sp√§ter wichtig)\n",
    "# Kaufpreis in echte Zahl wandeln (falls Strings wie \"25.000\" drin sind)\n",
    "def clean_money(val):\n",
    "    try:\n",
    "        return float(str(val).replace(\",\", \".\"))\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "if \"Kaufpreis\" in df_dataset.columns:\n",
    "    df_dataset[\"Kaufpreis_num\"] = df_dataset[\"Kaufpreis\"].apply(clean_money)\n",
    "\n",
    "# 5. Sanity-Check (Jetzt funktioniert er!)\n",
    "print(\"\\nVerteilung der Ergebnisse:\")\n",
    "print(df_dataset[\"target_label\"].value_counts(dropna=False))\n",
    "\n",
    "# 6. Export\n",
    "OUTPUT_BASENAME = \"lg_diesel_urteile_final\"\n",
    "df_dataset.to_csv(f\"{OUTPUT_BASENAME}.csv\", index=False, encoding=\"utf-8\")\n",
    "df_dataset.to_parquet(f\"{OUTPUT_BASENAME}.parquet\", index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Export fertig: {OUTPUT_BASENAME}.csv & .parquet erstellt.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cf9490",
   "metadata": {},
   "source": [
    "### 4.4 Datenaufteilung und Validierungskonzept\n",
    "\n",
    "Der Datensatz wird auf Fall-Ebene (`case_id`) in einen Trainings- (80 %) und einen Testdatensatz (20 %) aufgeteilt.  \n",
    "Der Trainingsdatensatz wird anschlie√üend mittels **5-facher stratified Cross-Validation** f√ºr die Modellselektion und Hyperparameter-Optimierung genutzt.\n",
    "\n",
    "Dieses Vorgehen erlaubt eine effiziente Nutzung der verf√ºgbaren, kostenintensiv extrahierten Labels, w√§hrend der Testdatensatz vollst√§ndig unber√ºhrt bleibt und ausschlie√ülich zur finalen Evaluation der Modellleistung dient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb61ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir trennen die Daten strikt in Training (80%) und Test (20%).\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# 1. Features ausw√§hlen (NUR Input-Daten, keine Ergebnisse!)\n",
    "# Wir nehmen nur den Kaufpreis als strukturiertes Feature.\n",
    "X_structured = df_dataset[['Kaufpreis_num']].fillna(0) \n",
    "\n",
    "# Wir nehmen den rohen Text (oder text_for_embedding) f√ºr den Split\n",
    "X_text = df_dataset['text'] \n",
    "\n",
    "# Ziel-Variable\n",
    "y = df_dataset['LABEL_Anspruch_Schadensersatz'].astype(int)\n",
    "\n",
    "# 2. Der Split\n",
    "X_train_text, X_test_text, X_train_struct, X_test_struct, y_train, y_test = train_test_split(\n",
    "    X_text, X_structured, y, \n",
    "    test_size=0.20, \n",
    "    random_state=42, \n",
    "    stratify=y  # Wichtig f√ºr gleiche Klassenverteilung!\n",
    ")\n",
    "\n",
    "# 3. DataFrames f√ºr Kapitel 5 erstellen (macht das Preprocessing einfacher)\n",
    "df_lg_train = pd.DataFrame({'text': X_train_text, 'LABEL_Anspruch_Schadensersatz': y_train}).join(X_train_struct)\n",
    "df_lg_test = pd.DataFrame({'text': X_test_text, 'LABEL_Anspruch_Schadensersatz': y_test}).join(X_test_struct)\n",
    "\n",
    "# 4. CV-Objekt f√ºr Abschnitt 6 bereitstellen\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "print(f\"‚úÖ Split abgeschlossen: Training ({len(df_lg_train)}), Test ({len(df_lg_test)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f899d3",
   "metadata": {},
   "source": [
    "## 5. Datenaufbereitung f√ºr maschinelles Lernen\n",
    "\n",
    "In diesem Abschnitt werden die Urteilstexte f√ºr die nachgelagerte pr√§diktive Modellierung aufbereitet. Hierzu erfolgt zun√§chst eine juristisch angepasste Textvorverarbeitung und die Ableitung numerischer Textrepr√§sentationen. Die f√ºr die supervised Lernphase erforderlichen Zielvariablen werden im Rahmen der LLM-basierten Extraktion (Abschnitt 4) erzeugt und anschlie√üend mit den Textmerkmalen zusammengef√ºhrt (Abschnitt 5.4).\n",
    "Ziel der Datenaufbereitung ist es, die extrahierten Merkmale in eine konsistente, auswertbare Form zu √ºberf√ºhren, fehlende oder uneinheitliche Angaben zu behandeln und die Zielvariablen f√ºr die sp√§tere Analyse eindeutig zu definieren."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8ab869",
   "metadata": {},
   "source": [
    "### 5.1 Juristische Textvorverarbeitung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b6d7f8",
   "metadata": {},
   "source": [
    "Wir wenden die spezialisierte Reinigung auf den Trainings- und Testdatensatz an.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b5a506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starte Vorverarbeitung der Trainingsdaten...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/951 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute '_is_builtin_func'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\humme\\OneDrive\\Dokumente\\Uni Ulm\\ds_law\\.venv\\Lib\\site-packages\\tqdm\\std.py:897\u001b[39m, in \u001b[36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001b[39m\u001b[34m(df, func, *args, **kwargs)\u001b[39m\n\u001b[32m    896\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:  \u001b[38;5;66;03m# pandas>=1.3.0\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m897\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_builtin_func\n\u001b[32m    898\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'is_builtin_func' from 'pandas.core.common' (c:\\Users\\humme\\OneDrive\\Dokumente\\Uni Ulm\\ds_law\\.venv\\Lib\\site-packages\\pandas\\core\\common.py)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_10836\\4287230271.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    103\u001b[39m tqdm.pandas()\n\u001b[32m    104\u001b[39m \n\u001b[32m    105\u001b[39m print(\u001b[33m\"Starte Vorverarbeitung der Trainingsdaten...\"\u001b[39m)\n\u001b[32m    106\u001b[39m \u001b[38;5;66;03m# Wir wenden die Reinigung nur auf df_lg_train an (erstellt in Schritt 4.4)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m df_lg_train[\u001b[33m'cleaned_text'\u001b[39m] = df_lg_train[\u001b[33m'text'\u001b[39m].progress_apply(legal_preprocess)\n\u001b[32m    108\u001b[39m \n\u001b[32m    109\u001b[39m print(f\"‚úÖ Preprocessing abgeschlossen. Datens√§tze im Training: {len(df_lg_train)}\")\n",
      "\u001b[32mc:\\Users\\humme\\OneDrive\\Dokumente\\Uni Ulm\\ds_law\\.venv\\Lib\\site-packages\\tqdm\\std.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(df, func, *args, **kwargs)\u001b[39m\n\u001b[32m    895\u001b[39m \n\u001b[32m    896\u001b[39m                 \u001b[38;5;28;01mtry\u001b[39;00m:  \u001b[38;5;66;03m# pandas>=1.3.0\u001b[39;00m\n\u001b[32m    897\u001b[39m                     \u001b[38;5;28;01mfrom\u001b[39;00m pandas.core.common \u001b[38;5;28;01mimport\u001b[39;00m is_builtin_func\n\u001b[32m    898\u001b[39m                 \u001b[38;5;28;01mexcept\u001b[39;00m ImportError:\n\u001b[32m--> \u001b[39m\u001b[32m899\u001b[39m                     is_builtin_func = df._is_builtin_func\n\u001b[32m    900\u001b[39m                 \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    901\u001b[39m                     func = is_builtin_func(func)\n\u001b[32m    902\u001b[39m                 \u001b[38;5;28;01mexcept\u001b[39;00m TypeError:\n",
      "\u001b[32mc:\\Users\\humme\\OneDrive\\Dokumente\\Uni Ulm\\ds_law\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   6202\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m name \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m self._accessors\n\u001b[32m   6203\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m self._info_axis._can_hold_identifiers_and_holds_name(name)\n\u001b[32m   6204\u001b[39m         ):\n\u001b[32m   6205\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self[name]\n\u001b[32m-> \u001b[39m\u001b[32m6206\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m object.__getattribute__(self, name)\n",
      "\u001b[31mAttributeError\u001b[39m: 'Series' object has no attribute '_is_builtin_func'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. Setup: Spezialisiertes deutsches Sprachmodell laden\n",
    "try:\n",
    "    # Wir deaktivieren unn√∂tige Komponenten (ner, parser), um die Verarbeitung zu beschleunigen\n",
    "    nlp = spacy.load(\"de_core_news_lg\", disable=[\"ner\", \"parser\"])\n",
    "except Exception:\n",
    "    print(\"Bitte installiere das spacy Modell: python -m spacy download de_core_news_lg\")\n",
    "\n",
    "# --- 2. JURISTISCHE TEXTVORVERARBEITUNG ---\n",
    "def legal_preprocess(text):\n",
    "    \"\"\"\n",
    "    Bereitet juristische Texte auf, indem Rauschen entfernt wird, \n",
    "    w√§hrend rechtlich relevante Zahlen und Kontexte gesch√ºtzt werden.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str) or not text:\n",
    "        return \"\"\n",
    "\n",
    "    # START DES URTEILS FINDEN (Rauschschnitt Anfang)\n",
    "    start_keywords = [\"tenor\", \"entscheidungsgr√ºnde\", \"tatbestand\", \"urteil\", \"beschluss\", \"endurteil\"]\n",
    "    text_lower_start = text.lower()\n",
    "    found_positions = [text_lower_start.find(kw) for kw in start_keywords if text_lower_start.find(kw) != -1]\n",
    "    if found_positions:\n",
    "        text = text[min(found_positions):]\n",
    "\n",
    "    # ENDE DES URTEILS FINDEN (Rauschschnitt Ende)\n",
    "    end_keywords = [\"impressum\", \"nutzungsbedingungen\", \"nach oben\", \"datenschutz\"]\n",
    "    text_lower_end = text.lower()\n",
    "    for ekw in end_keywords:\n",
    "        e_pos = text_lower_end.find(ekw)\n",
    "        if e_pos != -1:\n",
    "            text = text[:e_pos]\n",
    "            break\n",
    "\n",
    "    # 1. Bereinigung von Rauschen (HTML-Tags, Sonderzeichen)\n",
    "    text = re.sub(r'<.*?>', ' ', text)\n",
    "\n",
    "    # 2. Schutz von Zahlen & Paragraphen (Platzhalter)\n",
    "    text = re.sub(r'\\d{1,3}(?:\\.\\d{3})(?:,\\d+)?\\s(?:EUR|‚Ç¨|Euro)', ' PLATZHALTER_BETRAG ', text)\n",
    "    text = re.sub(r'¬ß+\\s*\\d+[a-z]?\\s*(?:\\w+)?', ' PLATZHALTER_PARAGRAPH ', text)\n",
    "    text = re.sub(r'\\b(19|20)\\d{2}\\b', ' PLATZHALTER_JAHR ', text)\n",
    "\n",
    "    # 3. Kleinschreibung\n",
    "    text = text.lower()\n",
    "\n",
    "    # 4. Tokenisierung und Lemmatisierung mit SpaCy\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # 5. Kontextsensitive Stoppwort-Entfernung\n",
    "    protected_negations = {\"nicht\", \"kein\", \"ohne\", \"gegen\", \"trotz\"}\n",
    "    custom_stop_words = nlp.Defaults.stop_words - protected_negations\n",
    "    \n",
    "    tokens = [\n",
    "        token.lemma_ for token in doc \n",
    "        if token.lemma_ not in custom_stop_words \n",
    "        and not token.is_punct \n",
    "        and not token.is_space\n",
    "        and len(token.text) > 1\n",
    "    ]\n",
    "    \n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# --- 2.5 HILFSFUNKTIONEN ---\n",
    "def get_llm_text(r: dict) -> str:\n",
    "    if \"text\" in r: return r[\"text\"]\n",
    "    if \"response\" in r: return r[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"]\n",
    "    raise KeyError(\"Unbekanntes Ergebnisformat.\")\n",
    "\n",
    "def parse_llm_json(text: str) -> dict:\n",
    "    text = re.sub(r\"^json\\s*|\\s*$\", \"\", text.strip(), flags=re.MULTILINE)\n",
    "    m = re.search(r\"(\\{.*\\})\", text, flags=re.DOTALL)\n",
    "    if m: text = m.group(1)\n",
    "    return json.loads(text)\n",
    "\n",
    "# --- AUSF√úHRUNG NUR F√úR TRAININGSDATEN ---\n",
    "# Wir aktivieren tqdm f√ºr den Fortschrittsbalken\n",
    "tqdm.pandas()\n",
    "\n",
    "print(\"Starte Vorverarbeitung der Trainingsdaten...\")\n",
    "# Wir wenden die Reinigung nur auf df_lg_train an (erstellt in Schritt 4.4)\n",
    "df_lg_train['cleaned_text'] = df_lg_train['text'].progress_apply(legal_preprocess)\n",
    "\n",
    "print(f\"‚úÖ Preprocessing abgeschlossen. Datens√§tze im Training: {len(df_lg_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e984ef",
   "metadata": {},
   "source": [
    "In dieser Zelle extrahieren wir die relevanten Abschnitte (Tenor + Gr√ºnde) und wenden das Preprocessing ausschlie√ülich auf die Trainingsdaten an.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b771f5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# Wir arbeiten NUR mit dem Trainingsdatensatz aus Abschnitt 4.4\n",
    "# (Sollte df_lg_train noch nicht existieren, stelle sicher, dass 4.4 ausgef√ºhrt wurde)\n",
    "df_train_work = df_lg_train.copy()\n",
    "\n",
    "# 1) Sicherstellen, dass Segmente existieren\n",
    "if \"segments\" not in df_train_work.columns:\n",
    "    print(\"Extrahiere Segmente f√ºr Trainingsdaten...\")\n",
    "    df_train_work[\"segments\"] = df_train_work[\"text\"].apply(split_judgment)\n",
    "\n",
    "# 2) Textbasis f√ºr ML definieren: Fokus auf TENOR + ENTSCHEIDUNGSGR√úNDE\n",
    "# Diese Abschnitte enthalten die juristische Essenz f√ºr Word2Vec\n",
    "def build_text_for_embedding(s):\n",
    "    if not isinstance(s, dict):\n",
    "        return \"\"\n",
    "    # Wir kombinieren Tenor und Gr√ºnde, da hier die Begr√ºndung f√ºr Schadensersatz steht\n",
    "    return (s.get(\"tenor\") or \"\") + \"\\n\" + (s.get(\"entscheidungsgruende\") or \"\")\n",
    "\n",
    "df_train_work[\"text_for_embedding\"] = df_train_work[\"segments\"].apply(build_text_for_embedding)\n",
    "\n",
    "# 3) L√§nge begrenzen (Token-/Laufzeitkontrolle)\n",
    "# 12.000 Zeichen sind meist ausreichend, um die Kernargumente zu erfassen\n",
    "MAX_CHARS = 12000\n",
    "df_train_work[\"text_for_embedding\"] = (\n",
    "    df_train_work[\"text_for_embedding\"]\n",
    "    .astype(str)\n",
    "    .str.slice(0, MAX_CHARS)\n",
    ")\n",
    "\n",
    "# 4) Juristisches Preprocessing (nur Trainingsdaten)\n",
    "# Hier wird die in der vorherigen Zelle definierte Funktion 'legal_preprocess' genutzt\n",
    "print(\"Starte juristische Vorverarbeitung der Trainingsdaten...\")\n",
    "df_train_work[\"cleaned_text\"] = df_train_work[\"text_for_embedding\"].progress_apply(legal_preprocess)\n",
    "\n",
    "# 5) Zur√ºckschreiben in den Haupt-Trainings-DataFrame\n",
    "df_lg_train = df_train_work\n",
    "\n",
    "# 6) Sanity-Checks\n",
    "print(\"-\" * 30)\n",
    "print(f\"‚úÖ Training-Datensatz bereit: {df_lg_train.shape[0]} Urteile\")\n",
    "print(f\"üìä Davon erfolgreich bereinigt: {(df_lg_train['cleaned_text'].str.len() > 0).sum()}\")\n",
    "\n",
    "print(\"\\nVorschau der bereinigten Trainings-Tokens:\")\n",
    "print(df_lg_train[\"cleaned_text\"].iloc[0][:300] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f3b2a0",
   "metadata": {},
   "source": [
    "### 5.2 Text-Vektorisierung mittels Word2Vec\n",
    "Das Modell lernt semantische Relationen ausschlie√ülich aus dem Trainingskorpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0bdb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# 1. Sicherstellen, dass wir den richtigen DataFrame nutzen\n",
    "df_train = df_lg_train \n",
    "\n",
    "# 2. Tokenisierung: Liste von Wortlisten erstellen\n",
    "# Wir nutzen .dropna(), falls durch das Preprocessing leere Felder entstanden sind\n",
    "train_sentences = [str(text).split() for text in df_train[\"cleaned_text\"] if text]\n",
    "\n",
    "# 3. Training des Word2Vec-Modells\n",
    "# sg=1 (Skip-Gram) ist top f√ºr juristische Nuancen\n",
    "print(\"Training des Word2Vec-Modells auf den Trainingsdaten...\")\n",
    "w2v_model = Word2Vec(\n",
    "    sentences=train_sentences,\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=2,\n",
    "    workers=4,\n",
    "    sg=1,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# 4. Vorbereitung der Zielvariable (y)\n",
    "# Wir stellen sicher, dass y_train exakt zu den Zeilen in df_train passt\n",
    "y_train = df_train[\"LABEL_Anspruch_Schadensersatz\"].astype(int)\n",
    "\n",
    "print(f\"‚úÖ Word2Vec-Modell trainiert. Vokabulargr√∂√üe: {len(w2v_model.wv)} W√∂rter.\")\n",
    "print(f\"‚úÖ Zielvariable y_train erstellt (N={len(y_train)}).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb422070",
   "metadata": {},
   "source": [
    "### 5.3 Aufbau des Analyse-Datensatzes\n",
    "Nach der Vektorisierung f√ºhren wir die mathematischen Ergebnisse in einer strukturierten Feature-Matrix zusammen. Wir wandeln die Sparse-Matrix in einen √ºbersichtlichen DataFrame um und verkn√ºpfen jedes Urteil √ºber die eindeutige case_id mit seinen Textmerkmalen. Diese Struktur ist essentiell, um im n√§chsten Schritt die durch das LLM extrahierten Zielvariablen (Schadensersatz oder Abweisung) pr√§zise jeder Beobachtung zuordnen zu k√∂nnen. Damit stellen wir sicher, dass der Datensatz modellunabh√§ngig konzipiert ist und eine solide Basis f√ºr die nachgelagerte pr√§diktive Modellierung bietet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff3c9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1. Hilfsfunktion zur Erstellung eines Dokument-Vektors\n",
    "def get_doc_vector(doc, model):\n",
    "    \"\"\" Erstellt einen Durchschnittsvektor aller bekannten W√∂rter im Urteil. \"\"\"\n",
    "    words = [w for w in str(doc).split() if w in model.wv]\n",
    "    if not words:\n",
    "        # Falls kein Wort des Urteils im Training vorkam, geben wir einen Null-Vektor zur√ºck\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(model.wv[words], axis=0)\n",
    "\n",
    "# 2. Vektorisierung der Trainings- und Testdaten\n",
    "# WICHTIG: Wir nutzen das w2v_model aus Schritt 5.2 (nur auf Train trainiert!)\n",
    "print(\"Vektorisierung der Trainingsdaten...\")\n",
    "X_train_vec = np.array([get_doc_vector(text, w2v_model) for text in df_lg_train[\"cleaned_text\"]])\n",
    "\n",
    "# Hinweis: Wir bereiten hier auch die Testdaten vor, damit wir sie sp√§ter evaluieren k√∂nnen.\n",
    "# Falls df_lg_test noch nicht bereinigt wurde, holen wir das hier kurz nach:\n",
    "if \"cleaned_text\" not in df_lg_test.columns:\n",
    "    print(\"Bereinige Testdaten f√ºr die Evaluation...\")\n",
    "    df_lg_test[\"cleaned_text\"] = df_lg_test[\"text\"].apply(legal_preprocess)\n",
    "\n",
    "print(\"Vektorisierung der Testdaten (mit Trainings-Modell)...\")\n",
    "X_test_vec = np.array([get_doc_vector(text, w2v_model) for text in df_lg_test[\"cleaned_text\"]])\n",
    "\n",
    "# 3. Auswahl der strukturierten Features (aus der Gemini-Extraktion in Abschnitt 4)\n",
    "# Wir f√ºllen fehlende Werte (NaN) mit 0, damit die ML-Modelle damit arbeiten k√∂nnen.\n",
    "struct_cols = ['Kaufpreis_num']\n",
    "X_train_structured = df_lg_train[struct_cols].fillna(0)\n",
    "X_test_structured = df_lg_test[struct_cols].fillna(0)\n",
    "\n",
    "# 4. Umwandlung der Word2Vec-Vektoren in DataFrames\n",
    "emb_cols = [f\"emb_{i}\" for i in range(X_train_vec.shape[1])]\n",
    "df_train_features = pd.DataFrame(X_train_vec, columns=emb_cols)\n",
    "df_test_features = pd.DataFrame(X_test_vec, columns=emb_cols)\n",
    "\n",
    "# 5. Finale Zusammenf√ºhrung (Struktur + Text-Embeddings)\n",
    "# WICHTIG: reset_index(drop=True) sorgt daf√ºr, dass die Zeilen beim Zusammenf√ºgen exakt matchen!\n",
    "X_train_final = pd.concat([X_train_structured.reset_index(drop=True), df_train_features], axis=1)\n",
    "X_test_final = pd.concat([X_test_structured.reset_index(drop=True), df_test_features], axis=1)\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"‚úÖ Feature-Matrizen erfolgreich erstellt.\")\n",
    "print(f\"üìä Training: {X_train_final.shape[0]} Urteile, {X_train_final.shape[1]} Features\")\n",
    "print(f\"üìä Test:     {X_test_final.shape[0]} Urteile, {X_test_final.shape[1]} Features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05160c8f",
   "metadata": {},
   "source": [
    "## 6. Analyse und Auswertung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4af3ec",
   "metadata": {},
   "source": [
    "Entscheidungsbaum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb49984b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# 1. Modell-Initialisierung\n",
    "dt_model = DecisionTreeClassifier(max_depth=10, random_state=42, class_weight=\"balanced\")\n",
    "\n",
    "# 2. Cross-Validation (auf Trainingsdaten)\n",
    "# Wir pr√ºfen die Stabilit√§t √ºber 5 Folds\n",
    "cv_results_dt = cross_validate(\n",
    "    dt_model, X_train_final, y_train, \n",
    "    cv=cv, # Das cv-Objekt (StratifiedKFold) aus Abschnitt 4.4\n",
    "    scoring=['accuracy', 'precision', 'recall', 'f1'],\n",
    "    return_train_score=False\n",
    ")\n",
    "\n",
    "print(f\"--- Cross-Validation (Train) ---\")\n",
    "print(f\"Mittlere Accuracy: {cv_results_dt['test_accuracy'].mean():.4f} (+/- {cv_results_dt['test_accuracy'].std():.4f})\")\n",
    "print(f\"Mittlerer Recall:   {cv_results_dt['test_recall'].mean():.4f}\")\n",
    "\n",
    "# 3. Finales Training & Test-Evaluation\n",
    "dt_model.fit(X_train_final, y_train)\n",
    "y_pred_dt = dt_model.predict(X_test_final)\n",
    "\n",
    "print(f\"\\n--- Finale Evaluation (Testset) ---\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_dt):.4f}\")\n",
    "print(classification_report(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4755b724",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c129f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 1. Modell-Initialisierung\n",
    "rf_model = RandomForestClassifier(n_estimators=300, random_state=42, n_jobs=-1, class_weight=\"balanced\")\n",
    "\n",
    "# 2. Cross-Validation (auf Trainingsdaten)\n",
    "cv_results_rf = cross_validate(\n",
    "    rf_model, X_train_final, y_train, \n",
    "    cv=cv, \n",
    "    scoring=['accuracy', 'precision', 'recall', 'f1'],\n",
    "    return_train_score=False\n",
    ")\n",
    "\n",
    "print(f\"--- Cross-Validation (Train) ---\")\n",
    "print(f\"Mittlere Accuracy: {cv_results_rf['test_accuracy'].mean():.4f} (+/- {cv_results_rf['test_accuracy'].std():.4f})\")\n",
    "\n",
    "# 3. Finales Training & Test-Evaluation\n",
    "rf_model.fit(X_train_final, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test_final)\n",
    "\n",
    "print(f\"\\n--- Finale Evaluation (Testset) ---\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d992e1a2",
   "metadata": {},
   "source": [
    "Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d134f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Modell-Initialisierung\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "\n",
    "# 2. Cross-Validation (auf Trainingsdaten)\n",
    "cv_results_gb = cross_validate(\n",
    "    gb_model, X_train_final, y_train, \n",
    "    cv=cv, \n",
    "    scoring=['accuracy', 'precision', 'recall', 'f1'],\n",
    "    return_train_score=False\n",
    ")\n",
    "\n",
    "print(f\"--- Cross-Validation (Train) ---\")\n",
    "print(f\"Mittlere Accuracy: {cv_results_gb['test_accuracy'].mean():.4f}\")\n",
    "\n",
    "# 3. Finales Training & Test-Evaluation\n",
    "gb_model.fit(X_train_final, y_train)\n",
    "y_pred_gb = gb_model.predict(X_test_final)\n",
    "\n",
    "print(f\"\\n--- Finale Evaluation (Testset) ---\")\n",
    "print(classification_report(y_test, y_pred_gb))\n",
    "\n",
    "# 4. Visualisierung der Feature Importance\n",
    "# Wir zeigen die Top 15 Merkmale (Strukturvariablen + Embeddings)\n",
    "importances = pd.Series(gb_model.feature_importances_, index=X_train_final.columns)\n",
    "plt.figure(figsize=(10, 6))\n",
    "importances.nlargest(15).sort_values().plot(kind='barh', color='skyblue')\n",
    "plt.title(\"Top 15 Features (Gradient Boosting)\")\n",
    "plt.xlabel(\"Gini Importance\")\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4bce4b",
   "metadata": {},
   "source": [
    "evtl. SHAP Werte f√ºr Erkl√§rbarkeit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

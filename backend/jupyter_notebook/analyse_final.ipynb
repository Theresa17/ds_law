{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f87c4b39",
   "metadata": {},
   "source": [
    "## 1. Datenimport und Initialisierung\n",
    "\n",
    "In diesem Abschnitt werden die OpenJur-Urteilstexte aus dem Datenverzeichnis eingelesen und die technische Datenbasis für die nachfolgenden Verarbeitungsschritte geschaffen. Dazu werden die benötigten Bibliotheken importiert und die verfügbaren Textdateien identifiziert.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972de4e7",
   "metadata": {},
   "source": [
    "### 1.1 Import der benötigten Bibliotheken\n",
    "\n",
    "Zu Beginn werden die für die weitere Verarbeitung erforderlichen Python-Bibliotheken importiert. Diese umfassen Funktionen für Dateizugriffe, reguläre Ausdrücke, Datenverarbeitung mit Pandas sowie den Export der Ergebnisse im JSON-Format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58f86b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61a736b",
   "metadata": {},
   "source": [
    "### 1.2 Einlesen der OpenJur-Urteilstexte \n",
    "\n",
    "In diesem Schritt werden alle identifizierten Urteilstexte aus dem Datenverzeichnis eingelesen. Jede Datei wird über den Dateinamen einer eindeutigen Fallkennung (`case_id`) zugeordnet. Die Texte bilden die Rohdatenbasis für die nachfolgenden Extraktions- und Filterprozesse. Der Datenpfad wird im Code parametriert (`DATA_DIR`), um eine reproduzierbare Ausführung zu gewährleisten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bef8dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pfad: c:\\Users\\humme\\OneDrive\\Dokumente\\Uni Ulm\\ds_law\\backend\\data\\Gerichtsurteile_Openjur\n",
      "Anzahl .txt: 2375\n",
      "Erste 10 Dateien: ['2090187.txt', '2112111.txt', '2112115.txt', '2112117.txt', '2112118.txt', '2112119.txt', '2112121.txt', '2112123.txt', '2124977.txt', '2126821.txt']\n"
     ]
    }
   ],
   "source": [
    "# (.txt) Dateien einlesen\n",
    "DATA_DIR = \"../data/Gerichtsurteile_Openjur\" \n",
    "files = [f for f in os.listdir(DATA_DIR) if f.lower().endswith(\".txt\")]\n",
    "\n",
    "print(\"Pfad:\", os.path.abspath(DATA_DIR))\n",
    "print(\"Anzahl .txt:\", len(files))\n",
    "print(\"Erste 10 Dateien:\", files[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d494b356",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed94d8a",
   "metadata": {},
   "source": [
    "## 2. Extraktion relevanter Urteilsbestandteile und Selektion der Landgerichtsurteile\n",
    "\n",
    "In diesem Abschnitt werden die eingelesenen Urteilstexte weiterverarbeitet, um für die nachfolgende Analyse relevante Textbestandteile gezielt zu extrahieren. Hierzu zählen insbesondere ein begrenzter Kopfbereich zur Voranalyse sowie der Tenor als Kern der gerichtlichen Entscheidung. Die strukturierte Aufbereitung dieser Textsegmente bildet die Grundlage für Filter-, Klassifikations- und Extraktionsschritte in den folgenden Abschnitten."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c915ba",
   "metadata": {},
   "source": [
    "### 2.1 Aufbau des DataFrames und Extraktion eines Kopfbereichs\n",
    "\n",
    "Die eingelesenen Texte werden in einem DataFrame (`df`) gespeichert. Zusätzlich wird ein begrenzter Kopfbereich (`head`) aus den ersten Zeichen extrahiert, da strukturelle Metadaten wie Gerichtstyp, Entscheidungsart und Zitierzeilen typischerweise am Anfang des Dokuments auftreten. Dieser Kopfbereich dient als effizienter Suchraum für die spätere Identifikation von Landgerichtsurteilen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28198986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gesamt eingelesen: 2375\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "for fn in files:\n",
    "    case_id = fn.replace(\".txt\", \"\")\n",
    "    path = os.path.join(DATA_DIR, fn)\n",
    "    with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        text = f.read()\n",
    "    rows.append({\"case_id\": case_id, \"text\": text})\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(\"Gesamt eingelesen:\", len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99a88600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head-Länge (Beispiel): 8000\n"
     ]
    }
   ],
   "source": [
    "HEAD_CHARS = 8000\n",
    "df[\"head\"] = df[\"text\"].astype(str).str.slice(0, HEAD_CHARS)\n",
    "\n",
    "print(\"Head-Länge (Beispiel):\", len(df.loc[0, \"head\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b62f66",
   "metadata": {},
   "source": [
    "### 2.2 Extraktion des Tenors\n",
    "\n",
    "Der Tenor enthält die eigentliche gerichtliche Entscheidung und ist daher für die inhaltliche Bewertung besonders relevant. Mithilfe regulärer Ausdrücke wird der Textabschnitt zwischen der Überschrift „Tenor“ und den nachfolgenden Abschnitten (z. B. „Tatbestand“ oder „Gründe“) extrahiert und in einer separaten Spalte gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6fae0b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tenor vorhanden: 2362 von 2375\n"
     ]
    }
   ],
   "source": [
    "def extract_tenor(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    m_start = re.search(r\"\\bTenor\\b\", text, flags=re.IGNORECASE)\n",
    "    if not m_start:\n",
    "        return \"\"\n",
    "\n",
    "    start = m_start.end()\n",
    "\n",
    "    # Begrenztes Suchfenster nach dem Tenor (robuster gegen Navigation)\n",
    "    window = text[start:start + 20000]\n",
    "\n",
    "    m_end = re.search(\n",
    "        r\"\\b(Tatbestand|Gründe|Gruende|Entscheidungsgründe|Entscheidungsgruende)\\b\",\n",
    "        window,\n",
    "        flags=re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    end = start + m_end.start() if m_end else min(len(text), start + 8000)\n",
    "    return text[start:end].strip()\n",
    "df[\"tenor\"] = df[\"text\"].apply(extract_tenor)\n",
    "print(\"Tenor vorhanden:\", (df[\"tenor\"].str.len() > 0).sum(), \"von\", len(df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2481ec6a",
   "metadata": {},
   "source": [
    "### 2.3 Identifikation von Landgerichtsurteilen (LG)\n",
    "\n",
    "Die Selektion der Landgerichtsurteile erfolgt anhand einer OpenJur-spezifischen Zitierzeile im Kopfbereich (Regex: „Einfach“ gefolgt von „LG“). Auf dieser Grundlage wird eine boolesche Variable erzeugt und der Teilkorpus df_lg gebildet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f6ff89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "✅ Echte LG-Urteile (über Zitierzeile): 1189\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Wir suchen nach der Zeile, die mit \"Einfach\" beginnt, gefolgt von \"LG\"\n",
    "# Der Regex r\"Einfach\\s*\\n\\s*LG\" stellt sicher, dass LG direkt darunter steht\n",
    "pattern_zitierung_lg = r\"Einfach\\s*\\n\\s*LG\"\n",
    "\n",
    "# Wir wenden das auf die Spalte an, die den Kopftext enthält\n",
    "df[\"is_landgericht\"] = df[\"head\"].str.contains(pattern_zitierung_lg, regex=True, na=False)\n",
    "\n",
    "# Jetzt erstellen wir den sauberen Dataframe\n",
    "df_lg = df[df[\"is_landgericht\"] == True].copy()\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(f\"✅ Echte LG-Urteile (über Zitierzeile): {len(df_lg)}\")\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85194c82",
   "metadata": {},
   "source": [
    "### 2.4 Segmentierung der Urteile in juristische Abschnitte\n",
    "Für die spätere Extraktion werden die Urteile in juristisch sinnvolle Teile zerlegt: Rubrum, Tenor, Tatbestand und Entscheidungsgründe. Dadurch kann das Modell gezielt relevante Passagen verarbeiten.\n",
    "Die Segmentierung dient dazu, spätere Analysen gezielt auf entscheidungsrelevante Abschnitte (insb. Tenor und Entscheidungsgründe) zu fokussieren.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "870d2bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_judgment(text):\n",
    "    \"\"\"\n",
    "    Teilt ein Urteil in Rubrum, Tenor, Tatbestand und Entscheidungsgründe auf.\n",
    "    \"\"\"\n",
    "    segments = {\n",
    "        \"rubrum\": \"\",\n",
    "        \"tenor\": \"\",\n",
    "        \"tatbestand\": \"\",\n",
    "        \"entscheidungsgruende\": \"\"\n",
    "    }\n",
    "    \n",
    "    # Muster für die Abschnittsüberschriften\n",
    "    # Das Rubrum ist alles vor dem Tenor\n",
    "    m_tenor = re.search(r\"\\bTenor\\b\", text, re.IGNORECASE)\n",
    "    m_tatbestand = re.search(r\"\\bTatbestand\\b\", text, re.IGNORECASE)\n",
    "    m_gruende = re.search(r\"\\b(Entscheidungsgründe|Gründe)\\b\", text, re.IGNORECASE)\n",
    "    \n",
    "    if m_tenor:\n",
    "        segments[\"rubrum\"] = text[:m_tenor.start()].strip()\n",
    "        \n",
    "        # Tenor bis Tatbestand\n",
    "        if m_tatbestand:\n",
    "            segments[\"tenor\"] = text[m_tenor.end():m_tatbestand.start()].strip()\n",
    "            \n",
    "            # Tatbestand bis Gründe\n",
    "            if m_gruende:\n",
    "                segments[\"tatbestand\"] = text[m_tatbestand.end():m_gruende.start()].strip()\n",
    "                segments[\"entscheidungsgruende\"] = text[m_gruende.end():].strip()\n",
    "            else:\n",
    "                segments[\"tatbestand\"] = text[m_tatbestand.end():].strip()\n",
    "        else:\n",
    "            # Falls kein Tatbestand gefunden wird, Tenor bis zum Ende oder Gründen\n",
    "            if m_gruende:\n",
    "                segments[\"tenor\"] = text[m_tenor.end():m_gruende.start()].strip()\n",
    "                segments[\"entscheidungsgruende\"] = text[m_gruende.end():].strip()\n",
    "            else:\n",
    "                segments[\"tenor\"] = text[m_tenor.end():].strip()\n",
    "                \n",
    "    return segments\n",
    "\n",
    "# Beispielanwendung auf den Dataframe\n",
    "df_lg['segments'] = df_lg['text'].apply(split_judgment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78144122",
   "metadata": {},
   "source": [
    "## 3 Prompt-Generierung und Pilotierung der LLM-Extraktion (Gemini Batch)\n",
    "Um API- und Token-Limits zu berücksichtigen, werden OpenJur-spezifische Navigationselemente aus dem Rubrum entfernt und alle Abschnitte in ihrer Länge begrenzt. Auf Basis dieser vorverarbeiteten Textsegmente wird ein standardisierter Prompt generiert, der die Extraktion der abgestimmten Variablen im JSON-Format steuert.\n",
    "Die segmentweise Längenbegrenzung dient der Einhaltung von Token-Limits sowie der Reduktion von Kosten und Laufzeit, ohne entscheidungsrelevante Passagen (insb. Tenor und Entscheidungsgründe) zu verlieren.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d039d706",
   "metadata": {},
   "source": [
    "### 3.1 Aufbereitung der Segmente und Definition des Extraktions-Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "753fa8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_rubrum(rubrum: str) -> str:\n",
    "    if not isinstance(rubrum, str):\n",
    "        return \"\"\n",
    "\n",
    "    blacklist = [\n",
    "        \"rechtsprechung\", \"aktuell\", \"trending\", \"filter\",\n",
    "        \"über openjur\", \"spenden\", \"api\", \"hilfe\",\n",
    "        \"startseite\", \"bundesland\", \"gerichtsbarkeit\",\n",
    "        \"impressum\", \"datenschutz\", \"nutzungsbedingungen\",\n",
    "        \"fachzeitschriften\", \"suchen\", \"changelog\", \"einfach\",\n",
    "        \"json\", \"bibtex\", \"ris\"\n",
    "    ]\n",
    "\n",
    "    lines = []\n",
    "    for line in rubrum.splitlines():\n",
    "        l = line.strip().lower()\n",
    "        if not l:\n",
    "            continue\n",
    "        if any(b in l for b in blacklist):\n",
    "            continue\n",
    "        lines.append(line.strip())\n",
    "\n",
    "    return \"\\n\".join(lines[:5])   \n",
    "\n",
    "def slim_segments(segments):\n",
    "    return {\n",
    "        \"rubrum\": clean_rubrum(segments.get(\"rubrum\") or \"\")[:2500],\n",
    "        \"tenor\": (segments.get(\"tenor\") or \"\")[:4000],\n",
    "        \"tatbestand\": (segments.get(\"tatbestand\") or \"\")[:3500],\n",
    "        \"entscheidungsgruende\": (segments.get(\"entscheidungsgruende\") or \"\")[:7000],\n",
    "    }\n",
    "\n",
    "def get_gemini_prompt(segments):\n",
    "    \"\"\"\n",
    "    Erstellt den finalen Prompt basierend auf den Urteilssegmenten.\n",
    "    \"\"\"\n",
    "    s = slim_segments(segments)   # <--- DAS ist der entscheidende Schritt\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Analysiere die folgenden Abschnitte eines Gerichtsurteils zum Dieselskandal und extrahiere die Variablen präzise als JSON-Liste. \n",
    "\n",
    "### URTEILS-BESTANDTEILE:\n",
    "RUBRUM (Kopfbereich mit Gericht & Datum): \n",
    "{s['rubrum']}\n",
    "\n",
    "TENOR (Ergebnis): \n",
    "{s['tenor']}\n",
    "\n",
    "TATBESTAND (Sachverhalt): \n",
    "{s['tatbestand']}\n",
    "\n",
    "ENTSCHEIDUNGSGRÜNDE (Rechtliche Würdigung): \n",
    "{s['entscheidungsgruende']}\n",
    "\n",
    "### EXTRAKTIONS-AUFGABE:\n",
    "Extrahiere folgende Variablen (bei Nichtfinden 'null' angeben):\n",
    "\n",
    "1. **Input-Variablen (Features):**\n",
    "   - Dieselmotor_Typ\n",
    "   - Art_Abschalteinrichtung\n",
    "   - KBA_Rueckruf\n",
    "   - Fahrzeugstatus\n",
    "   - Fahrzeugmodell_Baureihe\n",
    "   - Update_Status\n",
    "   - Kilometerstand_Kauf\n",
    "   - Kilometerstand_Klageerhebung\n",
    "   - Erwartete_Gesamtlaufleistung\n",
    "   - Kaufdatum\n",
    "   - Uebergabedatum\n",
    "   - Datum_Klageerhebung\n",
    "   - Nachweis_Aufklaerung\n",
    "   - Beklagten_Typ\n",
    "   - Datum_Urteil\n",
    "   - Kaufpreis\n",
    "   - Nacherfuellungsverlangen_Fristsetzung\n",
    "   - Klageziel\n",
    "   - Rechtsgrundlage\n",
    "\n",
    "2. **Zielvariablen (Labels):**\n",
    "   - LABEL_Anspruch_Schadensersatz\n",
    "   - LABEL_Schadensersatzhoehe_Betrag\n",
    "   - LABEL_Schadensersatzhoehe_Range\n",
    "\n",
    "### AUSGABEFORMAT:\n",
    "Antworte NUR mit einem validen JSON-Objekt in einer Liste:\n",
    "[{{\n",
    "  \"case_id\": \"...\",\n",
    "  \"Dieselmotor_Typ\": null,\n",
    "  \"Art_Abschalteinrichtung\": null,\n",
    "  \"KBA_Rueckruf\": null,\n",
    "  \"Fahrzeugstatus\": null,\n",
    "  \"Fahrzeugmodell_Baureihe\": null,\n",
    "  \"Update_Status\": null,\n",
    "  \"Kilometerstand_Kauf\": null,\n",
    "  \"Kilometerstand_Klageerhebung\": null,\n",
    "  \"Erwartete_Gesamtlaufleistung\": null,\n",
    "  \"Kaufdatum\": null,\n",
    "  \"Uebergabedatum\": null,\n",
    "  \"Datum_Klageerhebung\": null,\n",
    "  \"Nachweis_Aufklaerung\": null,\n",
    "  \"Beklagten_Typ\": null,\n",
    "  \"Datum_Urteil\": null,\n",
    "  \"Kaufpreis\": null,\n",
    "  \"Nacherfuellungsverlangen_Fristsetzung\": null,\n",
    "  \"Klageziel\": null,\n",
    "  \"Rechtsgrundlage\": null,\n",
    "  \"LABEL_Anspruch_Schadensersatz\": null,\n",
    "  \"LABEL_Schadensersatzhoehe_Betrag\": null,\n",
    "  \"LABEL_Schadensersatzhoehe_Range\": null\n",
    "}}]\n",
    "\"\"\".strip()\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a84b7b",
   "metadata": {},
   "source": [
    "### 3.2 Erstellung eines Pilot-Inputs im JSONL-Format\n",
    "Zur technischen Validierung der Analysepipeline wird ein Pilotdatensatz erzeugt, der eine begrenzte Anzahl von Landgerichtsurteilen umfasst. Für jedes ausgewählte Urteil werden die zuvor definierten Textsegmente extrahiert, zu einem standardisierten Analyse-Prompt zusammengeführt und im JSONL-Format gespeichert. Diese Pilotdatei dient als Testeingabe für die nachgelagerte Verarbeitung über die Gemini-API, bevor eine Skalierung auf den vollständigen Datensatz erfolgt.\n",
    "Der Pilot dient ausschließlich der technischen Validierung der Prompt-Struktur und der Batch-Pipeline und ist nicht für eine inhaltliche Evaluation der Extraktionsergebnisse vorgesehen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f6ac57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pilot erstellt: gemini_batch_input_pilot_10.jsonl\n"
     ]
    }
   ],
   "source": [
    "PILOT_N = 10\n",
    "pilot_path = \"gemini_batch_input_pilot_10.jsonl\"\n",
    "\n",
    "with open(pilot_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for _, row in df_lg.head(PILOT_N).iterrows():\n",
    "        segments = row[\"segments\"]\n",
    "        full_prompt = get_gemini_prompt(segments)\n",
    "\n",
    "        payload = {\n",
    "            \"custom_id\": f\"case_{row['case_id']}\",\n",
    "            \"contents\": [{\n",
    "                \"role\": \"user\",\n",
    "                \"parts\": [{\"text\": full_prompt}]\n",
    "            }]\n",
    "        }\n",
    "        f.write(json.dumps(payload, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(\"✅ Pilot erstellt:\", pilot_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26beec66",
   "metadata": {},
   "source": [
    "Der Code dient der inhaltlichen und technischen Validierung der erzeugten Pilotdatei. Hierzu wird der erste Eintrag der JSONL-Datei geladen und exemplarisch ausgegeben, um Struktur, Inhalt und Länge des generierten Analyse-Prompts zu überprüfen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8773a064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case_2090187\n",
      "Analysiere die folgenden Abschnitte eines Gerichtsurteils zum Dieselskandal und extrahiere die Variablen präzise als JSON-Liste. \n",
      "\n",
      "### URTEILS-BESTANDTEILE:\n",
      "RUBRUM (Kopfbereich mit Gericht & Datum): \n",
      "Rechtsgebiet\n",
      "Gericht\n",
      "Informationen\n",
      "\n",
      "TENOR (Ergebnis): \n",
      "I. Die Klage wird abgewiesen.II. Der Kläger hat die Kosten des Rechtsstreits zu tragen.III. Das Urteil ist gegen Sicherheitsleistung in Höhe des 1,1-fachen des zu vollstreckenden Betrags vorläufig vollstreckbar.IV. Der Streitwert wird auf 31.234,00 € festgesetzt.\n",
      "\n",
      "TATBESTAND (Sachverhalt): \n",
      "Der Kläger begehrt Lieferung eines mangelfreien Pkw.Der Kläger erwarb von der Beklagten im Jahr 2014 einen Neuwagen VW Passat 2,0 l TDI für 31.234,00 €. Der Pkw ist von dem \"VW-Abgasskandal\" betroffen. Der Kläger hat die Beklagte im Jahr 2016 durch Anwa\n",
      "Prompt-Länge: 8908\n"
     ]
    }
   ],
   "source": [
    "with open(\"gemini_batch_input_pilot_10.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    first = json.loads(f.readline())\n",
    "\n",
    "print(first[\"custom_id\"])\n",
    "print(first[\"contents\"][0][\"parts\"][0][\"text\"][:800])\n",
    "print(\"Prompt-Länge:\", len(first[\"contents\"][0][\"parts\"][0][\"text\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966495f0",
   "metadata": {},
   "source": [
    "### 3.3 Upload und Start eines Pilot-Batch-Jobs\n",
    "In diesem Schritt wird die zuvor erzeugte Pilot-JSONL-Datei als Eingabe für die Gemini-API hochgeladen. Die Datei enthält strukturierte Analyseanfragen für mehrere Urteile und wird auf den Servern bereitgestellt, sodass sie anschließend im Rahmen einer Batch- oder sequenziellen Verarbeitung vom Sprachmodell verarbeitet werden kann. Der Upload erzeugt eine referenzierbare Eingabedatei, die anschließend einem eindeutig benannten Batch-Job zugewiesen wird und damit eine reproduzierbare Verarbeitung durch das Sprachmodell ermöglicht.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371274c8",
   "metadata": {},
   "source": [
    "Initialisierung des API-Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7cb802c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client initialisiert\n"
     ]
    }
   ],
   "source": [
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise RuntimeError(\"GEMINI_API_KEY ist nicht gesetzt\")\n",
    "\n",
    "client = genai.Client(api_key=api_key)\n",
    "print(\"Client initialisiert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d462c1",
   "metadata": {},
   "source": [
    "Upload der JSONL-Datei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee753d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload: files/8i63btgg96qz\n"
     ]
    }
   ],
   "source": [
    "uploaded = client.files.upload(\n",
    "    file=\"gemini_batch_input_pilot_10.jsonl\",\n",
    "    config={\n",
    "        \"display_name\": \"diesel-lg-pilot-10\",\n",
    "        \"mime_type\": \"text/plain\"\n",
    "    }\n",
    ")\n",
    "print(\"Upload:\", uploaded.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e7aedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = client.batches.create(\n",
    "    model=\"models/gemini-2.5-flash\",\n",
    "    src=uploaded.name,\n",
    "    config={\"display_name\": \"diesel-lg-pilot-10\"}\n",
    ")\n",
    "\n",
    "print(\"Batch gestartet:\", job.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f99f72e",
   "metadata": {},
   "source": [
    "## 4 Verarbeitung der Modellantworten und Erstellung des Extraktions-Datensatzes\n",
    "\n",
    "In diesem Abschnitt werden die Batch-Ausgaben der Gemini-API eingelesen, validiert und in ein tabellarisches Format überführt. Zum Zeitpunkt der aktuellen Notebook-Version liegt lediglich der Pilot-Workflow vor; der Code zur Verarbeitung des vollständigen Batch-Outputs wird nach Abschluss des Batch-Jobs ergänzt.\n",
    "\n",
    "(gemini_batch_input_NUR_LG.jsonl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaca577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier Code einfügen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8b810e",
   "metadata": {},
   "source": [
    "### 4.1 Download/Export der Batch-Ausgabedatei (JSONL) (Platzhalter)\n",
    "\n",
    "Nach der in Abschnitt 2 beschriebenen Aufbereitung der Urteilstexte liegt der vollständige Analyse-Datensatz in Form einer strukturierten JSONL-Datei vor. Diese Datei dient in diesem Schritt als Eingabe für die automatisierte Verarbeitung durch ein großes Sprachmodell.\n",
    "\n",
    "Die JSONL-Datei wird zunächst in das Batch-System hochgeladen. Anschließend wird ein Batch-Verarbeitungsjob gestartet, der die hochgeladene Datei als Eingabequelle verwendet. Für jedes enthaltene Dokument erzeugt das Modell eine strukturierte Antwort gemäß den im Prompt definierten Extraktionsvorgaben.\n",
    "\n",
    "Als Ergebnis des Batch-Jobs stellt die API eine Ausgabedatei bereit, die die Modellantworten zu allen verarbeiteten Urteilen enthält. Diese Ausgabedatei liegt ebenfalls im JSONL-Format vor und bildet die Grundlage für die weitere Aufbereitung und Auswertung der Ergebnisse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f543fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier Code einfügen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a7cbd2",
   "metadata": {},
   "source": [
    "### 4.2 Parsing, Validierung und Tabellierung der Extraktionen (Platzhalter)\n",
    "\n",
    "Die im vorherigen Schritt erzeugte Ausgabedatei des Batch-Jobs liegt zunächst als Rohdaten im JSONL-Format vor. Jede Zeile dieser Datei enthält die strukturierte Modellantwort zu einem einzelnen Landgerichtsurteil.\n",
    "\n",
    "Diese Rohdaten werden lokal gespeichert und anschließend in ein tabellarisches Format überführt. Hierzu werden die relevanten Felder aus den JSON-Strukturen extrahiert und in einer einheitlichen Datenstruktur zusammengeführt, beispielsweise in Form einer CSV-Datei. \n",
    "Der so erzeugte Datensatz bildet die Grundlage für die weitere statistische Auswertung und Analyse in den folgenden Abschnitten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaacc270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier Code einfügen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2911c4f4",
   "metadata": {},
   "source": [
    "### 4.3 Zusammenführung mit Metadaten und Speicherung (CSV/Parquet) (Platzhalter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500c339b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f899d3",
   "metadata": {},
   "source": [
    "## 5. Datenaufbereitung für maschinelles Lernen\n",
    "\n",
    "In diesem Abschnitt werden die Urteilstexte für die nachgelagerte prädiktive Modellierung aufbereitet. Hierzu erfolgt zunächst eine juristisch angepasste Textvorverarbeitung und die Ableitung numerischer Textrepräsentationen. Die für die supervised Lernphase erforderlichen Zielvariablen werden im Rahmen der LLM-basierten Extraktion (Abschnitt 4) erzeugt und anschließend mit den Textmerkmalen zusammengeführt (Abschnitt 5.4).\n",
    "Ziel der Datenaufbereitung ist es, die extrahierten Merkmale in eine konsistente, auswertbare Form zu überführen, fehlende oder uneinheitliche Angaben zu behandeln und die Zielvariablen für die spätere Analyse eindeutig zu definieren."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8ab869",
   "metadata": {},
   "source": [
    "### 5.1 Juristische Textvorverarbeitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b021aba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 1. Setup: Spezialisiertes deutsches Sprachmodell laden\n",
    "try:\n",
    "    nlp = spacy.load(\"de_core_news_lg\", disable=[\"ner\", \"parser\"])\n",
    "except Exception:\n",
    "    print(\"Bitte installiere das spacy Modell: python -m spacy download de_core_news_lg\")\n",
    "\n",
    "# --- 2. JURISTISCHE TEXTVORVERARBEITUNG ---\n",
    "def legal_preprocess(text):\n",
    "    \"\"\"\n",
    "    Bereitet juristische Texte auf, indem Rauschen entfernt wird, \n",
    "    während rechtlich relevante Zahlen und Kontexte geschützt werden.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str) or not text:\n",
    "        return \"\"\n",
    "\n",
    "    # NEU: START DES URTEILS FINDEN (Rauschschnitt Anfang) ---\n",
    "    # Wir schneiden Webseiten-Menüs (\"trending\", \"suche\" etc.) weg\n",
    "    start_keywords = [\"tenor\", \"entscheidungsgründe\", \"tatbestand\", \"urteil\", \"beschluss\", \"endurteil\"]\n",
    "    text_lower_start = text.lower()\n",
    "    \n",
    "    # Finde die früheste Position eines der Keywords\n",
    "    found_positions = [text_lower_start.find(kw) for kw in start_keywords if text_lower_start.find(kw) != -1]\n",
    "    if found_positions:\n",
    "        text = text[min(found_positions):]\n",
    "\n",
    "    # NEU: ENDE DES URTEILS FINDEN (Rauschschnitt Ende) ---\n",
    "    # Wir schneiden Impressum und Footer weg\n",
    "    end_keywords = [\"impressum\", \"nutzungsbedingungen\", \"nach oben\", \"datenschutz\"]\n",
    "    text_lower_end = text.lower()\n",
    "    for ekw in end_keywords:\n",
    "        e_pos = text_lower_end.find(ekw)\n",
    "        if e_pos != -1:\n",
    "            text = text[:e_pos]\n",
    "            break\n",
    "\n",
    "    # 1. Bereinigung von Rauschen (HTML-Tags, Sonderzeichen)\n",
    "    text = re.sub(r'<.*?>', ' ', text)\n",
    "\n",
    "    # 2. Schutz von Zahlen & Paragraphen (Platzhalter statt Löschen)\n",
    "    # Euro-Beträge schützen\n",
    "    text = re.sub(r'\\d{1,3}(?:\\.\\d{3})*(?:,\\d+)?\\s*(?:EUR|€|Euro)', ' PLATZHALTER_BETRAG ', text)\n",
    "    # Paragraphen schützen\n",
    "    text = re.sub(r'§+\\s*\\d+[a-z]?\\s*(?:\\w+)?', ' PLATZHALTER_PARAGRAPH ', text)\n",
    "    # Jahreszahlen schützen\n",
    "    text = re.sub(r'\\b(19|20)\\d{2}\\b', ' PLATZHALTER_JAHR ', text)\n",
    "\n",
    "    # 3. Kleinschreibung zur Reduktion der Varianz\n",
    "    text = text.lower()\n",
    "\n",
    "    # 4. Tokenisierung und Lemmatisierung mit SpaCy\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # 5. Kontextsensitive Stoppwort-Entfernung\n",
    "    # Wichtige juristische Negationen schützen\n",
    "    protected_negations = {\"nicht\", \"kein\", \"ohne\", \"gegen\", \"trotz\"}\n",
    "    custom_stop_words = nlp.Defaults.stop_words - protected_negations\n",
    "    \n",
    "    # Extraktion der Lemmata (Grundformen)\n",
    "    tokens = [\n",
    "        token.lemma_ for token in doc \n",
    "        if token.lemma_ not in custom_stop_words \n",
    "        and not token.is_punct \n",
    "        and not token.is_space\n",
    "        and len(token.text) > 1 # Token mit Länge 1 entfernen\n",
    "    ]\n",
    "    \n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# --- 2.5 HILFSFUNKTIONEN: Simulation + echtes Batch lesen ---\n",
    "def get_llm_text(r: dict) -> str:\n",
    "    # Simulation (simulated_batch_output.jsonl)\n",
    "    if \"text\" in r:\n",
    "        return r[\"text\"]\n",
    "    # Echtes Batch (später)\n",
    "    if \"response\" in r:\n",
    "        return r[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"]\n",
    "    raise KeyError(\"Unbekanntes Ergebnisformat (kein 'text' und kein 'response').\")\n",
    "\n",
    "def parse_llm_json(text: str) -> dict:\n",
    "    # Entfernt ```json ... ``` falls vorhanden\n",
    "    text = re.sub(r\"^```json\\s*|\\s*```$\", \"\", text.strip(), flags=re.MULTILINE)\n",
    "    # Falls außenrum Text steht: ersten JSON-Block extrahieren\n",
    "    m = re.search(r\"(\\{.*\\})\", text, flags=re.DOTALL)\n",
    "    if m:\n",
    "        text = m.group(1)\n",
    "    return json.loads(text)\n",
    "\n",
    "# --- 3. MERGING DER DATEN (URTEILE + EXTRAKTIONEN) ---\n",
    "def merge_and_finalize(judgment_file, batch_results_file):\n",
    "    \"\"\"\n",
    "    Führt die ursprünglichen Urteilstexte mit den Gemini-Extraktionen zusammen.\n",
    "    \"\"\"\n",
    "    # 1. Laden der aufbereiteten LG-Urteile\n",
    "    df_judgments = pd.read_json(judgment_file, lines=True)\n",
    "    df_judgments['case_id'] = df_judgments['custom_id'].str.replace('case_', '')\n",
    "\n",
    "    # 2. Laden der Gemini-Batch-Ergebnisse\n",
    "    with open(batch_results_file, 'r', encoding='utf-8') as f:\n",
    "        results = [json.loads(line) for line in f]\n",
    "    \n",
    "    extracted_rows = []\n",
    "    for r in results:\n",
    "        try:\n",
    "            case_id = r['custom_id'].replace('case_', '')\n",
    "            llm_text = get_llm_text(r)\n",
    "            content = parse_llm_json(llm_text)\n",
    "            content['case_id'] = case_id\n",
    "            extracted_rows.append(content)\n",
    "        except Exception:\n",
    "            continue\n",
    "            \n",
    "    df_extracted = pd.DataFrame(extracted_rows)\n",
    "\n",
    "    # 3. Zusammenführung über case_id \n",
    "    df_final = pd.merge(df_judgments, df_extracted, on='case_id', how='inner')\n",
    "\n",
    "    # 4. Textverarbeitung anwenden\n",
    "    print(\"Starte Textvorverarbeitung...\")\n",
    "    df_final['cleaned_text'] = df_final['text'].apply(legal_preprocess)\n",
    "\n",
    "    return df_final\n",
    "\n",
    "# --- 4. MODELL-VORBEREITUNG (TF-IDF) ---\n",
    "tfidf = TfidfVectorizer(\n",
    "    ngram_range=(1, 2),   # Bigramme erhalten Wortzusammenhänge\n",
    "    max_features=1000,    # Reduktion der Komplexität\n",
    "    min_df=5              # Seltene Begriffe ignorieren\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca2d51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RESULTS_FILE = \"simulated_batch_output.jsonl\"   # später echte Batch-Output-Datei\n",
    "# df_final = merge_and_finalize(\n",
    "    judgment_file=\"lg_judgments.jsonl\",\n",
    "    batch_results_file=RESULTS_FILE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4388ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_final shape: (1189, 8)\n",
      "non-empty cleaned_text: 1185\n",
      "\n",
      "Beispiel cleaned_text:\n",
      "\n",
      "Urteil gegen Sicherheitsleistung Höhe 1,1-fache vollstreckend betrag vorläufig vollstreckbar.iv Streitwert Platzhalter_betrag festsetzen zulässig Klage unbegründet.d Kläger gegen beklagen Anspruch Nachlieferung mangelfrei Pkw aktuell Produktion Platzhalter_paragraph Platzhalter_paragraph Alternative\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# 1) Sicherstellen, dass Segmente existieren\n",
    "if \"segments\" not in df_lg.columns:\n",
    "    df_lg[\"segments\"] = df_lg[\"text\"].apply(split_judgment)\n",
    "\n",
    "df_final = df_lg.copy()\n",
    "\n",
    "# 2) Text für Embeddings: TENOR + ENTSCHEIDUNGSGRÜNDE\n",
    "def build_text_for_embedding(s):\n",
    "    if not isinstance(s, dict):\n",
    "        return \"\"\n",
    "    return (s.get(\"tenor\") or \"\") + \"\\n\" + (s.get(\"entscheidungsgruende\") or \"\")\n",
    "\n",
    "df_final[\"text_for_embedding\"] = df_final[\"segments\"].apply(build_text_for_embedding)\n",
    "\n",
    "# 3) Länge begrenzen (wichtig für Laufzeit)\n",
    "MAX_CHARS = 12000\n",
    "df_final[\"text_for_embedding\"] = (\n",
    "    df_final[\"text_for_embedding\"]\n",
    "    .astype(str)\n",
    "    .str.slice(0, MAX_CHARS)\n",
    ")\n",
    "\n",
    "# 4) Juristisches Preprocessing (einmal, mit Fortschritt)\n",
    "df_final[\"cleaned_text\"] = df_final[\"text_for_embedding\"].apply(legal_preprocess)\n",
    "\n",
    "# 5) Sanity-Checks\n",
    "print(\"df_final shape:\", df_final.shape)\n",
    "print(\n",
    "    \"non-empty cleaned_text:\",\n",
    "    (df_final[\"cleaned_text\"].str.len() > 0).sum()\n",
    ")\n",
    "\n",
    "# Vorschau\n",
    "print(\"\\nBeispiel cleaned_text:\\n\")\n",
    "print(df_final[\"cleaned_text\"].iloc[0][:300])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f3b2a0",
   "metadata": {},
   "source": [
    "### 5.2 Text-Vektorisierung mittels TF-IDF\n",
    "In diesem Schritt transformieren wir die bereinigten Urteilstexte mithilfe des TF-IDF-Verfahrens in ein numerisches Format, das für Machine-Learning-Algorithmen lesbar ist. Im Gegensatz zu abstrakten Embeddings bietet TF-IDF eine hohe Interpretierbarkeit, da jedes Merkmal einem konkreten juristischen Begriff oder einer Wortkombination (N-Gramm) entspricht. Durch die Begrenzung auf die 1.000 relevantesten Begriffe reduzieren wir das Rauschen im Datensatz und bereiten die Daten optimal auf den in der Aufgabenstellung empfohlenen Entscheidungsbaum vor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f9df7450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature-Matrix erstellt: 1189 Urteile, 1000 Begriffe.\n"
     ]
    }
   ],
   "source": [
    "# Semantische Repräsentation mittels TF-IDF (statt Word2Vec)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Wir nehmen Unigramme und Bigramme, um Begriffe wie \"Klage abgewiesen\" zu erfassen.\n",
    "tfidf = TfidfVectorizer(\n",
    "    ngram_range=(1, 2), \n",
    "    max_features=1000,  # Reduziert die Komplexität für den Baum\n",
    "    min_df=5,           # Wort muss in mind. 5 Urteilen vorkommen\n",
    "    stop_words=None      # Stoppwörter wurden bereits im Preprocessing entfernt\n",
    ")\n",
    "\n",
    "# Erstellt die Feature-Matrix\n",
    "X_tfidf = tfidf.fit_transform(df_final[\"cleaned_text\"].fillna(\"\"))\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "\n",
    "print(f\"Feature-Matrix erstellt: {X_tfidf.shape[0]} Urteile, {X_tfidf.shape[1]} Begriffe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a77edb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenisierte Texte für Word2Vec\n",
    "#sentences = [str(t).split() for t in df_final[\"cleaned_text\"].dropna()]\n",
    "# Skip-Gram Word2Vec Modell trainieren\n",
    "#from gensim.models import Word2Vec\n",
    "\n",
    "#w2v_model = Word2Vec(\n",
    "    sentences=sentences,\n",
    "    vector_size=200,   # Dimension der Wortvektoren\n",
    "    window=8,          # Kontextfenster\n",
    "    min_count=5,       # sehr seltene Wörter ignorieren\n",
    "    workers=4,\n",
    "    sg=1,              # <-- Skip-Gram (besser für Fachbegriffe, prüfen) \n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34222237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dokumenten-Vektor durch Mittelung der Wortvektoren\n",
    "#import numpy as np\n",
    "\n",
    "#def document_vector(doc, model):\n",
    "    if not isinstance(doc, str) or not doc.strip():\n",
    "        return np.zeros(model.vector_size)\n",
    "    words = doc.split()\n",
    "    vectors = [model.wv[w] for w in words if w in model.wv]\n",
    "    if len(vectors) == 0:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(vectors, axis=0)\n",
    "\n",
    "# Alle Urteile vektorisieren\n",
    "X_embeddings = np.vstack(\n",
    "    df_final[\"cleaned_text\"].apply(lambda x: document_vector(x, w2v_model))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718bee56",
   "metadata": {},
   "source": [
    "### 5.3 Aufbau des Analyse-Datensatzes\n",
    "Nach der Vektorisierung führen wir die mathematischen Ergebnisse in einer strukturierten Feature-Matrix zusammen. Wir wandeln die Sparse-Matrix in einen übersichtlichen DataFrame um und verknüpfen jedes Urteil über die eindeutige case_id mit seinen Textmerkmalen. Diese Struktur ist essentiell, um im nächsten Schritt die durch das LLM extrahierten Zielvariablen (Schadensersatz oder Abweisung) präzise jeder Beobachtung zuordnen zu können. Damit stellen wir sicher, dass der Datensatz modellunabhängig konzipiert ist und eine solide Basis für die nachgelagerte prädiktive Modellierung bietet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6f9dfb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyse-Datensatz bereit für Merge mit Labels.\n"
     ]
    }
   ],
   "source": [
    "# Aufbau des Analyse-Datensatzes\n",
    "df_features = pd.DataFrame(X_tfidf.toarray(), columns=feature_names)\n",
    "df_features.insert(0, \"case_id\", df_final[\"case_id\"].reset_index(drop=True).values)\n",
    "\n",
    "print(\"Analyse-Datensatz bereit für Merge mit Labels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "30ae8dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aufbau des Analyse-Datensatzes\n",
    "\n",
    "# Feature-Namen für die Embeddings\n",
    "#emb_cols = [f\"emb_{i}\" for i in range(X_embeddings.shape[1])]\n",
    "\n",
    "# Embeddings als DataFrame\n",
    "#df_features = pd.DataFrame(X_embeddings, columns=emb_cols)\n",
    "\n",
    "# case_id ergänzen (für spätere Joins mit Labels)\n",
    "#df_features.insert(0, \"case_id\", df_final[\"case_id\"].reset_index(drop=True).values)\n",
    "\n",
    "# optional: Duplikate prüfen (sollte 0 sein)\n",
    "#print(\"Duplicate case_id:\", df_features[\"case_id\"].duplicated().sum())\n",
    "\n",
    "#print(\"df_features shape:\", df_features.shape)\n",
    "#df_features[[\"case_id\"] + [c for c in df_features.columns if c.startswith(\"emb_\")]].head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32ca574",
   "metadata": {},
   "source": [
    "Der Analyse-Datensatz besteht aus 1.189 Beobachtungen (Urteilen) mit jeweils 200 numerischen Merkmalen, die den semantischen Gehalt der Entscheidungsgründe abbilden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e457d4a6",
   "metadata": {},
   "source": [
    "### 5.4 Modellierung und Evaluation (nach Verfügbarkeit der Labels)\n",
    "Auf Grundlage des in Abschnitt 5.3 aufgebauten Analyse-Datensatzes erfolgt im Folgenden die prädiktive Modellierung. Hierzu werden die semantischen Dokumenten-Embeddings mit den aus der automatisierten Extraktion gewonnenen Zielvariablen verknüpft und für den Einsatz überwachter Lernverfahren vorbereitet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b18330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5.4 (wird aktiviert sobald df_labels aus Batch da ist) ---\n",
    "\n",
    "# df_ml = df_features.merge(df_labels, on=\"case_id\", how=\"inner\")\n",
    "# X = df_ml.filter(like=\"emb_\").values\n",
    "# y = df_ml[\"LABEL_Anspruch_Schadensersatz\"].astype(int).values\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.2, random_state=42, stratify=y\n",
    "# )\n",
    "\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# rf = RandomForestClassifier(n_estimators=300, random_state=42, n_jobs=-1, class_weight=\"balanced\")\n",
    "# rf.fit(X_train, y_train)\n",
    "\n",
    "# from sklearn.metrics import classification_report, confusion_matrix\n",
    "# y_pred = rf.predict(X_test)\n",
    "# print(confusion_matrix(y_test, y_pred))\n",
    "# print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05160c8f",
   "metadata": {},
   "source": [
    "## 6. Analyse und Auswertung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb49984b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

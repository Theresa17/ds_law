{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f87c4b39",
   "metadata": {},
   "source": [
    "## 1. Datenimport und Initialisierung\n",
    "\n",
    "In diesem Abschnitt werden die OpenJur-Urteilstexte aus dem Datenverzeichnis eingelesen und die technische Datenbasis f√ºr die nachfolgenden Verarbeitungsschritte geschaffen. Dazu werden die ben√∂tigten Bibliotheken importiert und die verf√ºgbaren Textdateien identifiziert.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972de4e7",
   "metadata": {},
   "source": [
    "### 1.1 Import der ben√∂tigten Bibliotheken\n",
    "\n",
    "Zu Beginn werden die f√ºr die weitere Verarbeitung erforderlichen Python-Bibliotheken importiert. Diese umfassen Funktionen f√ºr Dateizugriffe, regul√§re Ausdr√ºcke, Datenverarbeitung mit Pandas sowie den Export der Ergebnisse im JSON-Format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58f86b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61a736b",
   "metadata": {},
   "source": [
    "### 1.2 Einlesen der OpenJur-Urteilstexte \n",
    "\n",
    "In diesem Schritt werden alle identifizierten Urteilstexte aus dem Datenverzeichnis eingelesen. Jede Datei wird √ºber den Dateinamen einer eindeutigen Fallkennung (`case_id`) zugeordnet. Die Texte bilden die Rohdatenbasis f√ºr die nachfolgenden Extraktions- und Filterprozesse. Der Datenpfad wird im Code parametriert (`DATA_DIR`), um eine reproduzierbare Ausf√ºhrung zu gew√§hrleisten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bef8dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pfad: c:\\Users\\humme\\OneDrive\\Dokumente\\Uni Ulm\\ds_law\\backend\\data\\Gerichtsurteile_Openjur\n",
      "Anzahl .txt: 2375\n",
      "Erste 10 Dateien: ['2090187.txt', '2112111.txt', '2112115.txt', '2112117.txt', '2112118.txt', '2112119.txt', '2112121.txt', '2112123.txt', '2124977.txt', '2126821.txt']\n"
     ]
    }
   ],
   "source": [
    "# (.txt) Dateien einlesen\n",
    "DATA_DIR = \"../data/Gerichtsurteile_Openjur\" \n",
    "files = [f for f in os.listdir(DATA_DIR) if f.lower().endswith(\".txt\")]\n",
    "\n",
    "print(\"Pfad:\", os.path.abspath(DATA_DIR))\n",
    "print(\"Anzahl .txt:\", len(files))\n",
    "print(\"Erste 10 Dateien:\", files[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d494b356",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed94d8a",
   "metadata": {},
   "source": [
    "## 2. Extraktion relevanter Urteilsbestandteile und Selektion der Landgerichtsurteile\n",
    "\n",
    "In diesem Abschnitt werden die eingelesenen Urteilstexte weiterverarbeitet, um f√ºr die nachfolgende Analyse relevante Textbestandteile gezielt zu extrahieren. Hierzu z√§hlen insbesondere ein begrenzter Kopfbereich zur Voranalyse sowie der Tenor als Kern der gerichtlichen Entscheidung. Die strukturierte Aufbereitung dieser Textsegmente bildet die Grundlage f√ºr Filter-, Klassifikations- und Extraktionsschritte in den folgenden Abschnitten."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c915ba",
   "metadata": {},
   "source": [
    "### 2.1 Aufbau des DataFrames und Extraktion eines Kopfbereichs\n",
    "\n",
    "Die eingelesenen Texte werden in einem DataFrame (`df`) gespeichert. Zus√§tzlich wird ein begrenzter Kopfbereich (`head`) aus den ersten Zeichen extrahiert, da strukturelle Metadaten wie Gerichtstyp, Entscheidungsart und Zitierzeilen typischerweise am Anfang des Dokuments auftreten. Dieser Kopfbereich dient als effizienter Suchraum f√ºr die sp√§tere Identifikation von Landgerichtsurteilen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28198986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gesamt eingelesen: 2375\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "for fn in files:\n",
    "    case_id = fn.replace(\".txt\", \"\")\n",
    "    path = os.path.join(DATA_DIR, fn)\n",
    "    with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        text = f.read()\n",
    "    rows.append({\"case_id\": case_id, \"text\": text})\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(\"Gesamt eingelesen:\", len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99a88600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head-L√§nge (Beispiel): 8000\n"
     ]
    }
   ],
   "source": [
    "HEAD_CHARS = 8000\n",
    "df[\"head\"] = df[\"text\"].astype(str).str.slice(0, HEAD_CHARS)\n",
    "\n",
    "print(\"Head-L√§nge (Beispiel):\", len(df.loc[0, \"head\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b62f66",
   "metadata": {},
   "source": [
    "### 2.2 Extraktion des Tenors\n",
    "\n",
    "Der Tenor enth√§lt die eigentliche gerichtliche Entscheidung und ist daher f√ºr die inhaltliche Bewertung besonders relevant. Mithilfe regul√§rer Ausdr√ºcke wird der Textabschnitt zwischen der √úberschrift ‚ÄûTenor‚Äú und den nachfolgenden Abschnitten (z. B. ‚ÄûTatbestand‚Äú oder ‚ÄûGr√ºnde‚Äú) extrahiert und in einer separaten Spalte gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fae0b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tenor vorhanden: 2362 von 2375\n"
     ]
    }
   ],
   "source": [
    "def extract_tenor(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    m_start = re.search(r\"\\bTenor\\b\", text, flags=re.IGNORECASE)\n",
    "    if not m_start:\n",
    "        return \"\"\n",
    "\n",
    "    start = m_start.end()\n",
    "\n",
    "    # Begrenztes Suchfenster nach dem Tenor (robuster gegen Navigation)\n",
    "    window = text[start:start + 20000]\n",
    "\n",
    "    m_end = re.search(\n",
    "        r\"\\b(Tatbestand|Gr√ºnde|Gruende|Entscheidungsgr√ºnde|Entscheidungsgruende)\\b\",\n",
    "        window,\n",
    "        flags=re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    end = start + m_end.start() if m_end else min(len(text), start + 8000)\n",
    "    return text[start:end].strip()\n",
    "df[\"tenor\"] = df[\"text\"].apply(extract_tenor)\n",
    "print(\"Tenor vorhanden:\", (df[\"tenor\"].str.len() > 0).sum(), \"von\", len(df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2481ec6a",
   "metadata": {},
   "source": [
    "### 2.3 Identifikation von Landgerichtsurteilen (LG)\n",
    "\n",
    "Die Selektion der Landgerichtsurteile erfolgt anhand einer OpenJur-spezifischen Zitierzeile im Kopfbereich (Regex: ‚ÄûEinfach‚Äú gefolgt von ‚ÄûLG‚Äú). Auf dieser Grundlage wird eine boolesche Variable erzeugt und der Teilkorpus df_lg gebildet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f6ff89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "‚úÖ Echte LG-Urteile (√ºber Zitierzeile): 1189\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Wir suchen nach der Zeile, die mit \"Einfach\" beginnt, gefolgt von \"LG\"\n",
    "# Der Regex r\"Einfach\\s*\\n\\s*LG\" stellt sicher, dass LG direkt darunter steht\n",
    "pattern_zitierung_lg = r\"Einfach\\s*\\n\\s*LG\"\n",
    "\n",
    "# Wir wenden das auf die Spalte an, die den Kopftext enth√§lt\n",
    "df[\"is_landgericht\"] = df[\"head\"].str.contains(pattern_zitierung_lg, regex=True, na=False)\n",
    "\n",
    "# Jetzt erstellen wir den sauberen Dataframe\n",
    "df_lg = df[df[\"is_landgericht\"] == True].copy()\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(f\"‚úÖ Echte LG-Urteile (√ºber Zitierzeile): {len(df_lg)}\")\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85194c82",
   "metadata": {},
   "source": [
    "### 2.4 Segmentierung der Urteile in juristische Abschnitte\n",
    "F√ºr die sp√§tere Extraktion werden die Urteile in juristisch sinnvolle Teile zerlegt: Rubrum, Tenor, Tatbestand und Entscheidungsgr√ºnde. Dadurch kann das Modell gezielt relevante Passagen verarbeiten.\n",
    "Die Segmentierung dient dazu, sp√§tere Analysen gezielt auf entscheidungsrelevante Abschnitte (insb. Tenor und Entscheidungsgr√ºnde) zu fokussieren.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "870d2bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_judgment(text):\n",
    "    \"\"\"\n",
    "    Teilt ein Urteil in Rubrum, Tenor, Tatbestand und Entscheidungsgr√ºnde auf.\n",
    "    \"\"\"\n",
    "    segments = {\n",
    "        \"rubrum\": \"\",\n",
    "        \"tenor\": \"\",\n",
    "        \"tatbestand\": \"\",\n",
    "        \"entscheidungsgruende\": \"\"\n",
    "    }\n",
    "    \n",
    "    # Muster f√ºr die Abschnitts√ºberschriften\n",
    "    # Das Rubrum ist alles vor dem Tenor\n",
    "    m_tenor = re.search(r\"\\bTenor\\b\", text, re.IGNORECASE)\n",
    "    m_tatbestand = re.search(r\"\\bTatbestand\\b\", text, re.IGNORECASE)\n",
    "    m_gruende = re.search(r\"\\b(Entscheidungsgr√ºnde|Entscheidungsgruende|Gr√ºnde|Gruende)\\b\", text, re.IGNORECASE)\n",
    "    \n",
    "    if m_tenor:\n",
    "        segments[\"rubrum\"] = text[:m_tenor.start()].strip()\n",
    "        \n",
    "        # Tenor bis Tatbestand\n",
    "        if m_tatbestand:\n",
    "            segments[\"tenor\"] = text[m_tenor.end():m_tatbestand.start()].strip()\n",
    "            \n",
    "            # Tatbestand bis Gr√ºnde\n",
    "            if m_gruende:\n",
    "                segments[\"tatbestand\"] = text[m_tatbestand.end():m_gruende.start()].strip()\n",
    "                segments[\"entscheidungsgruende\"] = text[m_gruende.end():].strip()\n",
    "            else:\n",
    "                segments[\"tatbestand\"] = text[m_tatbestand.end():].strip()\n",
    "        else:\n",
    "            # Falls kein Tatbestand gefunden wird, Tenor bis zum Ende oder Gr√ºnden\n",
    "            if m_gruende:\n",
    "                segments[\"tenor\"] = text[m_tenor.end():m_gruende.start()].strip()\n",
    "                segments[\"entscheidungsgruende\"] = text[m_gruende.end():].strip()\n",
    "            else:\n",
    "                segments[\"tenor\"] = text[m_tenor.end():].strip()\n",
    "                \n",
    "    return segments\n",
    "\n",
    "# Beispielanwendung auf den Dataframe\n",
    "df_lg['segments'] = df_lg['text'].apply(split_judgment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78144122",
   "metadata": {},
   "source": [
    "## 3 Prompt-Generierung und Pilotierung der LLM-Extraktion (Gemini Batch)\n",
    "Um API- und Token-Limits zu ber√ºcksichtigen, werden OpenJur-spezifische Navigationselemente aus dem Rubrum entfernt und alle Abschnitte in ihrer L√§nge begrenzt. Auf Basis dieser vorverarbeiteten Textsegmente wird ein standardisierter Prompt generiert, der die Extraktion der abgestimmten Variablen im JSON-Format steuert.\n",
    "Die segmentweise L√§ngenbegrenzung dient der Einhaltung von Token-Limits sowie der Reduktion von Kosten und Laufzeit, ohne entscheidungsrelevante Passagen (insb. Tenor und Entscheidungsgr√ºnde) zu verlieren.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d039d706",
   "metadata": {},
   "source": [
    "### 3.1 Aufbereitung der Segmente und Definition des Extraktions-Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af70046",
   "metadata": {},
   "source": [
    "Der Prompt wurde so konzipiert, dass er neben technischen Features (Motor, Kilometer) gezielt die Anforderungen der Aufgabenstellung erf√ºllt. Kernaspekte sind die Identifikation des Gerichtstyps sowie die Differenzierung der Zielvariable in Schadensersatz, Klageabweisung und prozessuale Sonderf√§lle (‚ÄûSonstige‚Äú). Durch explizite Anweisungen zum Ausschluss von Zinsen und zur Erkennung von Streitwertbeschl√ºssen wird eine hohe Datenqualit√§t f√ºr das anschlie√üende Machine Learning sichergestellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ed232f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_rubrum(rubrum: str) -> str:\n",
    "    if not isinstance(rubrum, str):\n",
    "        return \"\"\n",
    "\n",
    "    blacklist = [\n",
    "        \"rechtsprechung\", \"aktuell\", \"trending\", \"filter\",\n",
    "        \"√ºber openjur\", \"spenden\", \"api\", \"hilfe\",\n",
    "        \"startseite\", \"bundesland\", \"gerichtsbarkeit\",\n",
    "        \"impressum\", \"datenschutz\", \"nutzungsbedingungen\",\n",
    "        \"fachzeitschriften\", \"suchen\", \"changelog\", \"einfach\",\n",
    "        \"json\", \"bibtex\", \"ris\"\n",
    "    ]\n",
    "\n",
    "    lines = []\n",
    "    for line in rubrum.splitlines():\n",
    "        l = line.strip().lower()\n",
    "        if not l:\n",
    "            continue\n",
    "        if any(b in l for b in blacklist):\n",
    "            continue\n",
    "        lines.append(line.strip())\n",
    "\n",
    "    return \"\\n\".join(lines[:5])   \n",
    "\n",
    "def slim_segments(segments):\n",
    "    return {\n",
    "        \"rubrum\": clean_rubrum(segments.get(\"rubrum\") or \"\")[:2500],\n",
    "        \"tenor\": (segments.get(\"tenor\") or \"\")[:4000],\n",
    "        \"tatbestand\": (segments.get(\"tatbestand\") or \"\")[:3500],\n",
    "        \"entscheidungsgruende\": (segments.get(\"entscheidungsgruende\") or \"\")[:7000],\n",
    "    }\n",
    "def get_gemini_prompt(segments):\n",
    "    \"\"\"\n",
    "    Erstellt den finalen Prompt basierend auf den Urteilssegmenten.\n",
    "    \"\"\"\n",
    "    s = slim_segments(segments)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Analysiere die folgenden Abschnitte eines Gerichtsurteils zum Dieselskandal und extrahiere die Variablen pr√§zise als JSON-Liste. \n",
    "\n",
    "### URTEILS-BESTANDTEILE:\n",
    "RUBRUM (Kopfbereich mit Gericht & Datum): \n",
    "{s['rubrum']}\n",
    "\n",
    "TENOR (Ergebnis): \n",
    "{s['tenor']}\n",
    "\n",
    "TATBESTAND (Sachverhalt): \n",
    "{s['tatbestand']}\n",
    "\n",
    "ENTSCHEIDUNGSGR√úNDE (Rechtliche W√ºrdigung): \n",
    "{s['entscheidungsgruende']}\n",
    "\n",
    "### EXTRAKTIONS-AUFGABE:\n",
    "Extrahiere folgende Variablen (bei Nichtfinden 'null' angeben):\n",
    "\n",
    "WICHTIG (Validierung & Datenqualit√§t):\n",
    "1) **Gerichtstyp** muss explizit angegeben werden (z.B. \"Landgericht\", \"Oberlandesgericht\", \"Amtsgericht\").  \n",
    "2) **Sonstige-Kategorie (prozessuale Dokumente):** Falls das Dokument **keine materielle Entscheidung √ºber einen Schadensersatzanspruch** enth√§lt (z.B. nur Streitwertfestsetzung/-beschluss, Prozesskostenhilfe/PKH, Kostenentscheidung ohne Sachentscheidung, Ablehnungsgesuch/Befangenheit, rein prozessualer Beschluss), dann setze zwingend:\n",
    "   - LABEL_Anspruch_Schadensersatz = false\n",
    "   - LABEL_Schadensersatzhoehe_Betrag = null\n",
    "   - LABEL_Schadensersatzhoehe_Range = \"Sonstige\"\n",
    "3) **Betrag ohne Zinsen:** LABEL_Schadensersatzhoehe_Betrag ist **ohne Zinsen/Verzugszinsen/Nebenforderungen** anzugeben.\n",
    "\n",
    "1. **Input-Variablen (Features):**\n",
    "   - Dieselmotor_Typ: (Beispiel: \"EA 189\", \"EA 288\")\n",
    "   - Art_Abschalteinrichtung: (Beispiel: \"Umschaltlogik\", \"Thermofenster\")\n",
    "   - KBA_Rueckruf: (Boolean: true/false - Beispiel: true)\n",
    "   - Fahrzeugstatus: (\"Neuwagen\" oder \"Gebrauchtwagen\")\n",
    "   - Fahrzeugmodell_Baureihe: (Beispiel: \"VW Golf 2.0 TDI\")\n",
    "   - Update_Status: (Boolean: true/false/null - Beispiel: false)\n",
    "   - Kilometerstand_Kauf: (Integer - Beispiel: 15200)\n",
    "   - Kilometerstand_Klageerhebung: (Integer - Beispiel: 45000)\n",
    "   - Erwartete_Gesamtlaufleistung: (Integer - Beispiel: 250000)\n",
    "   - Kaufdatum: (Date YYYY-MM-DD - Beispiel: 2014-05-12)\n",
    "   - Uebergabedatum: (Date YYYY-MM-DD - Beispiel: 2014-05-20)\n",
    "   - Datum_Klageerhebung: (Date YYYY-MM-DD - Beispiel: 2018-11-03)\n",
    "   - Beklagten_Typ: (\"H√§ndler\" oder \"Hersteller\")\n",
    "   - Datum_Urteil: (Date YYYY-MM-DD - Beispiel: 2019-12-17)\n",
    "   - Kaufpreis: (Float in EUR - Beispiel: 25900.00)\n",
    "   - Nacherfuellungsverlangen_Fristsetzung: (\"Ja\", \"Nein\", \"Entbehrlich\")\n",
    "   - Klageziel: (\"R√ºckabwicklung\", \"Minderung\", \"Schadensersatz\")\n",
    "   - Rechtsgrundlage: (Beispiel: \"¬ß 826 BGB\", \"¬ß 437 BGB\")\n",
    "\n",
    "2. **Zielvariablen (Labels):**\n",
    "   - LABEL_Anspruch_Schadensersatz (Boolean: true/false - Beispiel: true)\n",
    "   - LABEL_Schadensersatzhoehe_Betrag (Float in EUR - Beispiel: 18450.50)\n",
    "   - LABEL_Schadensersatzhoehe_Range (Beispiel: \"< 5000\", \"5000-10000\", \"10000-15000\", \"15000-20000\", \"20000-25000\", \"> 25000\", \"Abgewiesen\")\n",
    "\n",
    "### AUSGABEFORMAT:\n",
    "Antworte NUR mit einem validen JSON-Objekt in einer Liste:\n",
    "[{{\n",
    "  \"case_id\": null,\n",
    "  \"Gerichtstyp\": null,\n",
    "  \"Dieselmotor_Typ\": null,\n",
    "  \"Art_Abschalteinrichtung\": null,\n",
    "  \"KBA_Rueckruf\": null,\n",
    "  \"Fahrzeugstatus\": null,\n",
    "  \"Fahrzeugmodell_Baureihe\": null,\n",
    "  \"Update_Status\": null,\n",
    "  \"Kilometerstand_Kauf\": null,\n",
    "  \"Kilometerstand_Klageerhebung\": null,\n",
    "  \"Erwartete_Gesamtlaufleistung\": null,\n",
    "  \"Kaufdatum\": null,\n",
    "  \"Uebergabedatum\": null,\n",
    "  \"Datum_Klageerhebung\": null,\n",
    "  \"Nachweis_Aufklaerung\": null,\n",
    "  \"Beklagten_Typ\": null,\n",
    "  \"Datum_Urteil\": null,\n",
    "  \"Kaufpreis\": null,\n",
    "  \"Nacherfuellungsverlangen_Fristsetzung\": null,\n",
    "  \"Klageziel\": null,\n",
    "  \"Rechtsgrundlage\": null,\n",
    "  \"LABEL_Anspruch_Schadensersatz\": null,\n",
    "  \"LABEL_Schadensersatzhoehe_Betrag\": null,\n",
    "  \"LABEL_Schadensersatzhoehe_Range\": null\n",
    "}}]\n",
    "\"\"\".strip()\n",
    "\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f043ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starte 'Pay-as-you-go' Lauf f√ºr 1189 F√§lle mit models/gemini-2.5-flash...\n",
      "üíæ Zwischenergebnisse werden alle 50 F√§lle in 'gemini_results_checkpoint.csv' gespeichert.\n",
      "‚úÖ 50/1189 geschafft (976.1s) -> üíæ Checkpoint gesichert.\n",
      "‚úÖ 100/1189 geschafft (1830.6s) -> üíæ Checkpoint gesichert.\n",
      "‚úÖ 150/1189 geschafft (2801.6s) -> üíæ Checkpoint gesichert.\n",
      "‚úÖ 200/1189 geschafft (3741.5s) -> üíæ Checkpoint gesichert.\n",
      "‚úÖ 250/1189 geschafft (4609.3s) -> üíæ Checkpoint gesichert.\n",
      "‚úÖ 300/1189 geschafft (5551.5s) -> üíæ Checkpoint gesichert.\n",
      "‚úÖ 350/1189 geschafft (6510.9s) -> üíæ Checkpoint gesichert.\n",
      "‚úÖ 400/1189 geschafft (7372.8s) -> üíæ Checkpoint gesichert.\n",
      "‚úÖ 450/1189 geschafft (8183.8s) -> üíæ Checkpoint gesichert.\n",
      "‚úÖ 500/1189 geschafft (8984.6s) -> üíæ Checkpoint gesichert.\n",
      "‚úÖ 550/1189 geschafft (9833.6s) -> üíæ Checkpoint gesichert.\n",
      "‚úÖ 600/1189 geschafft (10653.7s) -> üíæ Checkpoint gesichert.\n",
      "‚úÖ 650/1189 geschafft (11524.9s) -> üíæ Checkpoint gesichert.\n",
      "‚úÖ 700/1189 geschafft (12349.7s) -> üíæ Checkpoint gesichert.\n",
      "‚úÖ 750/1189 geschafft (13226.1s) -> üíæ Checkpoint gesichert.\n",
      "‚úÖ 800/1189 geschafft (14029.4s) -> üíæ Checkpoint gesichert.\n",
      "‚úÖ 850/1189 geschafft (14906.0s) -> üíæ Checkpoint gesichert.\n",
      "‚úÖ 900/1189 geschafft (15707.2s) -> üíæ Checkpoint gesichert.\n",
      "‚úÖ 950/1189 geschafft (16553.7s) -> üíæ Checkpoint gesichert.\n",
      "‚úÖ 1000/1189 geschafft (17397.4s) -> üíæ Checkpoint gesichert.\n",
      "‚úÖ 1050/1189 geschafft (18190.7s) -> üíæ Checkpoint gesichert.\n",
      "‚úÖ 1100/1189 geschafft (19096.5s) -> üíæ Checkpoint gesichert.\n",
      "‚úÖ 1150/1189 geschafft (19901.6s) -> üíæ Checkpoint gesichert.\n",
      "\n",
      "üéâ FERTIG!\n",
      "Erfolgreich extrahiert: 1189\n",
      "‚úÖ Finale Daten gespeichert als: gemini_results_paid_complete.csv\n",
      "üßπ Checkpoint-Datei entfernt (Job erledigt).\n"
     ]
    }
   ],
   "source": [
    "'''import time\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "from google import genai\n",
    "\n",
    "# --- 1. EINSTELLUNGEN ---\n",
    "MODEL_NAME = \"models/gemini-2.5-flash\"\n",
    "CHECKPOINT_FILE = \"gemini_results_checkpoint.csv\" # Sicherungsdatei\n",
    "\n",
    "# API Key Client starten\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\") \n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "# --- 2. HILFSFUNKTIONEN ---\n",
    "def extract_json_from_llm(text: str):\n",
    "    text = re.sub(r\"^```json\\s*|\\s*```$\", \"\", text.strip(), flags=re.MULTILINE)\n",
    "    m = re.search(r\"(\\[\\s*\\{.*?\\}\\s*\\]|\\{.*?\\})\", text, flags=re.DOTALL)\n",
    "    if not m: raise ValueError(\"Kein JSON gefunden\")\n",
    "    return json.loads(m.group(1))\n",
    "\n",
    "# --- 3. DER HAUPT-LAUF (ROBUST & KORREKTER Z√ÑHLER) ---\n",
    "working_df = df_lg.copy() \n",
    "results = []\n",
    "errors = []\n",
    "\n",
    "print(f\"üöÄ Starte 'Pay-as-you-go' Lauf f√ºr {len(working_df)} F√§lle mit {MODEL_NAME}...\")\n",
    "print(f\"üíæ Zwischenergebnisse werden alle 50 F√§lle in '{CHECKPOINT_FILE}' gespeichert.\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# KORREKTUR: Wir nutzen enumerate(), um einen echten Z√§hler (i) zu haben\n",
    "for i, (index, row) in enumerate(working_df.iterrows()):\n",
    "    case_id = row['case_id']\n",
    "    \n",
    "    # Retry-Logik\n",
    "    max_retries = 3\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # 1. Prompt holen (MIT Sicherheits-Check f√ºr Strings)\n",
    "            segs = row[\"segments\"]\n",
    "            if isinstance(segs, str):\n",
    "                import ast\n",
    "                segs = ast.literal_eval(segs)\n",
    "            \n",
    "            # (Hier war dein Einr√ºckungsfehler)\n",
    "            prompt = get_gemini_prompt(segs)\n",
    "            \n",
    "            # 2. Anfrage senden (Das fehlte in deinem Code!)\n",
    "            response = client.models.generate_content(\n",
    "                model=MODEL_NAME,\n",
    "                contents=prompt\n",
    "            )\n",
    "            \n",
    "            # 3. Ergebnis verarbeiten\n",
    "            data = extract_json_from_llm(response.text)\n",
    "            if isinstance(data, list): data = data[0]\n",
    "            \n",
    "            data[\"case_id\"] = case_id\n",
    "            results.append(data)\n",
    "            \n",
    "            # Fortschrittsanzeige & Checkpoint (nutzt jetzt 'i' statt 'index')\n",
    "            if (i + 1) % 50 == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                \n",
    "                # Checkpoint speichern\n",
    "                pd.DataFrame(results).to_csv(CHECKPOINT_FILE, index=False)\n",
    "                \n",
    "                print(f\"‚úÖ {i + 1}/{len(working_df)} geschafft ({elapsed:.1f}s) -> üíæ Checkpoint gesichert.\")\n",
    "            \n",
    "            break # Erfolg -> Raus aus Retry\n",
    "\n",
    "        except Exception as e:\n",
    "            error_msg = str(e)\n",
    "            # Exponentielles Warten: 5s, 10s, 15s\n",
    "            wait_time = 5 * (attempt + 1)\n",
    "            \n",
    "            if \"429\" in error_msg or \"RESOURCE_EXHAUSTED\" in error_msg:\n",
    "                if attempt < max_retries - 1:\n",
    "                    print(f\"‚è≥ Limit bei {case_id}. Warte {wait_time}s (Versuch {attempt+1}/{max_retries})...\")\n",
    "                    time.sleep(wait_time)\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"‚ùå Limit-Fehler bei {case_id} endg√ºltig.\")\n",
    "                    errors.append({\"case_id\": case_id, \"error\": \"429 Limit\"})\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Fehler bei {case_id}: {error_msg}\")\n",
    "                errors.append({\"case_id\": case_id, \"error\": error_msg})\n",
    "                break\n",
    "\n",
    "print(\"\\nüéâ FERTIG!\")\n",
    "print(f\"Erfolgreich extrahiert: {len(results)}\")\n",
    "\n",
    "# --- 4. FINALES SPEICHERN ---\n",
    "df_final = pd.DataFrame(results)\n",
    "filename = \"gemini_results_paid_complete.csv\"\n",
    "df_final.to_csv(filename, index=False)\n",
    "print(f\"‚úÖ Finale Daten gespeichert als: {filename}\")\n",
    "\n",
    "# Aufr√§umen: Wenn alles geklappt hat, l√∂schen wir den Checkpoint\n",
    "if os.path.exists(CHECKPOINT_FILE):\n",
    "    os.remove(CHECKPOINT_FILE)\n",
    "    print(\"üßπ Checkpoint-Datei entfernt (Job erledigt).\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f99f72e",
   "metadata": {},
   "source": [
    "## 4 Verarbeitung der Modellantworten und Erstellung des Extraktions-Datensatzes\n",
    "\n",
    "In diesem Abschnitt werden die Ergebnisse des direkten API-Durchlaufs (`gemini_results_paid_complete.csv`) eingelesen und mit den urspr√ºnglichen Urteilstexten verkn√ºpft. Um eine hohe Datenqualit√§t f√ºr das anschlie√üende Machine Learning zu gew√§hrleisten, erfolgen hier zudem wichtige Bereinigungsschritte:\n",
    "\n",
    "1.  **Daten-Merge:** Die KI-Extraktionen werden √ºber die eindeutige `case_id` mit den Originaltexten (`df_lg`) zusammengef√ºhrt. Dabei wird sichergestellt, dass die ID in beiden Datens√§tzen als String behandelt wird, um Datenverlust zu vermeiden.\n",
    "2.  **Bereinigung von Geldbetr√§gen:** Die Funktion `clean_money_robust` konvertiert diverse deutsche W√§hrungsformate (z. B. \"25.000,00 ‚Ç¨\", \"1.000 Euro\" oder \"25.000\") zuverl√§ssig in numerische Gleitkommazahlen (`float`), indem sie Tausenderpunkte und W√§hrungssymbole korrekt interpretiert und entfernt.\n",
    "3.  **Standardisierung der Zielvariable:** Die Funktion `determine_target_label` vereinheitlicht die unterschiedlichen R√ºckgabeformate des Modells (z. B. \"True\", \"yes\", \"1\") in saubere Kategorien (\"Schadensersatz\", \"Abgewiesen\", \"Sonstige\").\n",
    "\n",
    "Abschlie√üend wird der bereinigte Gesamtdatensatz sowohl im CSV-Format (f√ºr manuelle Pr√ºfung) als auch im Parquet-Format (f√ºr performante Weiterverarbeitung) gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48fb521c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in c:\\users\\humme\\onedrive\\dokumente\\uni ulm\\ds_law\\.venv\\lib\\site-packages (23.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "üì• Lade Ergebnisse aus: gemini_results_paid_complete.csv\n",
      "‚úÖ Merge erfolgreich: 1189 Datens√§tze.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "üìä Verteilung Target-Label:\n",
      "target_label\n",
      "Abgewiesen        572\n",
      "Schadensersatz    531\n",
      "Sonstige           86\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üíæ Datensatz gespeichert (Parquet & CSV).\n"
     ]
    }
   ],
   "source": [
    "# Wir laden die Ergebnisse, bereinigen Datentypen und f√ºhren sie mit den Originaltexten zusammen.\n",
    "%pip install pyarrow \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "# 1. Konfiguration & Laden\n",
    "RESULTS_FILENAME = \"gemini_results_paid_complete.csv\"\n",
    "\n",
    "if not os.path.exists(RESULTS_FILENAME):\n",
    "    raise FileNotFoundError(f\"Datei {RESULTS_FILENAME} fehlt! Bitte Kapitel 3 ausf√ºhren.\")\n",
    "\n",
    "print(f\"üì• Lade Ergebnisse aus: {RESULTS_FILENAME}\")\n",
    "df_extracted = pd.read_csv(RESULTS_FILENAME)\n",
    "\n",
    "# IDs f√ºr Merge sicherstellen (String)\n",
    "df_lg[\"case_id\"] = df_lg[\"case_id\"].astype(str)\n",
    "df_extracted[\"case_id\"] = df_extracted[\"case_id\"].astype(str)\n",
    "\n",
    "# 2. Merge: Originaltexte (df_lg) + KI-Daten (df_extracted)\n",
    "df_dataset = pd.merge(df_lg, df_extracted, on=\"case_id\", how=\"inner\")\n",
    "\n",
    "print(f\"‚úÖ Merge erfolgreich: {len(df_dataset)} Datens√§tze.\")\n",
    "\n",
    "# --- BEREINIGUNGS-FUNKTIONEN ---\n",
    "\n",
    "def clean_money_robust(val):\n",
    "    \"\"\" Wandelt Strings wie '25.000,00' oder '1000 ‚Ç¨' sicher in Floats um. \"\"\"\n",
    "    if pd.isna(val) or str(val).strip().lower() in [\"null\", \"none\", \"nan\", \"\"]:\n",
    "        return 0.0\n",
    "    \n",
    "    if isinstance(val, (int, float)):\n",
    "        return float(val)\n",
    "\n",
    "    s = str(val).strip()\n",
    "    # Entferne alles au√üer Ziffern, Punkt, Komma, Minus\n",
    "    s = re.sub(r'[^\\d.,-]', '', s)\n",
    "    \n",
    "    # Logik f√ºr deutsche Tausenderpunkte (z.B. 25.000 -> 25000)\n",
    "    if \",\" in s:\n",
    "        s = s.replace(\".\", \"\")  # Tausender weg\n",
    "        s = s.replace(\",\", \".\") # Dezimal-Komma zu Punkt\n",
    "    else:\n",
    "        # Fall \"25.000\" (ohne Komma) -> Punkt ist Tausender\n",
    "        if \".\" in s:\n",
    "            parts = s.split(\".\")\n",
    "            # Wenn nach dem letzten Punkt genau 3 Ziffern kommen und davor auch was steht\n",
    "            if len(parts) > 1 and len(parts[-1]) == 3:\n",
    "                s = s.replace(\".\", \"\")\n",
    "    \n",
    "    try:\n",
    "        return float(s)\n",
    "    except ValueError:\n",
    "        return 0.0\n",
    "\n",
    "def determine_target_label(row):\n",
    "    \"\"\" Bestimmt die Zielklasse: Schadensersatz, Abgewiesen oder Sonstige. \"\"\"\n",
    "    # 1. Sonstige (Prozessual)\n",
    "    if str(row.get(\"LABEL_Schadensersatzhoehe_Range\")).lower() == \"sonstige\":\n",
    "        return \"Sonstige\"\n",
    "    \n",
    "    # 2. Anspruch (True/False pr√ºfen)\n",
    "    val = str(row.get(\"LABEL_Anspruch_Schadensersatz\")).strip().lower()\n",
    "    if val in [\"true\", \"1\", \"1.0\", \"ja\", \"yes\"]:\n",
    "        return \"Schadensersatz\"\n",
    "    \n",
    "    return \"Abgewiesen\"\n",
    "\n",
    "# --- ANWENDUNG ---\n",
    "\n",
    "# Geld bereinigen\n",
    "if \"Kaufpreis\" in df_dataset.columns:\n",
    "    df_dataset[\"Kaufpreis_num\"] = df_dataset[\"Kaufpreis\"].apply(clean_money_robust)\n",
    "\n",
    "if \"LABEL_Schadensersatzhoehe_Betrag\" in df_dataset.columns:\n",
    "    df_dataset[\"Schadensersatz_Betrag_num\"] = df_dataset[\"LABEL_Schadensersatzhoehe_Betrag\"].apply(clean_money_robust)\n",
    "\n",
    "# Label erstellen\n",
    "df_dataset[\"target_label\"] = df_dataset.apply(determine_target_label, axis=1)\n",
    "\n",
    "# Speichern\n",
    "df_dataset.to_parquet(\"lg_diesel_urteile_final.parquet\", index=False)\n",
    "df_dataset.to_csv(\"lg_diesel_urteile_final.csv\", index=False)\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(\"üìä Verteilung Target-Label:\")\n",
    "print(df_dataset[\"target_label\"].value_counts(dropna=False))\n",
    "print(f\"\\nüíæ Datensatz gespeichert (Parquet & CSV).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2911c4f4",
   "metadata": {},
   "source": [
    "### 4.3 Zusammenf√ºhrung mit Metadaten und Speicherung (CSV/Parquet) (Platzhalter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500c339b",
   "metadata": {},
   "source": [
    "In diesem finalen Schritt der Datenextraktion werden die extrahierten Modellantworten (`df_extracted`) mit den urspr√ºnglichen Metadaten und Urteilstexten der Landgerichte (`df_lg`) zusammengef√ºhrt. Die Verkn√ºpfung erfolgt √ºber die eindeutige `case_id`, um eine konsistente Zuordnung zwischen den technischen Features (z. B. Motortyp, Kilometerstand) und den Zielvariablen (Schadensersatzh√∂he, Anspruchsstatus) zu gew√§hrleisten.\n",
    "\n",
    "Der resultierende Gesamtdatensatz wird in zwei Formaten exportiert:\n",
    "* **CSV-Format:** Zur einfachen manuellen √úberpr√ºfung der Extraktionsergebnisse in Excel/Tabellenkalkulationen.\n",
    "* **Parquet-Format:** Zur effizienten Weiterverarbeitung in der Machine-Learning-Phase (Kapitel 5), da dieses Format Datentypen (z. B. numerische Betr√§ge ohne Zinsen) verlustfrei speichert.\n",
    "\n",
    "Damit ist die Datenbasis f√ºr die nachfolgende semantische Analyse und Modellierung vollst√§ndig vorbereitet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd5436cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Merge abgeschlossen: 1189 Urteile\n",
      "‚úÖ Fertig. Datei gespeichert. Kaufpreise sind jetzt korrekt.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# 1. Datentypen angleichen\n",
    "df_lg[\"case_id\"] = df_lg[\"case_id\"].astype(str)\n",
    "df_extracted[\"case_id\"] = df_extracted[\"case_id\"].astype(str)\n",
    "\n",
    "# 2. Merge durchf√ºhren\n",
    "df_dataset = pd.merge(\n",
    "    df_lg,\n",
    "    df_extracted,\n",
    "    on=\"case_id\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Merge abgeschlossen: {df_dataset.shape[0]} Urteile\")\n",
    "\n",
    "# 3. Target Label erstellen\n",
    "def determine_label(row):\n",
    "    if str(row.get(\"LABEL_Schadensersatzhoehe_Range\")).lower() == \"sonstige\":\n",
    "        return \"Sonstige\"\n",
    "    val = row.get(\"LABEL_Anspruch_Schadensersatz\")\n",
    "    if str(val).lower() == \"true\":\n",
    "        return \"Schadensersatz\"\n",
    "    return \"Abgewiesen\"\n",
    "\n",
    "df_dataset[\"target_label\"] = df_dataset.apply(determine_label, axis=1)\n",
    "\n",
    "# 4. KORRIGIERTE Geld-Funktion (Wichtig!)\n",
    "def clean_money(val):\n",
    "    if pd.isna(val) or str(val).strip().lower() in [\"null\", \"none\", \"nan\", \"\"]:\n",
    "        return 0.0\n",
    "    \n",
    "    s = str(val).strip()\n",
    "    s = re.sub(r'[^\\d.,-]', '', s) # Nur Zahlen, Punkt, Komma\n",
    "    \n",
    "    # Deutsche Logik: Wenn Komma da ist, muss Punkt weg (Tausender)\n",
    "    if \",\" in s:\n",
    "        s = s.replace(\".\", \"\")      # 25.000,00 -> 25000,00\n",
    "        s = s.replace(\",\", \".\")     # 25000,00 -> 25000.00\n",
    "    else:\n",
    "        # Fall: \"25.000\" (ohne Komma)\n",
    "        if \".\" in s and len(s.split(\".\")[-1]) == 3:\n",
    "             s = s.replace(\".\", \"\")\n",
    "             \n",
    "    try:\n",
    "        return float(s)\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "if \"Kaufpreis\" in df_dataset.columns:\n",
    "    df_dataset[\"Kaufpreis_num\"] = df_dataset[\"Kaufpreis\"].apply(clean_money)\n",
    "\n",
    "# 5. Speichern\n",
    "OUTPUT_BASENAME = \"lg_diesel_urteile_final\"\n",
    "df_dataset.to_csv(f\"{OUTPUT_BASENAME}.csv\", index=False, encoding=\"utf-8\")\n",
    "df_dataset.to_parquet(f\"{OUTPUT_BASENAME}.parquet\", index=False)\n",
    "\n",
    "print(f\"‚úÖ Fertig. Datei gespeichert. Kaufpreise sind jetzt korrekt.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cf9490",
   "metadata": {},
   "source": [
    "### 4.4 Datenaufteilung und Validierungskonzept\n",
    "\n",
    "Der Datensatz wird auf Fall-Ebene (`case_id`) in einen Trainings- (80 %) und einen Testdatensatz (20 %) aufgeteilt.  \n",
    "Der Trainingsdatensatz wird anschlie√üend mittels **5-facher stratified Cross-Validation** f√ºr die Modellselektion und Hyperparameter-Optimierung genutzt.\n",
    "\n",
    "Dieses Vorgehen erlaubt eine effiziente Nutzung der verf√ºgbaren, kostenintensiv extrahierten Labels, w√§hrend der Testdatensatz vollst√§ndig unber√ºhrt bleibt und ausschlie√ülich zur finalen Evaluation der Modellleistung dient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "962dc7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Split erfolgreich und Labels bereinigt!\n",
      "üìä Training: 951 F√§lle (davon 430x Schadensersatz)\n",
      "üìä Test:     238 F√§lle (davon 107x Schadensersatz)\n",
      "Probe-ID im Training: 2304966\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ### 4.4 Datenaufteilung und Validierungskonzept (Final & Repariert)\n",
    "# Wir teilen den GESAMTEN Datensatz in Train/Test.\n",
    "\n",
    "# %%\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Split auf dem gesamten DataFrame durchf√ºhren\n",
    "# WICHTIG: Das .fillna(\"false\") verhindert den \"Input contains NaN\" Fehler!\n",
    "df_lg_train, df_lg_test = train_test_split(\n",
    "    df_dataset,\n",
    "    test_size=0.20,\n",
    "    random_state=42,\n",
    "    stratify=df_dataset[\"LABEL_Anspruch_Schadensersatz\"].fillna(\"false\").astype(str).str.lower()\n",
    ")\n",
    "\n",
    "# 2. Robuste Reinigungs-Funktion f√ºr die Labels\n",
    "def to_int_label(s):\n",
    "    return (\n",
    "        s.astype(str).str.lower()\n",
    "         .map({\"true\": 1, \"false\": 0, \"1\": 1, \"0\": 0, \"ja\": 1, \"nein\": 0})\n",
    "         .astype(float)   # erlaubt NaN als Zwischenschritt\n",
    "         .fillna(0)       # NaN/Fehler werden zu 0 (Abgewiesen)\n",
    "         .astype(int)\n",
    "    )\n",
    "\n",
    "# 3. Anwendung: Wir bereinigen die Spalte direkt im DataFrame!\n",
    "# Damit sind die DataFrames f√ºr die Zukunft sauber.\n",
    "df_lg_train[\"LABEL_Anspruch_Schadensersatz\"] = to_int_label(df_lg_train[\"LABEL_Anspruch_Schadensersatz\"])\n",
    "df_lg_test[\"LABEL_Anspruch_Schadensersatz\"]  = to_int_label(df_lg_test[\"LABEL_Anspruch_Schadensersatz\"])\n",
    "\n",
    "# 4. y-Vektoren f√ºr Scikit-Learn ziehen\n",
    "y_train = df_lg_train[\"LABEL_Anspruch_Schadensersatz\"].values\n",
    "y_test  = df_lg_test[\"LABEL_Anspruch_Schadensersatz\"].values\n",
    "\n",
    "# 5. CV-Objekt erstellen\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "print(\"‚úÖ Split erfolgreich und Labels bereinigt!\")\n",
    "print(f\"üìä Training: {len(df_lg_train)} F√§lle (davon {sum(y_train)}x Schadensersatz)\")\n",
    "print(f\"üìä Test:     {len(df_lg_test)} F√§lle (davon {sum(y_test)}x Schadensersatz)\")\n",
    "print(f\"Probe-ID im Training: {df_lg_train.iloc[0]['case_id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f899d3",
   "metadata": {},
   "source": [
    "## 5. Datenaufbereitung f√ºr maschinelles Lernen\n",
    "\n",
    "In diesem Abschnitt werden die Urteilstexte f√ºr die nachgelagerte pr√§diktive Modellierung aufbereitet. Hierzu erfolgt zun√§chst eine juristisch angepasste Textvorverarbeitung und die Ableitung numerischer Textrepr√§sentationen. Die f√ºr die supervised Lernphase erforderlichen Zielvariablen werden im Rahmen der LLM-basierten Extraktion (Abschnitt 4) erzeugt und anschlie√üend mit den Textmerkmalen zusammengef√ºhrt (Abschnitt 5.4).\n",
    "Ziel der Datenaufbereitung ist es, die extrahierten Merkmale in eine konsistente, auswertbare Form zu √ºberf√ºhren, fehlende oder uneinheitliche Angaben zu behandeln und die Zielvariablen f√ºr die sp√§tere Analyse eindeutig zu definieren."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8ab869",
   "metadata": {},
   "source": [
    "### 5.1 Juristische Textvorverarbeitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237365cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir bereiten Train- und Testdaten identisch auf.\n",
    "# KORREKTUR: Verbesserte Erkennung von Geldbetr√§gen (Regex Update).\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. Setup: Spacy laden\n",
    "try:\n",
    "    nlp = spacy.load(\"de_core_news_lg\", disable=[\"ner\", \"parser\"])\n",
    "except Exception:\n",
    "    print(\"‚ö†Ô∏è Modell nicht gefunden. Lade Fallback...\")\n",
    "    import subprocess\n",
    "    subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", \"de_core_news_lg\"])\n",
    "    nlp = spacy.load(\"de_core_news_lg\", disable=[\"ner\", \"parser\"])\n",
    "\n",
    "# --- HILFSFUNKTIONEN ---\n",
    "\n",
    "def legal_preprocess(text):\n",
    "    \"\"\" Reinigt den Text (Lemmatisierung, Stoppw√∂rter, Platzhalter). \"\"\"\n",
    "    if not isinstance(text, str) or not text:\n",
    "        return \"\"\n",
    "    \n",
    "    # 1. Text normalisieren\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'<.*?>', ' ', text) # HTML-Reste weg\n",
    "    \n",
    "    # 2. PLATZHALTER SETZEN (Der wichtige Fix!)\n",
    "    # Erkl√§rung Regex:\n",
    "    # \\d{1,3}       -> Startet mit 1-3 Ziffern (z.B. 1, 50, 500)\n",
    "    # (?:\\.\\d{3})* -> Gefolgt von BELIEBIG vielen Tausender-Gruppen (.000)\n",
    "    # (?:,\\d+)?     -> Optionales Komma mit Cents\n",
    "    # \\s* -> Optionales Leerzeichen (f√§ngt auch \"100‚Ç¨\")\n",
    "    # (?:eur|‚Ç¨|euro)-> W√§hrungssymbol\n",
    "    \n",
    "    money_regex = r'\\d{1,3}(?:\\.\\d{3})*(?:,\\d+)?\\s*(?:eur|‚Ç¨|euro)'\n",
    "    text = re.sub(money_regex, ' PLATZHALTER_BETRAG ', text)\n",
    "    \n",
    "    # Paragraphen (z.B. ¬ß 826, ¬ß¬ß 280ff)\n",
    "    paragraph_regex = r'¬ß+\\s*\\d+[a-z]?'\n",
    "    text = re.sub(paragraph_regex, ' PLATZHALTER_PARAGRAPH ', text)\n",
    "    \n",
    "    # Jahreszahlen (1990-2029) grob filtern, um sie nicht als \"Zahl\" zu verlieren\n",
    "    text = re.sub(r'\\b(19|20)\\d{2}\\b', ' PLATZHALTER_JAHR ', text)\n",
    "    \n",
    "    # 3. Tokenisierung & Lemmatisierung mit Spacy\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # 4. Filterung (Stoppw√∂rter raus, Interpunktion raus)\n",
    "    tokens = [\n",
    "        t.lemma_ for t in doc \n",
    "        if not t.is_stop      # keine Stoppw√∂rter (\"der\", \"die\", \"und\")\n",
    "        and not t.is_punct    # keine Satzzeichen\n",
    "        and not t.is_space    # keine Leerzeichen\n",
    "        and len(t.text) > 1   # kein \"M√ºll\" wie einzelne Buchstaben\n",
    "    ]\n",
    "    \n",
    "    return \" \".join(tokens)\n",
    "\n",
    "def build_text_for_embedding(row):\n",
    "    \"\"\" \n",
    "    Baut den Text f√ºr das Modell: Fokus auf Tenor + Entscheidungsgr√ºnde.\n",
    "    Sichert ab, falls Segmente fehlen.\n",
    "    \"\"\"\n",
    "    segs = row.get(\"segments\")\n",
    "    \n",
    "    # Fallback, falls Segmente korrupt/fehlt\n",
    "    if not isinstance(segs, dict):\n",
    "        try:\n",
    "            # Versuch, den String wieder in ein Dict zu wandeln (falls CSV-Fehler)\n",
    "            import ast\n",
    "            segs = ast.literal_eval(str(segs))\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "    # Wenn immer noch kein Dict, nimm den rohen Text\n",
    "    if not isinstance(segs, dict):\n",
    "         return str(row[\"text\"])[:10000]\n",
    "\n",
    "    tenor = segs.get(\"tenor\") or \"\"\n",
    "    gruende = segs.get(\"entscheidungsgruende\") or \"\"\n",
    "    \n",
    "    combined = (tenor + \" \" + gruende).strip()\n",
    "    \n",
    "    # Wenn Tenor+Gr√ºnde zu kurz sind (z.B. Parsing-Fehler), nimm lieber alles als nichts\n",
    "    if len(combined) < 100:\n",
    "        return str(row[\"text\"])[:10000]\n",
    "    \n",
    "    return combined[:15000] # Limit f√ºr Spacy Performance\n",
    "\n",
    "# --- HAUPTVERARBEITUNG ---\n",
    "\n",
    "tqdm.pandas(desc=\"Preprocessing\")\n",
    "\n",
    "# 1. TRAININGS-DATEN\n",
    "print(\"‚öôÔ∏è Verarbeite TRAININGS-Daten...\")\n",
    "df_lg_train[\"text_for_embedding\"] = df_lg_train.apply(build_text_for_embedding, axis=1)\n",
    "df_lg_train[\"cleaned_text\"] = df_lg_train[\"text_for_embedding\"].progress_apply(legal_preprocess)\n",
    "\n",
    "# 2. TEST-DATEN (Exakt gleiches Verfahren!)\n",
    "print(\"‚öôÔ∏è Verarbeite TEST-Daten...\")\n",
    "df_lg_test[\"text_for_embedding\"] = df_lg_test.apply(build_text_for_embedding, axis=1)\n",
    "df_lg_test[\"cleaned_text\"] = df_lg_test[\"text_for_embedding\"].progress_apply(legal_preprocess)\n",
    "\n",
    "# 3. Ergebnis-Check\n",
    "print(\"-\" * 30)\n",
    "print(f\"‚úÖ Preprocessing abgeschlossen.\")\n",
    "print(f\"Train Samples: {len(df_lg_train)}\")\n",
    "print(\"Beispiel (Money-Check):\")\n",
    "# Wir suchen mal einen Text, wo hoffentlich Geld vorkam\n",
    "sample_text = df_lg_train[df_lg_train[\"cleaned_text\"].str.contains(\"betrag\", na=False)][\"cleaned_text\"].iloc[0]\n",
    "print(sample_text[:200] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f3b2a0",
   "metadata": {},
   "source": [
    "### 5.2 Text-Vektorisierung mittels Word2Vec\n",
    "Das Modell lernt semantische Relationen ausschlie√ülich aus dem Trainingskorpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc7f7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "df_train = df_lg_train\n",
    "\n",
    "# Tokenisierung (nur nicht-leere Texte)\n",
    "train_sentences = [\n",
    "    str(t).split()\n",
    "    for t in df_train[\"cleaned_text\"].fillna(\"\")\n",
    "    if str(t).strip()\n",
    "]\n",
    "\n",
    "print(\"Training des Word2Vec-Modells auf den Trainingsdaten...\")\n",
    "w2v_model = Word2Vec(\n",
    "    sentences=train_sentences,\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=2,\n",
    "    workers=4,\n",
    "    sg=1,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(\"y_train distribution (aus 4.4):\")\n",
    "print(y_train.value_counts(dropna=False))\n",
    "\n",
    "print(f\"‚úÖ Word2Vec-Modell trainiert. Vokabulargr√∂√üe: {len(w2v_model.wv)} W√∂rter.\")\n",
    "print(f\"‚úÖ Zielvariable y_train erstellt (N={len(y_train)}).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb422070",
   "metadata": {},
   "source": [
    "### 5.3 Aufbau des Analyse-Datensatzes\n",
    "Nach der Vektorisierung f√ºhren wir die mathematischen Ergebnisse in einer strukturierten Feature-Matrix zusammen. Wir wandeln die Sparse-Matrix in einen √ºbersichtlichen DataFrame um und verkn√ºpfen jedes Urteil √ºber die eindeutige case_id mit seinen Textmerkmalen. Diese Struktur ist essentiell, um im n√§chsten Schritt die durch das LLM extrahierten Zielvariablen (Schadensersatz oder Abweisung) pr√§zise jeder Beobachtung zuordnen zu k√∂nnen. Damit stellen wir sicher, dass der Datensatz modellunabh√§ngig konzipiert ist und eine solide Basis f√ºr die nachgelagerte pr√§diktive Modellierung bietet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff3c9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1. Hilfsfunktion zur Erstellung eines Dokument-Vektors\n",
    "def get_doc_vector(doc, model):\n",
    "    \"\"\" Erstellt einen Durchschnittsvektor aller bekannten W√∂rter im Urteil. \"\"\"\n",
    "    words = [w for w in str(doc).split() if w in model.wv]\n",
    "    if not words:\n",
    "        # Falls kein Wort des Urteils im Training vorkam, geben wir einen Null-Vektor zur√ºck\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(model.wv[words], axis=0)\n",
    "\n",
    "# 2. Vektorisierung der Trainings- und Testdaten\n",
    "# WICHTIG: Wir nutzen das w2v_model aus Schritt 5.2 (nur auf Train trainiert!)\n",
    "print(\"Vektorisierung der Trainingsdaten...\")\n",
    "X_train_vec = np.array([get_doc_vector(text, w2v_model) for text in df_lg_train[\"cleaned_text\"]])\n",
    "\n",
    "\n",
    "print(\"Vektorisierung der Testdaten (mit Trainings-Modell)...\")\n",
    "X_test_vec = np.array([get_doc_vector(text, w2v_model) for text in df_lg_test[\"cleaned_text\"]])\n",
    "\n",
    "# 3. Auswahl der strukturierten Features (aus der Gemini-Extraktion in Abschnitt 4)\n",
    "# Wir f√ºllen fehlende Werte (NaN) mit 0, damit die ML-Modelle damit arbeiten k√∂nnen.\n",
    "struct_cols = ['Kaufpreis_num']\n",
    "X_train_structured = df_lg_train[struct_cols].fillna(0)\n",
    "X_test_structured = df_lg_test[struct_cols].fillna(0)\n",
    "\n",
    "# 4. Umwandlung der Word2Vec-Vektoren in DataFrames\n",
    "emb_cols = [f\"emb_{i}\" for i in range(X_train_vec.shape[1])]\n",
    "df_train_features = pd.DataFrame(X_train_vec, columns=emb_cols)\n",
    "df_test_features = pd.DataFrame(X_test_vec, columns=emb_cols)\n",
    "\n",
    "# 5. Finale Zusammenf√ºhrung (Struktur + Text-Embeddings)\n",
    "# WICHTIG: reset_index(drop=True) sorgt daf√ºr, dass die Zeilen beim Zusammenf√ºgen exakt matchen!\n",
    "X_train_final = pd.concat([X_train_structured.reset_index(drop=True), df_train_features], axis=1)\n",
    "X_test_final = pd.concat([X_test_structured.reset_index(drop=True), df_test_features], axis=1)\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"‚úÖ Feature-Matrizen erfolgreich erstellt.\")\n",
    "print(f\"üìä Training: {X_train_final.shape[0]} Urteile, {X_train_final.shape[1]} Features\")\n",
    "print(f\"üìä Test:     {X_test_final.shape[0]} Urteile, {X_test_final.shape[1]} Features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05160c8f",
   "metadata": {},
   "source": [
    "## 6. Analyse und Auswertung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4af3ec",
   "metadata": {},
   "source": [
    "Entscheidungsbaum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb49984b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# 1. Modell-Initialisierung\n",
    "dt_model = DecisionTreeClassifier(max_depth=10, random_state=42, class_weight=\"balanced\")\n",
    "\n",
    "# 2. Cross-Validation (auf Trainingsdaten)\n",
    "# Wir pr√ºfen die Stabilit√§t √ºber 5 Folds\n",
    "cv_results_dt = cross_validate(\n",
    "    dt_model, X_train_final, y_train, \n",
    "    cv=cv, # Das cv-Objekt (StratifiedKFold) aus Abschnitt 4.4\n",
    "    scoring=['accuracy', 'precision', 'recall', 'f1'],\n",
    "    return_train_score=False\n",
    ")\n",
    "\n",
    "print(f\"--- Cross-Validation (Train) ---\")\n",
    "print(f\"Mittlere Accuracy: {cv_results_dt['test_accuracy'].mean():.4f} (+/- {cv_results_dt['test_accuracy'].std():.4f})\")\n",
    "print(f\"Mittlerer Recall:   {cv_results_dt['test_recall'].mean():.4f}\")\n",
    "\n",
    "# 3. Finales Training & Test-Evaluation\n",
    "dt_model.fit(X_train_final, y_train)\n",
    "y_pred_dt = dt_model.predict(X_test_final)\n",
    "\n",
    "print(f\"\\n--- Finale Evaluation (Testset) ---\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_dt):.4f}\")\n",
    "print(classification_report(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4755b724",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c129f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 1. Modell-Initialisierung\n",
    "rf_model = RandomForestClassifier(n_estimators=300, random_state=42, n_jobs=-1, class_weight=\"balanced\")\n",
    "\n",
    "# 2. Cross-Validation (auf Trainingsdaten)\n",
    "cv_results_rf = cross_validate(\n",
    "    rf_model, X_train_final, y_train, \n",
    "    cv=cv, \n",
    "    scoring=['accuracy', 'precision', 'recall', 'f1'],\n",
    "    return_train_score=False\n",
    ")\n",
    "\n",
    "print(f\"--- Cross-Validation (Train) ---\")\n",
    "print(f\"Mittlere Accuracy: {cv_results_rf['test_accuracy'].mean():.4f} (+/- {cv_results_rf['test_accuracy'].std():.4f})\")\n",
    "\n",
    "# 3. Finales Training & Test-Evaluation\n",
    "rf_model.fit(X_train_final, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test_final)\n",
    "\n",
    "print(f\"\\n--- Finale Evaluation (Testset) ---\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d992e1a2",
   "metadata": {},
   "source": [
    "Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d134f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Modell-Initialisierung\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "\n",
    "# 2. Cross-Validation (auf Trainingsdaten)\n",
    "cv_results_gb = cross_validate(\n",
    "    gb_model, X_train_final, y_train, \n",
    "    cv=cv, \n",
    "    scoring=['accuracy', 'precision', 'recall', 'f1'],\n",
    "    return_train_score=False\n",
    ")\n",
    "\n",
    "print(f\"--- Cross-Validation (Train) ---\")\n",
    "print(f\"Mittlere Accuracy: {cv_results_gb['test_accuracy'].mean():.4f}\")\n",
    "\n",
    "# 3. Finales Training & Test-Evaluation\n",
    "gb_model.fit(X_train_final, y_train)\n",
    "y_pred_gb = gb_model.predict(X_test_final)\n",
    "\n",
    "print(f\"\\n--- Finale Evaluation (Testset) ---\")\n",
    "print(classification_report(y_test, y_pred_gb))\n",
    "\n",
    "# 4. Visualisierung der Feature Importance\n",
    "# Wir zeigen die Top 15 Merkmale (Strukturvariablen + Embeddings)\n",
    "importances = pd.Series(gb_model.feature_importances_, index=X_train_final.columns)\n",
    "plt.figure(figsize=(10, 6))\n",
    "importances.nlargest(15).sort_values().plot(kind='barh', color='skyblue')\n",
    "plt.title(\"Top 15 Features (Gradient Boosting)\")\n",
    "plt.xlabel(\"Gini Importance\")\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4bce4b",
   "metadata": {},
   "source": [
    "evtl. SHAP Werte f√ºr Erkl√§rbarkeit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
